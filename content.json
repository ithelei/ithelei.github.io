{"meta":{"title":"养码哥","subtitle":null,"description":null,"author":"He Lei","url":"http://www.ithelei.com","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2019-08-26T13:42:29.302Z","updated":"2019-08-26T05:57:26.706Z","comments":false,"path":"/404.html","permalink":"http://www.ithelei.com//404.html","excerpt":"","text":""},{"title":"书单","date":"2019-09-14T14:43:42.012Z","updated":"2019-08-26T05:57:26.713Z","comments":false,"path":"books/index.html","permalink":"http://www.ithelei.com/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2020-05-10T13:53:29.311Z","updated":"2020-05-10T13:53:29.311Z","comments":false,"path":"about/index.html","permalink":"http://www.ithelei.com/about/index.html","excerpt":"","text":"2015年-2016年，主要集中在数字化（教育）领域。 2017.02.21 https://www.jianshu.com/p/2fcfb711db09 2017.03.10 https://www.jianshu.com/p/8f1d8f90ab8b 2017.03.18 https://www.jianshu.com/p/16bce5d15308 2017.03.26 https://www.jianshu.com/p/37865c28091f 2017.05.15（学习微安老师课程） https://www.jianshu.com/p/dfdc042074af 2017.11.11 下定决心研究技术。买书，静下心，扎实学技术。 2019.09.01 截止到目前，我买了近两万多块钱的技术书籍，有的还没有学。（但是每天都在精进） 说实话，技术在，心里踏实。（只为更好） 以下是我自己的书。 视频https://jishu-resource.oss-cn-beijing.aliyuncs.com/blog-img/b364346a1620a2ac81e1dc64e494274a.mp4 不忘初心，继续前行。"},{"title":"分类","date":"2019-08-26T13:42:29.311Z","updated":"2019-08-26T05:57:26.715Z","comments":false,"path":"categories/index.html","permalink":"http://www.ithelei.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-08-26T14:06:33.045Z","updated":"2019-08-26T05:57:26.717Z","comments":true,"path":"links/index.html","permalink":"http://www.ithelei.com/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-08-26T13:42:29.318Z","updated":"2019-08-26T05:57:26.720Z","comments":false,"path":"repository/index.html","permalink":"http://www.ithelei.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-08-26T13:42:29.321Z","updated":"2019-08-26T05:57:26.722Z","comments":false,"path":"tags/index.html","permalink":"http://www.ithelei.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"【成为架构师3-1】服务化：微服务架构，究竟解决什么问题","slug":"【成为架构师3-1】服务化：微服务架构，究竟解决什么问题","date":"2020-08-27T01:20:45.000Z","updated":"2020-08-30T00:25:22.043Z","comments":true,"path":"2020/08/27/【成为架构师3-1】服务化：微服务架构，究竟解决什么问题/","link":"","permalink":"http://www.ithelei.com/2020/08/27/【成为架构师3-1】服务化：微服务架构，究竟解决什么问题/","excerpt":"","text":"本篇作为微服务的开篇，只是简单的阐述一下微服务架构能带来的优势，以及微服务架构的弊端 早期架构的痛点 微服务架构的好处 微服务架构带来的问题 早期架构的痛点上一种架构通常只有四层： 客户端 反向代理 Web集群 数据库集群 或者是All in one的单体架构 这类架构通常有以下痛点： 代码到处拷贝 底层复杂性扩散（如引入缓存之后，业务调用方都要跟着修改） 公共库耦合 SQL质量无法保证 不易扩展，数据库耦合，join频繁 微服务架构的好处 复用性，消除代码拷贝 专注性，防止复杂性扩散 解耦合，消除公共库耦合 高质量，SQL稳定性有保障 易扩展，消除数据库耦合 高效性，调用方研发更高效 微服务架构带来的问题 系统复杂性上升 层次间依赖关系变得复杂 运维、部署更加麻烦 监控变得更加复杂 定位问题更加麻烦 服务化，不是简单的引入一个RPC框架，他需要一系列的基础设施，前者是容易的，后者才是困难的","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师3-3】服务化：必须保证高可用","slug":"【成为架构师3-3】服务化：必须保证高可用","date":"2020-08-27T01:20:45.000Z","updated":"2020-08-30T00:25:52.579Z","comments":true,"path":"2020/08/27/【成为架构师3-3】服务化：必须保证高可用/","link":"","permalink":"http://www.ithelei.com/2020/08/27/【成为架构师3-3】服务化：必须保证高可用/","excerpt":"","text":"高可用的常用手段 端到反向代理的 反向代理到站点 站点应用到微服务 服务到缓存 memcache缓存 redis缓存 缓存分片 服务到读库 服务到写库 高可用的常用手段可用，指的是系统对外能够提供服务，系统的可用时间 / 系统的总运行时间，所得的比值就是表征系统的可用的度量指标，用几个九来表示，99.99%就是四个九。 互联网架构实践中，实现高可用通常使用以下两种方式： 集群化（冗余） 故障自动转移 微服务的架构有很多层，每一层之间都要实现高可用 也就有了：端到反向代理、反向代理到站点、站点应用到微服务、微服务到缓存、微服务到读库、微服务到写库的多个层面高可用 端到反向代理的自上而下，先来看端到反向代理 在前面章节反向代理的内容中已经提及，反向代理的高可用使用虚VIP + Keepalived的方式来实现的，keepalived机制会检测主nginx的存活状态，当其不可用时会用从nginx顶上，虚IP使其二者对外是一个整体，流量迁移对调用方是透明的。 但是当主nginx挂掉的时候，当时连接的流量还是会有影响，不过用户只要进行刷新操作就可以恢复了。 之前有一个预留问题，就是这种方案nginx的利用率只用50%，解决方案就是双主互备，两个nginx使用两个虚IP，nginx之间互为主从，使用DNS轮询来进行访问，如果其中一个挂了，两个虚IP会指向同一个nginx。 反向代理到站点 反向代理到站点的高可用是反向代理层，也就是nginx来实现的，它会探测站点的存活状态，不会将流量转发到不可用的站点。 站点应用到微服务 站点到微服务的高可用是借助站点端的连接池 来实现的，连接池也负责对服务进行探活等操作，如果其中有微服务节点挂了，那么连接池就会将流量迁移到其它可用的微服务上去。 整个过程是由连接池完成的，对客户端，也就是调用方是透明的。 服务到缓存memcache缓存 memchache本身不支持集群，它的高可用是用缓存客户端的双读写来实现的。 redis缓存 redis天然支持集群，也就是经常说的哨兵机制，redis-sentinel负责监控主节点和从节点的状态，主节点自动地与从节点进行数据同步。 哨兵集群机制的自动故障转移是当主节点挂掉的时候，redis-sentinel会通知缓存客户端访问从节点，通知这一机制也是“哨兵”名字的由来了。 缓存分片 服务到缓存的高可用有其特殊性，因为缓存是为了加速数据的访问而存在的，它的高可用限度是不造成缓存“雪崩”即可。 缓存分片是将缓存数据分别存储在不同的缓存节点，每个节点只保存部分数据，通过一个cache proxy根据key来进行存取的选择。 如果其中一个分片挂了，那么流量会暂时打到数据库上，只要分片设计的粒度还是小的，那么这部分流量打到数据库，对于数据库也是完全可以接受的，对于整体架构也是可以接受的。 服务到读库如果数据库做了读写分离，那么数据库的架构应该是主库负责写入，从库或者提供读服务。 读库的高可用是以靠连接池来实现的，也是对客户端透明 服务到写库通常我们会说读写分离是一主多从，但是一主就无法实现主库的高可用。 学习nginx的高可用方式，数据库写库的高可用也是使用vip + keepalived的机智来实现的，同样的，它们也可以互备。 可以看到，在互联网架构中，高可用的实现方案在方法论上是互通的，其本质就是冗余 + 故障的自动转移。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师3-2】服务化：微服务的粒度，究竟要细到什么程度","slug":"【成为架构师3-2】服务化：微服务的粒度，究竟要细到什么程度","date":"2020-08-27T01:20:45.000Z","updated":"2020-08-30T00:25:41.580Z","comments":true,"path":"2020/08/27/【成为架构师3-2】服务化：微服务的粒度，究竟要细到什么程度/","link":"","permalink":"http://www.ithelei.com/2020/08/27/【成为架构师3-2】服务化：微服务的粒度，究竟要细到什么程度/","excerpt":"","text":"统一服务层 子业务服务 一个数据库一个服务 一个接口一个服务 常用的最佳实践 统一服务层最开始，也是最简单的，仅是抽象出一个服务层，所有的服务都是在一起的，全局只有一个服务的概念，这一服务满足上游的所有调用，并对下游进行操作 子业务服务统一的服务层不利于扩展部署和维护，按照业务的垂直拆分，进行服务划分，一个业务一个服务，下图就是表现了用户服务、朋友服务、群组服务、消息服务 上游的业务可能会调用多个服务，形成了网状关系，复杂性增大，引入网关进行统一转发可以解决这个问题 调用方通过服务号访问网关，网关通过服务号对调用进行分发 一个数据库一个服务一个服务可能会对应多个数据库，如下图的群组服务，就是群组信息、群组成员、群组消息三个库，但由一个统一的群组服务进行访问 一个数据库一个服务就是划分为三种服务： 这在按照业务划分服务的粒度上变得更细了 一个接口一个服务除一个数据库一个服务外，还有更细的粒度，就是按照接口来划分服务，一个接口一个服务： 群组服务包含，更新、添加、获取等接口，按照这些接口再划分为不同的服务 这一粒度太细了，细到依赖于特定的编程语言，如进程轻量级的Go 常用的最佳实践越细的粒度服务化通常会有以下的优点： 易于扩容缩容、独立部署 耦合度小，容错性好 缺点也是显而易见的，那就是复杂： 系统复杂、依赖关系复杂 运维也更复杂 配套设施也更为复杂 真正投入生产实践的，是一个权衡的过程，通常，基于业务作为微服务的划分粒度是最佳实践","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师3-4】服务化：必须支持高并发","slug":"【成为架构师3-4】服务化：必须支持高并发","date":"2020-08-27T01:20:45.000Z","updated":"2020-08-30T00:26:04.083Z","comments":true,"path":"2020/08/27/【成为架构师3-4】服务化：必须支持高并发/","link":"","permalink":"http://www.ithelei.com/2020/08/27/【成为架构师3-4】服务化：必须支持高并发/","excerpt":"","text":"高并发指标 垂直扩展（Scale up） 水平扩展（Scale out） 数据库的水平扩展 本篇是对微服务架构中高并发一个通用思路的阐述，侧重的是要实现高并发的架构基础，也就是提升性能，并不涉及任何实现的细节，也不对应某个具体的业务场景（前面的文章也基本上是这样的风格） 高并发指标 响应时间 （Response Time） 吞吐量（Throughout） 每秒查询率QPS（Query Per Second） 并发用户数 这些内容的解释之路: https://blog.csdn.net/u010889616/article/details/83245695 垂直扩展（Scale up） 增加单机硬件性能 提升单机架构性能 垂直扩展是有极限的，但是如果垂直扩展就能hold住，那么应该优先考虑垂直扩展 水平扩展（Scale out）端到反向代理、反向代理到站点、站点到服务的高并发的水平扩展和高可用的冗余的集群本质上是一样的，它们的集群方案在保证高可用的同时也支持高并发 数据库的水平扩展 数据库的水平扩展指的是两方面： 存储能力的扩展，理论上要达到无限的存储能力 读写能力的扩展，理论上要达到无限的读写能力 对于存储能力的扩展，就是数据库分片，分片既扩展了存储能力，也提高了读写性能 最简单的两种分片方式是：范围分片、Hash分片 范围分片 根据数据库主键Id以范围来划分数据库，比如1-1000w为库1，1000w-2000w为库2 实现非常的容易，微服务路由也十分容易 这种方式的好处是可以很容易的进行扩展，数据的划分也是均衡的（新库早期不均衡） 但是它的访问是不均衡的，新产生的数据，如新用户总是比老用户要活跃 Hash分片 根据主键的hash来进行划分和路由，规则也同样很简单，比如说奇数库、偶数库 数据划分是均衡的，访问也是均衡的，只要id是完全随机的 不利于水平扩展，当增加新节点的时候要重新计算hash，并对数据进行迁移","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师3-6】服务化：连接池，微服务的基础组件","slug":"【成为架构师3-6】服务化：连接池，微服务的基础组件","date":"2020-08-27T01:20:45.000Z","updated":"2020-08-30T00:26:26.179Z","comments":true,"path":"2020/08/27/【成为架构师3-6】服务化：连接池，微服务的基础组件/","link":"","permalink":"http://www.ithelei.com/2020/08/27/【成为架构师3-6】服务化：连接池，微服务的基础组件/","excerpt":"","text":"如何访问下游 连接池的核心接口 初始化 拿连接 放回连接 连接池的基本架构 其它考虑因素 在互联网架构中，我们常有访问下游的需求，包括但不限于：微服务、缓存、数据库。而连接池就是这些访问中的一个重要组件，本篇主要是对微服务中的重要组件 —— 连接池的核心设计思路进行一个简单的阐释。 如何访问下游在不使用连接池的情况下 就像把大象放进冰箱一样，有三个步骤，打开冰箱，放进去，关上冰箱（虽然这是讽刺空谈）但现实就是如此，在没有连接池的情况下，我们调用下游服务通常就是： 建立连接（Connection） 通过连接，收发请求 关闭连接 在早期使用jdbc的时候，我们都会下载一个比如说mysql-jdbc的driver，然后根据官方文档，学习如何建立连接，通过连接访问数据库，进行增删查改，操作完之后释放连接，简单来讲，也就是上述三步。1、3两步我们可以称之为new和close 有连接池的情况 有连接池的情况，访问下游服务也是三步： 拿一个连接 通过链接，收发请求 放回连接 这次的1、3两步我们可以称之为get和free，连接池事先建立好了比如说与数据库的连接，维护这个连接的数组就是连接池的核心数据结构 连接池的核心接口连接池操作有三个核心接口，分别是初始化、拿连接、放回连接 初始化 初始化的伪代码如下： `init() { for i to N { Array DBClientConnection[i] = new() Array DBClientConnection[i] -&gt; connect() Array lock[i] = 0 } }`数据结构很简单，总共是两个数组，一个是表示所有真正连接的数组，还有一个是第三行出现的一个lock数组，lock数组的作用即是表征下标对应的连接的状态，当前是否被占用。 拿连接 拿连接的过程也非常简单，首先就是遍历锁数组，如果为0，那么设置锁为1，返回连接即可，伪代码如下： GetConnection() { for i to N { if(Array lock[i] == 0) { Array lock[i] = 1 return Array DBClientConnection[i] } } }放回连接 放回连接只需要把lock设置为0就可以了 `FreeConnection(c) { for i to N { if(Array DBClientConnection[i] == c) { Array lock[i] = 0 } } }`###连接池的基本架构 上述简化的操作表示为架构就是这个样子： 其它考虑因素 上面只是最简单的连接池的数据结构和实现原理，真实的情况当然不可能就是这么简单的 比如说在数据结构上就有可以优化的，可以使用一个表征可用连接的链表来实现去连接的O(1) 复杂度，使用connectMap来对放回连接实现O(1) 的复杂度 连接的可用性检测，如果连接失效了，要进行重连 如果下游服务故障，失效连接需要剔除，以实现故障的自动转移 要保证连接选取的概率，实现负载均衡，比如动态负载均衡就是实施在连接池层面的 如果下游有新增的节点，需要动态扩充连接池，以实现服务自动发现","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师3-5】服务化：必须搞定负载均衡","slug":"【成为架构师3-5】服务化：必须搞定负载均衡","date":"2020-08-27T01:20:45.000Z","updated":"2020-08-30T00:26:14.914Z","comments":true,"path":"2020/08/27/【成为架构师3-5】服务化：必须搞定负载均衡/","link":"","permalink":"http://www.ithelei.com/2020/08/27/【成为架构师3-5】服务化：必须搞定负载均衡/","excerpt":"","text":"负载均衡方法论 同构环境下的负载均衡 静态权重 动态权重 过载保护 本篇是对微服务架构中实现负载均衡的一个通用思路的阐述 负载均衡方法论 同构环境下，重点在于 “均匀” 异构环境下，重点在于 “负载与能力匹配” 同构环境下的负载均衡 在同构环境下，负载均衡的实现基本上不需要额外的支持，在实现高并发、高可用的基础设施中：客户端到反向代理由dns轮询完成；反向代理到站点由nginx来完成；站点到服务由连接池完成；服务到数据层也是由数据层框架的客户端提供的连接池来完成。 因为是同构的，所以均衡策略是简单，轮询，随机的方式都可以实现。 本篇的重点是异构环境下的负载均衡。 静态权重 静态权重和同构环境下的“均衡方式”几乎是一样的，若按照 1：1：1配置下游的权重，那么就是均衡，可以说均衡是静态权重的一个特殊例子 静态权重一个最大的问题它是静态的，它是无法实时变化的，过载保护等也无法进行实施，但它是最快的也是成本最低的。 动态权重 动态权重有两个要点： 如何标识服务的处理能力 如何设计动态权重 服务的处理能力由调用方说了算，如果服务能够正常返回那么说明能力可以，如果超时了说明服务不能承受当前的流量压力 设计动态权重的原则就是：成功加小分，失败减大分 举个例子，先规定分值区间为【0，100】假设三个集群的下游服务service-1、service-2、service-3，三个服务的初始分值都是60，也就是说，在最初负载是均匀的。 随着时间的推移： 处理能力强的服务处理成功的请求越来越多 处理能力相对弱的服务偶尔有超时 最后动态权重的增减，变化为：service1-100分，service2-60分，service3-40分 那么这三个service负载比就是：5：3：2，service1会处理一半的请求，符合按照能力进行负载均衡。 过载保护什么是过载保护：当服务过载的时候很有可能造成我们说的“雪崩”，服务的流量到达处理能力的峰值，随之再增加流量，处理成功的请求直线下降，服务进入不可用的状态。 过载保护也有两种方式，一种是静态的，一种是动态的。 静态的过载就是设定一个流量阈值，超过这个阈值就不会再有多的请求了。 动态的过载保护和动态的负载均衡策略是相似的： 连接代表服务，分值代表服务（连接）的处理能力 处理成功加小分，处理失败减大分 临界边界喘口小气（减少流量、短时） 死亡状态喘口大气（没有流量、可能时间较长） 过载保护的核心是为了不掉底，过载保护是实施在集群中的某一个节点的，本来应该由该节点处理的流量转由其它节点处理。 如果整个集群达到过载状态，那么只能依靠丢弃请求来实现自我保护，集群的过载保护策略和某一节点的策略是不同的。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师3-7】服务化：连接池，高可用、可扩展、负载均衡都离不开它","slug":"【成为架构师3-7】服务化：连接池，高可用、可扩展、负载均衡都离不开它","date":"2020-08-27T01:20:45.000Z","updated":"2020-08-30T00:26:38.313Z","comments":true,"path":"2020/08/27/【成为架构师3-7】服务化：连接池，高可用、可扩展、负载均衡都离不开它/","link":"","permalink":"http://www.ithelei.com/2020/08/27/【成为架构师3-7】服务化：连接池，高可用、可扩展、负载均衡都离不开它/","excerpt":"","text":"高可用：剔除失效连接，故障自动转移 扩展性：服务发现：自动载入新服务节点配置、动态连接池 监听配置文件的md5，如果改变则重新载入 使用配置中心的回调机制，新的节点注册到配置中心，配置中心回调通知服务调用方 负载均衡：轮询，随机，静态权重动态权重","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-10】章节小结：百万流量，这些技术就够了","slug":"【成为架构师2-10】章节小结：百万流量，这些技术就够了","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-30T00:25:07.694Z","comments":true,"path":"2020/08/23/【成为架构师2-10】章节小结：百万流量，这些技术就够了/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-10】章节小结：百万流量，这些技术就够了/","excerpt":"","text":"知识串讲 往期回顾 知识串讲 早期单机系统的两个问题：性能瓶颈、耦合问题 解决性能问题早期最佳的方式是实施三大分离的伪分布式：动静分离、读写分离、前后台分离 解决耦合问题的方法是进行业务的垂直拆分，变为独立的子系统 如何实现子系统的高可用，引入反向代理，实现子系统的真正集群 引入反向代理之后，就多了反向代理的负载均衡和高可用问题 反向代理的负载均衡策略：random、轮询、一致性hash，四层和七层抓手 反向代理层的高可用：“影子主”模式，虚IP + Keepalived 在反向代理之前如何实现子系统的集群：DNS轮询，早期的DNS轮询无法完全的高可用 反向代理层（如nginx）出现瓶颈时可以引入操作系统层面的lvs，硬件层面的F5来实现多级反向代理，这是一个scale-up的方案；在此基础上使用DNS轮询可以实现理论上无限扩容的scale-out方案，且此时引入的DNS轮询是高可用的。 子系统集群之后会引发session一致性问题，解决方法常有：session同步、客户端保存、反向代理层来进行hash之后转发、后端统一存储（其中三、四使用较为广泛） 静态资源访问加速方案：CDN 往期回顾 【成为架构师2-1】 …. 后续篇章将进入千万级流量的架构设计，涉及： 服务化 缓存 数据库拆分 …","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-2】伪分布式与垂直拆分：快速解决单机性能问题的实践方案","slug":"【成为架构师2-2】伪分布式与垂直拆分：快速解决单机性能问题的实践方案","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-24T15:31:38.325Z","comments":true,"path":"2020/08/23/【成为架构师2-2】伪分布式与垂直拆分：快速解决单机性能问题的实践方案/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-2】伪分布式与垂直拆分：快速解决单机性能问题的实践方案/","excerpt":"","text":"架构演进阶段的新需求 单机资源瓶颈产生时的环境 架构演进，伪分布式，提升性能 1、三大分离结构（图中仅两种） 2、设计思路 3、什么问题没有解决 垂直拆分，解耦 1、四种垂直拆分： 2、设计思路 1 架构演进阶段的新需求原始的All in one 的单机系统无法满足需求，将会主要暴露出以下两个问题 访问人多的时候，访问能够快一点 （性能问题） 部分出错的时候不要全部挂掉 （耦合问题 2 单机资源瓶颈产生时的环境 此时最大的成本，是时间成本 能用“钱”解决的系统问题，往往不是问题 老板最不愿意见到的，是解决一个系统问题，花很长时间（市场和投资人等不起） 解决思路：增加硬件资源（时间短），避免大规模代码重构（时间长） 3 架构演进，伪分布式，提升性能三大分离结构（图中仅两种） 读写分离（会引发主从延时的问题） 动静分离，图中表现了文件服务器（第三方的OSS也是）与业务逻辑的服务器分离；现代前端，像vue就是动静分离的，对比古典的jsp，就无法实现动静分离 前后台分离，客户端访问与后台管理访问分离 设计思路 用最快的速度，增加硬件资源，提升系统性能，增加访问速度 什么问题没有解决 耦合问题：依旧是一个挂了全部就挂了 主从延时新问题 读写分离只能提升读性能，无法解决数据库量的问题 4 垂直拆分，解耦五八同城早期的页面结构，就像是BBS一样 有四种主要结构：首页、贴子发布页、帖子（分类）列表、帖子详情 四种垂直拆分： 业务垂直拆分（拆分的基础和依据，还是沈剑的那句话“脱离业务的架构，都是耍流氓”） 代码垂直拆分（子系统解耦） 数据库垂直拆分（数据量降低，延时缓解） 研发团队垂直拆分（专业化，效率提升） 设计思路 用最快的速度，增加硬件资源，解耦 伪分布式之所以称之为“伪”是因为它在整体系统层面依旧是一个单体，垂直拆分只是子系统之间实现了部分解耦，子系统之间有了一定的隔离性，但它也依旧是一个整体。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-1】容量设计：流量高低，对架构究竟有什么影响","slug":"【成为架构师2-1】容量设计：流量高低，对架构究竟有什么影响","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-24T15:19:59.734Z","comments":true,"path":"2020/08/23/【成为架构师2-1】容量设计：流量高低，对架构究竟有什么影响/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-1】容量设计：流量高低，对架构究竟有什么影响/","excerpt":"","text":"何时需要进行容量评估 哪些指标需要进行容量预估 架构设计的容量评估步骤（吞吐量为例） 1、评估总访问量 2、评估平均访问量 3、评估高峰QPS 4、评估系统、单机极限QPS 5、根据线上冗余度做决策 1、何时需要进行容量评估 容量有质变性增长 临时运营活动 新系统上线 两个场景例子： 要做双十一促销活动，那么机器能不能抗住，扛不住有需要加几台 新系统上线，数据库需不需要分库，如果需要，那么分几个库 技术上来说，这些都是系统容量预估问题，容量设计是架构师的必备技能。 2 哪些指标需要进行容量预估看具体业务侧的主要矛盾是什么： 数据量 （通常有用户发布行为的，如帖子） 并发量、吞吐量 （抢票、秒杀） 带宽（音视频） CPU/MEM/DISK等（计算需求、IO密集） 3 架构设计的容量评估步骤（吞吐量为例）1 评估总访问量 方式： 询问产品、运营的预期访问量是多少 Q： 一个App-push的运营活动，计划在30min内完成5000w用户的push推送，预计push点击率为10%，那么push落地页的总访问量是多少？ A： 5000w * 10% = 500w 2 评估平均访问量 QPS的计算方式为：总量 / 时间，若以一天计，则当作为4w秒。 QPS、并发、吞吐等的理解可以参考这篇文章：QPS、TPS、吞吐量等性能指标的理解 Q： push落地页系统30min的访问量为500w，平均QPS为多少？A： 500w / （30 * 60） Q： 某信息分类网站的日均PV约8000w，平均QPS是多少？A： 一天按照4w秒计算，8000w / 4w = 2000 3 评估高峰QPS 方式 根据业务的访问曲线图来，按照比例计算峰值QPS 没有曲线图则根据82原则计算，认为80%的请求落在20%的时间里，即（总量0.8）/ （总时间0.2） 若日均QPS为2000，则根据图中得到平均和峰值的比例关系为1：2.5，那么峰值的QPS可以估计为500 4 评估系统、单机极限QPS 方式： 进行压力测试 举例，以App-push运营活动落地页为例（日均2000QPS，峰值5000QPS）假设系统的架构如下： 访问端是APP 活动的落地页是一个H5 H5的数据大部分来自cache（99%），少数来自db（1%） 通过压力测试发现，web层是瓶颈，tomcat的压测只能抗住1200QPS 5 根据线上冗余度做决策 经过上面4个步骤的计算，已经得到了需求的容量大小，再根据线上已经有的，就可以判断出是否需要能够满足需求，以及扩容到什么程度。 举例： 若线上有两台web服务器，那么为了满足需求应至少再增加三台，四台更为保险。 在上述的五个步骤中，只有第四步压力测试是需要提前准备的，其它四步骤都是临时计算得到的。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-3】反向代理：接入层扩容，负载均衡","slug":"【成为架构师2-3】反向代理：接入层扩容，负载均衡","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-24T15:44:23.362Z","comments":true,"path":"2020/08/23/【成为架构师2-3】反向代理：接入层扩容，负载均衡/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-3】反向代理：接入层扩容，负载均衡/","excerpt":"","text":"单机遗留问题 反向代理，接入层扩容 用什么做反向代理 反向代理解决了什么问题 反向代理带来了什么新问题 反向代理，负载均衡 负载均衡方法： 负载均衡抓手（如何维护session状态一致性）： 反向代理，高可用 两个遗留问题 1 单机遗留问题上一篇讨论了伪分布式与垂直拆分的问题 垂直拆分，解除了子系统耦合，但是对于同一个垂直站点子系统，仍然是一个“单体架构” 集群的实现，通常需要引入反向代理 2 反向代理，接入层扩容用什么做反向代理 软件层面：nginx / apache 操作系统层面：LVS 硬件：F5 在这里我们只谈软件层面的，OS与硬件层面感兴趣的话可以百度或者Google，至于何为反向代理这里也不赘述了 反向代理解决了什么问题 子web系统性能，不再受到单台机器资源限制，可以扩展 子web系统，实现了高可用，伪集群变为真集群 反向代理带来了什么新问题 多个web节点，负载如何分配（负载均衡问题） 反向代理层，如何保证高可用（反向代理高可用问题） 3 反向代理，负载均衡负载均衡方法： 随机，将请求random到web-server 轮询，按照web-server 1-n的顺序依次的分发请求 静态权重轮询，不同web-server之间的处理能力不同，性能好的权重大，会被转发更多的请求 态权重轮询（后续讨论），权重分配是动态的，而不是一个固定值 一致性哈希（后续讨论），ip哈希之后落在hash环上，按照顺时针方向找到对应的真实服务器ip或者虚拟节点 负载均衡抓手（如何维护session状态一致性）： 四层（转发/交换） 七层（转发/交换） 这来自于七层结构模型 第四层传输层：使用ip作为负载均衡的抓手 第七层应用层（在TCP/IP模型中为第五层）：使用http请求中携带的参数作为负载均衡的抓手 4 反向代理，高可用虚拟IP + keepalived方案： 公网IP虚拟化，nginx集群对外暴露的公网ip是一个虚拟ip，dns解析得到的是此虚拟ip 通过keepalived保证nginx的可用性，当其中一个nginx挂了，虚拟ip得到的请求会转到另一个可用的nginx上 但是这种stand by的方式会引入新的问题：利用率的问题，图中利用率只有50%，这将在后续进行讨论。 5 两个遗留问题 异构服务器的负载均衡，即前面的动态权重问题 keepalived方案造成的其中一个nginx stand by利用率低下的问题","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-4】反向代理与DNS轮询：接入层的架构演进","slug":"【成为架构师2-4】反向代理与DNS轮询：接入层的架构演进","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-30T00:23:45.744Z","comments":true,"path":"2020/08/23/【成为架构师2-4】反向代理与DNS轮询：接入层的架构演进/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-4】反向代理与DNS轮询：接入层的架构演进/","excerpt":"","text":"DNS轮询 反向代理 多层反向代理 多层反向代理，加DNS轮询 问题引入： nginx是2012年才流行起来的技术，在反向代理之前的怎么对流量承受能力进行扩容呢？ nginx成为了瓶颈应该怎么办 1 DNS轮询最初的单体架构，流量直接打到唯一的一个web-server上： tomcat只有1000QPS的抗压能力，当流量增大时，在反向代理流行之前，解决方案就是引入DNS轮询 DNS轮询：就是将多个web-server的实际公网ip配置到域名之下，通过dns-server来将流量按照轮询顺序转到对应ip的web-server上 DNS轮询的优势 支持扩展且成本低，主要增加机器和添加ip到域名即可 原先的系统不需要改造 负载均衡，dns可以保证每个节点是均衡的 DNS轮询的劣势 无法保证高可用，dns-server无法知道某一ip下的web-server是否可用，流量依旧会会被转到这里，这部分流量就会访问失败 扩容非实时，dns的解析生效有延迟 暴露过的的公网ip，安全性存在问题 2 反向代理反向代理的优势 对外屏蔽web-server，由nginx进行流行转发 扩容是实时的，原有系统也无需变化 反向代理的问题 nginx成为单点，依旧有高可用问题 反向代理层增加了复杂性和时延（次要） 高可用的反向代理 keepalived 不足的是资源利用率只有50%，假设nginx的承受QPS为10000，如果整个站点吞吐超过了nginx的上限，就需要转到多层反向代理 3 多层反向代理之前提到过，lvs和F5，lvs是实施在操作系统层面的，F5是在硬件层面的，性能一个比一个好，用它们来作为nginx的方向代理就可以做到流量扩容 把lvs架在nginx上面作为nginx反向代理，F5又在lvs的上面作为反向代理，使用虚IP+keepalived来确保高可用。只有入口处需要这种方式来保证高可用，之后的下层和上层的结构，下层某一个节点挂了，上层都可以探测到将流量转发到可用的节点上，所以不需要虚IP+keepalived的模式 假设此时的QPS上限达到了10w，因为这是一个scale-up的方案，就始终会有明确的上限，这是由使用的工具本身决定的，要实现理论上的无限扩容，就必然需要scale-out的方案，这就又回到了最初的DNS轮询 4 多层反向代理，加DNS轮询如果日PV达到了80亿次，像百度、Google、淘宝，以及一些大一些的企业的网站他们的域名都不止对应一个IP，终点又是起点，我们依旧需要DNS轮询 这种DNS轮询方式是高可用的，因为它的下游是高可用的 没有提到的： 比如区域划分，这就是dns解析服务区对应的服务区块了，华中的归华中，华东的归华东，这是由地理位置决定的 可以使用dns轮询 + nginx的模式 这一次分享了接入层的架构演进，依旧是干货满满的，下一篇将讲述session的一致性问题，这个session是广义的session，指的是用户会话状态的管理，不是单指web-server生产的session。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-5】维护session一致性的四种方案","slug":"【成为架构师2-5】维护session一致性的四种方案","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-30T00:24:11.819Z","comments":true,"path":"2020/08/23/【成为架构师2-5】维护session一致性的四种方案/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-5】维护session一致性的四种方案/","excerpt":"","text":"session同步 客户端存储 反向代理 后端统一存储 文中所指的session是广义的session，其含义是用户的会话状态，web-server如tomcat会产生用于存储用户数据的session，以及现在常用的token机制如jwt，都属于这一范畴 1 session同步多台web-server之间同步session 这种机子同步信息的模型在架构实践中其实非常的多，但是session一致性的维护有更好的方式，而且这种同步信息的模型随着数量的水平扩展消耗是指数级增加的，基本不会考虑这种方式 2 客户端存储最传统的方式就是cookie + session的模式，保存在客户端的cookie充当了标识用户的作用，通过cookie取得在服务端保存的session，所以这一模型的核心其实是cookie 客户端存储的含义就是将保存在服务端的用户信息转而由客户端存储，服务端不保存任何的信息 JWT JWT常会宣传的一个优势就是可以节省服务端的存储资源，它可以完全由客户端单独保存，这一实现的前提就是它是能够自描述的 JWT在创建时就所有需要信息用一个key加密起来，之后返回给客户端，之后客户端每次请求都带上JWT，服务端用之前加密的key解密，其完全依靠JWT来判断用户身份，而不需要再做任何查询 安全性 就安全性来说如果不做其他处理，其和cookie + session模式是完全一样的，二者的核心都还是在客户端 3 反向代理之前的文章中已经提到过了七层抓手和四层抓手，通过nginx按照规则转发请求，那么只有相同的输入量就可以得到相同的输出结果 通常使用四层抓手，即ip来作为转发规则，因为七层属于业务的范畴，从解耦的角度讲，nginx不应该关心业务层的内容 session依旧独立保存在每个web-server中 当某一个web-server重启的话这部分session将丢失，会造成用户的重新登录，不过这不是十分重要，不是主要矛盾 4 后端统一存储将session保存在后端统一的机子上，是数据库或者redis等缓存中，使用redis更多，因为session是一个经常要访问的内容 这一模型应该是实践中使用最多的： 它解耦了web-server的状态性，这下web-server是无状态的了，增加或者拿掉都不影响 session统一管理之后可以为其它上游提供服务 不过这一方式对获取session增加了一次网络调用，web-server可以在本地再对session进行一次缓存 通常 3 与 4 的使用是较为多的，3和4也可以结合起来使用","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-6】CDN：就近访问，缓解网络拥塞","slug":"【成为架构师2-6】CDN：就近访问，缓解网络拥塞","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-30T00:24:22.357Z","comments":true,"path":"2020/08/23/【成为架构师2-6】CDN：就近访问，缓解网络拥塞/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-6】CDN：就近访问，缓解网络拥塞/","excerpt":"","text":"cdn 就近访问 CDN的构成部分 源与镜像的一致性问题 一致性问题的解决方案 资源更新 1 CDNCDN（content delivery network）即内容分发网络，它的核心就是实现就近访问 CDN非常适合用于静态资源的加速访问（js、css、html、多媒体文件等） 2 就近访问那么什么是就近访问呢，就近的实际含义就是物理网络的”地理位置“近 假设有一个静态资源 abc.jpg在不同地理区域的机房都有存放，那么当北京用户试图访问这一资源的时候浏览器的请求就会被解析到北京机房，或许你会有疑问，请求根本就没到服务器，怎么会知道要到那个机房呢？ 这一过程的实现依赖的DNS的解析服务，DNS解析可以根据请求的ip，依照一定的配置规则，将域名解析为不同的nginx的公网ip，比如北京的ip，www.daojia.com的域名就会被解析为北京机房的公网ip 地理位置是CDN最常用的一种边缘网络配置规则 3 CDN的构成部分从CDN的就近访问实现来看，我们可以知道dns-server是这一过程的核心，除了dns-server，CDN作为一个分发网络，还需要其他的组成部分 CDN网络的主要构成： 源：主数据库，所有的、最新的资源 镜像：多个”穿透缓存“，源的复制 智能DNS，决定我们访问哪一个 4 源与镜像的一致性问题一致性问题的解决方案 数据在多处存储，就一定会有一致性问题，而一致性问题的解决有共性，又有具体问题具体分析的个性，每种场景下都有适合它的更优方案 假如源里更新了abc.js，但是镜像没有更新，数据不一致了，如何处理？ 这是一致性问题属于（分布式）缓存的不一致问题，通常有两种方案： 源更新的时候，过期掉镜像里的abc.js （缓存淘汰） 等待镜像里的abc.js过期（缓存过期） 就方案一来说，考虑这要如何实现，源需要维护一份镜像的List，然后for循环这一List对缓存进行淘汰，这是典型的反向依赖，源依赖了镜像在增加或者减少减少镜像节点的时候都要修改源的配置，是不合理的 来看方案二，在缓存未过期的时间段内，将有很长一段时间客户端会得到脏数据，这让人也不太能接受 在这一场景下，有一种更加的实践：使用文件版本号 为每一个静态文件的命名带上版本号，若原先的abc_v1.2.3.js升级为abc_v1.2.4，那么dns-server在解析域名试图获取这一文件的时候就能知道镜像里并不存在，就可以直接去源里取得数据，十分的高效 资源更新 资源更新无外乎两种方式： 资源更新的时候，源一次性推送所有镜像 发现资源缺失的时候，镜像主动去拉取源 方案一如前文所说的，发生了反向依赖的问题，所以在CDN的实践中通常采取第二种，即拉取的策略，镜像可以定时主动与源进行同步","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-9】早期性能优化-三大分离：读写分离与前后台分离","slug":"【成为架构师2-9】早期性能优化-三大分离：读写分离与前后台分离","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-30T00:24:58.061Z","comments":true,"path":"2020/08/23/【成为架构师2-9】早期性能优化-三大分离：读写分离与前后台分离/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-9】早期性能优化-三大分离：读写分离与前后台分离/","excerpt":"","text":"读写分离 水平切分 前后台分离 前后台介绍 耦合的架构设计 分离的常见设计 1 读写分离读写分离的核心思想就是：使用数据库分组，快速提升数据库读性能 读写分离的架构有三个特点： 主库负责数据库写入 从库可以水平扩展以实现数据库读性能的线性提高 主库与从库之间使用某种机制进行同步，比如binlog 2 水平切分容易和读写分离相混淆的就是水平切分技术，读写分离的实质是进行分组，而水平切分的核心是分片 比如上图中的按照id对2取模对数据进行分片 分片是提升数据库存储容量的有效方案，但它往往涉及系统改造 3 前后台分离前后台介绍 前后台分离与我们常听到的“前后台分离”是不同的概念，前后台分离关注的业务上的区分，而前后台分离是真实的技术实践，是前端与后台采取的开发和实现模式，前后台分离可以包含前后端分离这一实现模式 前后台耦合，后台的系统瓶颈将会影响前台的用户业务，何为前后台，通常通过业务进行简单的区分： 前台：用户访问的对外系统 后台：运营访问的对内系统 举一个房产信息平台的例子： 前台写入，用户发布数据 后台写入，爬虫抓取数据 前台读取，用户浏览数据 后台读取，运营浏览数据 从以上可以看出前后台的数据特点： 前台数据特点：结构化、变化少 后台数据特点：数据源多，结构变化快 耦合的架构设计 在早期，耦合的架构设计是这样子的： 其特点就是：前后台共用一个数据库 这就很容易使后台的系统瓶颈影响到前台 分离的常见设计 那么分离的核心也就是分离前后台的数据库了： 但是后台爬虫抓取的数据存入后台数据库后，前台呈现信息是需要这个内容的，所以需要一个后台数据库到前台数据库的转化机制（关于异步转换的落地技术就留给读者自己查阅资料了） 通过异步转换，使得前台与后台分离，后台的数据库变动、架构变动都可以几乎不影响前台的架构，所要做的只是更新异步转换即可","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-8】早期性能优化-三大分离之一：动静分离","slug":"【成为架构师2-8】早期性能优化-三大分离之一：动静分离","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-30T00:24:45.862Z","comments":true,"path":"2020/08/23/【成为架构师2-8】早期性能优化-三大分离之一：动静分离/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-8】早期性能优化-三大分离之一：动静分离/","excerpt":"","text":"三大分离 动静分离 静态页面 动态页面 架构设计 页面静态化 动态页面的生成过程 实施页面静态化 什么样的场景适合页面静态化 1 三大分离早期，对架构影响最小，提升性能最快的方案就是实施三大分离架构： 动静分离 读写分离 前后台分离 2 动静分离静态页面 指的是几乎不变或修改非常少的页面，通常有： 首页html css，js JPEG等资源文件 与之相对应的加速静态页面访问速度的技术通常有： CDN nginx squid / varnish 动态页面 动态页面通常是那些服务于业务逻辑的页面，需要进行数据查询，加速动态页面访问的架构通常有： 分层架构 服务化架构 数据库，缓存架构 加速动态页面的访问的架构是一个复杂的工作，这里就不做展开了，它本身也就是架构优化的核心内容 架构设计 动静分离：静态页面与动态页面，分开不同的系统访问的架构方法 通常来说静态页面的访问路径很短，时间也只需要几毫秒；而动态页面的访问路径通常较长，需要经过：反向代理、web-server、服务层、数据库或者缓存，时间在几十毫秒甚至几百毫秒，且动态页面对架构的扩展性更高 动态页面与静态页面通常使用不同的域名来进行区分： 3 页面静态化静态页面的访问速度是动态页面的上百倍，把需要“动态生成的页面”给“静态化”，岂不是可以极大地提升性能？ 动态页面的生成过程 动态页面生成通常是以下流程： 基本就是以下必要的几步： 浏览器解析域名请求服务器 web-server解析参数，请求服务层 服务层访问数据库（查询）或者缓存 实施页面静态化 提前生成静态页面，使用静态页面的相关加速技术来进行访问 什么样的场景适合页面静态化 适合的场景：返回页面结果集有限 城市页面 二手车（两万多也是有限的） … 不适合的场景：返回的结果集数量过大、写入变化频繁的： 帖子 搜索 …","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师2-7】TCP负载均衡，长连接的负载均衡策略","slug":"【成为架构师2-7】TCP负载均衡，长连接的负载均衡策略","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-30T00:24:31.263Z","comments":true,"path":"2020/08/23/【成为架构师2-7】TCP负载均衡，长连接的负载均衡策略/","link":"","permalink":"http://www.ithelei.com/2020/08/23/【成为架构师2-7】TCP负载均衡，长连接的负载均衡策略/","excerpt":"","text":"单体架构TCP连接与HTTP的负载均衡 客户端负载均衡（内置集群） 服务单负载均衡（静态IP列表） 高可用方案 1 单体架构TCP连接与HTTP的负载均衡单机架构 使用简单的TCP直连 http负载均衡 http负载均衡通常使用反向代理来实现，这在前面的文章中已经进行了阐述 2 客户端负载均衡（内置集群）客户端负载均衡就是在客户端维护一个域名列表，当要发起TCP连接的时候，使用选定的策略选择其中一个域名，通过dns-server的域名解析得到tcp服务器的ip 高可用如何保持 客户端需要自己制定重连机制，当发现选择域名的tcp-server 问题 多了一次dns解析，速度下降（手机端尤为明显） dns劫持的安全风险 上述问题可以通过ip直连来解决，也就是客户端保存的不是域名列表，而直接是tcp-server的外网ip 但这一方案的核心问题是：无法进行扩展，如果新增加了tcp-server需要修改客户端 所以将负载均衡策略会有诸多的问题 3 服务单负载均衡（静态IP列表）每一次访问tcp-server之前先访问一个新增的http服务器来获取tcp-server的ip 这一web-server将向客户端返回一个可用的tcp-server的ip 高可用方案 如何保证高可用呢？对于客户端负载均衡策略来说，客户端能够知道tcp-server不可用了而选择新的tcp-server，这里同理客户端也可以重新请求一次web-server来获取tcp-server，但是它还有可能返回不可用的tcp-server，严重浪费资源，所以必须要有机制来保证tcp-server的状态对web-server来说是可知的 服务状态上报 这有一个明显的缺点就是出现了反向依赖，tcp-server不应该依赖一个只是作为获取其ip的简单服务器，它应该只关心自己的业务，对于它的状态是否可用应该由属于这一范畴的事物来维护 服务状态拉取 由web-server去主动的获取各个tcp-server的状态，监听它们的可用状态，以及是否过载，完全地承担负载均衡的职责 至此，在流量达到百万级别，企业的增长期，接入层的架构演进技术已经暂时介绍完了，之后会分三篇详细介绍一下之前提过三大分离设计","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"公司目前架构","slug":"公司目前架构","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-23T14:57:50.738Z","comments":true,"path":"2020/08/23/公司目前架构/","link":"","permalink":"http://www.ithelei.com/2020/08/23/公司目前架构/","excerpt":"","text":"多vpc","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"公司网络","slug":"公司网络","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-23T15:09:21.780Z","comments":true,"path":"2020/08/23/公司网络/","link":"","permalink":"http://www.ithelei.com/2020/08/23/公司网络/","excerpt":"","text":"","categories":[{"name":"网络","slug":"网络","permalink":"http://www.ithelei.com/categories/网络/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://www.ithelei.com/tags/网络/"}]},{"title":"什么是vlan、三层交换机、网关、DNS、子网掩码、MAC地址","slug":"什么是vlan、三层交换机、网关、DNS、子网掩码、MAC地址","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-23T15:54:09.623Z","comments":true,"path":"2020/08/23/什么是vlan、三层交换机、网关、DNS、子网掩码、MAC地址/","link":"","permalink":"http://www.ithelei.com/2020/08/23/什么是vlan、三层交换机、网关、DNS、子网掩码、MAC地址/","excerpt":"","text":"很多朋友多次问到什么是网关、dns、子网掩码，三层交换机，它们定位的用途；确实，因为网络技术在弱电中确实应用非常广泛，我们平时在vip技术群中也是不断的讨论到网关、vlan、三层交换机或子网掩码等问题，今天我们就一起用通俗方式一次性了解清楚。 一、什么是vlan?VLAN中文是“虚拟局域网”。LAN可以是由少数几台家用计算机构成的网络，也可以是数以百计的计算机构成的企业网络。VLAN所指的LAN特指使用路由器分割的网络——也就是广播域。听上面的概念，肯定有不少朋友是一头雾水的，什么是虚拟局域网？好好的，为什么要划分vlan？ 这里举个例：通俗的了解 一所高中，新学期高一招了800个学生，这800个学生，如果放在一个班里，那肯定是管理不过来，面对800个人，老师看了也头疼，这边在授课，那边完全听不到，老师布置什么任务，也会有一些传达不到，老师要是想找某个学生的信息，要从800份信息中去找，极其麻烦，浪费时间； 而实际中，也是一样，电脑A要想要与电脑B通信，于是电脑A就需要发送arp请求，而网络中电脑众多，最终ARP请求会被转发到同一网络中的所有电脑，才能找到电脑B，如此一来，为了找到电脑B，消耗了网络整体的带宽，收到广播信息的计算机还要消耗一部分CPU时间来对它进行处理。造成了网络带宽和CPU运算能力的大量无谓消耗。 那么怎么办呢？ 学校就针对这800个学生，分成了10个班，每个班80人，分别命名为高一（1）班，高一（2）班、、、、高一（10）班，每个人都会获得一个班级编号。1101表示一班01号学生。1102表示一班02号学生。1201表示2班01号学生。同一个班的学生编号尾数不同，其它的都相同。那么这样老师再管理起来就轻松多了，可以把一班这80人管理的妥妥的，隔壁2班与3班乱成一锅粥也不管一班的事，我就要这一班80人好好上课就行。 这就是vlan，每个班就相当于一个vlan，而每个班名称，就相当于vlan的名称，而每个学生的编号就是ip地址；同班同学（同一个vlan的ip），因为同一个教室，朝夕相处，且可以相互通信，不同班的同学，若不做其它工作，很难往来通信。 所以同一个vlan间，可以相互通信；不同vlan，若不做配置，不能相互通信。 那么不同vlan如何通通信呢？就需要单臂路由与三层交换机。 二、单臂路由与三层交换机我们知道要实现不同vlan间通信，就必须需要有路由功能，不同VLAN之间相互通信的两种方式（单臂路由、三层交换机）。 什么是单臂路由？单臂路由的实现方式，其实就是普通二层交换机加路由器，从而实现不同vlan间的可以互相通信。 那什么是三层交换机呢？对于小型的网络，单臂路由可以应付，但随着VLAN之间流量的不断增加，很可能导致路由器成为整个网络的瓶颈，出现掉包、或者通信堵塞。 为了解决上述问题，三层交换机应运而生。三层交换机，本质上就是“带有路由功能的（二层）交换机”。路由属于OSI参照模型中第三层网络层的功能，因此带有第三层路由功能的交换机才被称为“三层交换机”。 关于三层交换机的内部结构，可以参照下面的简图。 在一台本体内，分别设置了交换机模块和路由器模块；而内置的路由模块与交换模块相同，使用ASIC硬件处理路由。因此，与传统的路由器相比，可以实现高速路由。并且，路由与交换模块是汇聚链接的，由于是内部连接，可以确保相当大的带宽，所以对于正规的项目，需要使用三层交换机来实现网网络间的通信。 三、什么是网关在了解了vlan与三层交换机后，能不能通信，还需要看网关是否正确。 一、什么是网关网关(Gateway)又称网间连接器、协议转换器。网关在传输层上以实现网络互连，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。 二、如何来理解网关大家都知道，从一个房间走到另一个房间，必然要经过一扇门。同样，从一个网络向另一个网络发送信息，也必须经过一道“关口”，这道关口就是网关。顾名思义，网关(Gateway)就是一个网络连接到另一个网络的“关口”。 按照不同的分类标准，网关也有很多种。TCP/IP协议里的网关是最常用的，在这里我们所讲的“网关”均指TCP/IP协议下的网关。 三、网关的ip地址那么网关到底是什么呢？ 网关实质上是一个网络通向其他网络的IP地址，网关在网段内的可用ip中选一个，不过，一般用的是第1个和最后一个。 ` 例如 比如有网络A和网络B， 网络A：的IP地址范围为“192.168.1.1~192. 168.1.254”，子网掩255.255.255.0； 如果需要与其它网段通信，那么它的网关可以设置为192.168.1.1，当然也可以设置为网段内其它的一个ip地址。 网络B：的IP地址范为“192.168.2.1~192.168.2.254”，子网掩码255.255.255.0。 如果需要与其它网段通信，那么它的网关可以设置为192.168.2.1，当然也可以设置为网段内其它的一个ip地址。` 四、网关是如何实现通信？在没有路由器的情况下，不同的两个网络之间是不能进行TCP/IP通信的，即使是两个网络连接在同一台交换机(或集线器)上，TCP/IP协议也会根据子网掩码(255.255.255.0)判定两个网络中的主机处在不同的网络里。而要实现这两个网络之间的通信，则必须通过网关。 如果网络A中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络B的网关，网络B的网关再转发给网络B的某个主机(如附图所示)。网络B向网络A转发数据包的过程。 所以说，只有设置好网关的IP地址，TCP/IP协议才能实现不同网络之间的相互通信。 什么是默认网关？如果搞清了什么是网关，默认网关也就好理解了。就好像一个房间可以有多扇门一样，一台主机可以有多个网关。默认网关的意思是一台主机如果找不到可用的网关，就把数据包发给默认指定的网关，由这个网关来处理数据包。现在主机使用的网关，一般指的是默认网关。 四、什么是DNSDNS是域名解析服务器（Domain Name System），是把网址变成IP地址的服务器。DNS说白了是把域名翻译成IP地址用的，这里面举个例子，大家就很容易清楚了。例如我们在浏览器里面输入www.baidu.com的时候，机器要跟百度这个网站进行通信，机器要往外面发送数据包，数据包里面要写百度这台服务器的IP地址，我们不知道IP地址是多少，那么就需要主机问DNS服务器，DNS服务器就自动帮我们把www.baidu.com这个域名翻译成了IP地址61.135.169.105。然后写到了数据包的目的IP地址里面就可以进行通信。 就跟我们写信一样，你得写个收信人的地址邮局才能给你发送吧，你给国外写信，你写中文地址邮局不认识，需要这个一个人帮你翻译成英语。这就是DNS的作用，所以你的在本地连接里面写DNS才可以正常浏览网页，如果不设置DNS，是无法正常访问网页的。 ##五、MAC地址 讲到MAC地址，就不得不提ip地址，这里顺便把ip地址也说下。 IP与MAC虽然现在已经ipv6了，但我们基本用的大多数还是ipv4协议，所谓ip就是你电脑整个网络的编号。其他电脑想访问电脑就得需要这个编号。但是这个编号很多情况下是一直在变化的。唯一不变的是你的MAC地址：物理地址。 MAC是网络中用来标识网卡设备的唯一网络地址。由相关硬件制造商统一分配，每台电脑的MAC地址都是唯一的。 做个比喻，你经常搬家，你没搬一次家都有一个地址，XX小区XX单元XX号，这个就是IP。但是你的名字不变，这个就是MAC，不同的是我们的MAC不允许重名。 我们的IP分为两个部分：如上图分为网络部分和主机部分。网络部分好比就是你在XX省XX市XX镇，这个是国家固定下来了的。但是XX小区XX单元XX号是开发商自己定的。两个编号加起来就是你的ip了。不同的是在现实中两个编号的长度是固定的，在网络上A、B、C、D的ip地址却是变化的。 六、子网掩码子网掩码是为了区分网络位和主机位，上面我们说到过，一个ip地址是由网络部分和主机部分。正如一个人的名字由姓与名组成。 那么我们可以把IP地址比作一个人的名字，那么子网掩码就像是一份名单，可以快速的知道那些人同姓，那些人不同姓，把同姓的人分在一组，让他们之前可以互相交流。 `举个例子 有一个网段是192.168.1.0-192.1.254，这个网段就像一个村子一样，就称它为安防村，此这网段有个ip地址是192.168.1.1，我们就叫他安防一，另外一个人叫安防二，它的ip地址为192.168.1.2，我们一看他们，就知道他们是同村的。 另外有一个网段，是192.168.0.0——192.168.255.254，我们叫它安村，村里有个同样有两个ip地址为92.168.1.1与192.168.1.2，也叫安防一，安防二，那么问题来了？这个时候，如何区分他们是属于那个村的？ 这个时候就需要子网掩码了来判断他们是属于那个网段的，需要把安防一、安防二带到村里去认下，就知道他们是属于那个村了，安防村的网段是255.255.255.0，安村的网段是255.255.0.0。 网络中也会出现类似于“同名”“同姓”的ip地址，如何区分他们到底是属于那个网段，就需要依靠子网掩码了。`","categories":[{"name":"网络","slug":"网络","permalink":"http://www.ithelei.com/categories/网络/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://www.ithelei.com/tags/网络/"}]},{"title":"百万流量","slug":"百万流量","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-23T14:55:36.895Z","comments":true,"path":"2020/08/23/百万流量/","link":"","permalink":"http://www.ithelei.com/2020/08/23/百万流量/","excerpt":"","text":"技术为更好","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"系统架构升级培训指导","slug":"阿里来公司会议","date":"2020-08-23T01:20:45.000Z","updated":"2020-08-23T15:21:57.020Z","comments":true,"path":"2020/08/23/阿里来公司会议/","link":"","permalink":"http://www.ithelei.com/2020/08/23/阿里来公司会议/","excerpt":"","text":"今天阿里两位高级构架师到信融总部给研发中心同事做系统架构升级培训指导。信融与阿里一直在业务及技术层面有很深合作，未来阿里技术团队将与信融研发中心开展更深入的合作，为信融企业客户提供更加稳定高效服务保驾护航，为信融集团的做好企业服务蓝图提供坚定有力保障。","categories":[{"name":"会议","slug":"会议","permalink":"http://www.ithelei.com/categories/会议/"},{"name":"架构","slug":"会议/架构","permalink":"http://www.ithelei.com/categories/会议/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"},{"name":"会议","slug":"会议","permalink":"http://www.ithelei.com/tags/会议/"}]},{"title":"【成为架构师1-1】技术选型：创业初期，技术如何选型","slug":"【成为架构师1-1】技术选型：创业初期，技术如何选型","date":"2020-08-22T01:20:45.000Z","updated":"2020-08-30T00:22:56.836Z","comments":true,"path":"2020/08/22/【成为架构师1-1】技术选型：创业初期，技术如何选型/","link":"","permalink":"http://www.ithelei.com/2020/08/22/【成为架构师1-1】技术选型：创业初期，技术如何选型/","excerpt":"","text":"创业初期的系统特点 创业初期的架构特点 创业初期，推荐的技术选型 创业初期，工程师的主要矛盾 创业初期的系统特点 请求量低（小于10w） 数据量小（小于10w） 代码量小 一台机器 创业初期的架构特点 单机系统（All in one） 程序耦合（All in one） 逻辑核心是CRUD 创业初期，推荐的技术选型 HP体系（Linux，Apache，MySQL，PHP） Java体系（Linux，Tomcat，MySQL，Java） 早期选型的依据是：熟悉的，擅长的，这关乎的是技术人员的视野问题 创业初期，工程师的主要矛盾 CURD频繁出错，应当尽早引入DAO/ORM技术","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"【成为架构师1-2】技术选型：框架组件要不要自研，何时自研","slug":"【成为架构师1-2】技术选型：框架组件要不要自研，何时自研","date":"2020-08-22T01:20:45.000Z","updated":"2020-08-30T00:23:12.723Z","comments":true,"path":"2020/08/22/【成为架构师1-2】技术选型：框架组件要不要自研，何时自研/","link":"","permalink":"http://www.ithelei.com/2020/08/22/【成为架构师1-2】技术选型：框架组件要不要自研，何时自研/","excerpt":"","text":"早期不建议自研 控制技术栈的统一 对第三方库“浅浅地封装一层” 在后期，适当地造一些轮子 早期不建议自研 早期，业务以“快速迭代”为最高优先级 技术栈，以自己熟悉的为选型依据 此时，对技术合伙人的视野有一定要求 控制技术栈的统一 绝对不能，每个人想用什么就用什么 使是开源，技术栈也要尽量统一 团队之间不统一的技术栈必然造成开发、测试、运维成本的巨额提高，且必将造成混乱 以下是我自己的一点感触：技术栈统一听上去是一个很简单也十分基础的要求，大家作为一个团队一起开发，使用相同的技术框架似乎是理所当然的。就我自己而言，我所处的团队规模还非常的小，技术栈不统一这一点却不仅发生在成员之间还发生在自己身上。或许这听起来匪夷所思，为什么自己使用的技术栈都会不一样，这个不一样表现在一个开发周期内的时间尺度上，我总是倾向于使用业内更成熟、更高效的技术框架，但原先的项目是以旧的技术框架为基础的，在没有大规模的重构之前，不合理地引入部分新技术造成了冲击，而新技术实际带来的收益（开发效率、成品性能）并不足以弥补造成的损失。且这对于未来重构也未必能起到好的作用。 对第三方库“浅浅地封装一层”何为“浅浅地封装一层” `// Memcache的原API String Memcache::get(String key) // 向调用方暴露的API String 58DaojiaKV::get(String key) { String result = Memcache::get(key); return result; }`上述封装看上去只是命名空间的变化，但其实这一封装首先有两点封装的通用优势： 对使用方屏蔽实现细节 底层变化时，调用方改动很小（如Memcache变化为Redis，调用方只需要升级依赖的 58DaojiaKV 这一库即可） 能够方便实现统一的功能，为后续的扩展预留空间 在开发初期，并不能识别所有的业务需求和非功能性需求，这一层浅浅的封装就为后续的扩展预留了空间，比如说要记录缓存的访问时间： `String 58DaojiaKV::get(String key) { Long startTime = now(); String result = Memcache::get(key); Long endTime = now(); reportKVTime(startTime - endTime); return result; }`当然上述只是一个例子，像这类公共的记录可以从全局去处理，比如做切面等等。 在后期，适当地造一些轮子为什么无法全部使用开源：开源解决不了全部的个性化需求 造轮子的可能性：不同的技术团队，痛点是相似的 自研解决痛点，更贴合团队的实际","categories":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/categories/架构/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.ithelei.com/tags/架构/"}]},{"title":"Linux系统的ECS实例中如何对MySQL进行自动备份","slug":"Linux系统的ECS实例中如何对MySQL进行自动备份","date":"2020-03-01T11:33:45.000Z","updated":"2020-03-01T04:40:47.881Z","comments":true,"path":"2020/03/01/Linux系统的ECS实例中如何对MySQL进行自动备份/","link":"","permalink":"http://www.ithelei.com/2020/03/01/Linux系统的ECS实例中如何对MySQL进行自动备份/","excerpt":"","text":"主要介绍Linux系统的ECS实例中如何对MySQL进行自动备份。Linux系统的ECS实例中搭建了MySQL服务，用户可以使用如下脚本实现MySQL的定期自动备份。 将以下脚本拷贝到本地，上传到服务器上，名称叫 “autoback.sh”。 `#!/bin/bash #-----------------------------------------------# #This is a free GNU GPL version 3.0 or abover #Copyright (C) 2008 06 05 #mysql_backup Dedicated copyright by My #-----------------------------------------------# echo -e [`date +&quot;%Y-%m-%d %H:%M:%S&quot;`] start #system time time=`date +&quot;%y-%m-%d&quot;` #host IP host=&quot;127.0.0.1&quot; #database backup user user=&quot;root&quot; #database password passwd=&quot;yourpasswd&quot; #Create a backup directory mkdir -p /backup/db/&quot;$time&quot; #list database name all_database=`/usr/bin/mysql -u$user -p$passwd -Bse &apos;show databases&apos;` #in the table from the database backup for i in $all_database do /usr/bin/mysqldump -u$user -p$passwd $i &gt; /backup/db/&quot;$time&quot;/&quot;$i&quot;_&quot;$time&quot;.sql done echo -e [`date +&quot;%Y-%m-%d %H:%M:%S&quot;`] end exit 0`注：脚本中的数据库名和数据库密码以用户需要备份的数据库信息为准，需要用户修改下。 运行crontab -e，写入以下内容。保存退出，之后每天早上5：30就会自动备份数据库了。 `30 5 * * * root sh /root/autobackup.sh &gt;/dev/null 2&gt;&amp;1`注意：备份会占用磁盘空间，及时清理不需要的数据或者扩展磁盘空间。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"}]},{"title":"Nginx+Tomcat动静分离及Nginx优化(企业案例)","slug":"Nginx+Tomcat动静分离及Nginx优化(企业案例)","date":"2020-03-01T11:33:45.000Z","updated":"2020-03-01T12:47:37.519Z","comments":true,"path":"2020/03/01/Nginx+Tomcat动静分离及Nginx优化(企业案例)/","link":"","permalink":"http://www.ithelei.com/2020/03/01/Nginx+Tomcat动静分离及Nginx优化(企业案例)/","excerpt":"","text":"目的： Nginx处理用户请求的静态页面，tomcat处理用户请求jsp页面，来实现动态分离，nginx处理静态页面效率远高于tomcat，这样一来就能更好的提高并发，处理性能。 准备软件： 下载jdk1.7：https://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html 下载tomcat8.0：http://tomcat.apache.org/download-80.cgi 下载nginx1.4.4：http://nginx.org/en/download.html 1、JDK配置 2、Tomcat配置 tar zxvf apache-tomcat-8.0.0-RC5.tar.gz mv apache-tomcat-8.0.0-RC5 /usr/local/tomcat 默认tomcat是root身份运行的，这样不安全，我们设置来用普通用户`[root@localhost ~]# groupadd tomcat [root@localhost ~]# useradd -g tomcat tomcat [root@localhost ~]# passwd tomcat [root@localhost ~]# chown tomcat.tomcat -R /usr/local/tomcat [root@localhost ~]# su - tomcat /usr/local/tomcat/bin/startup.sh [root@localhost ~]# echo &apos;su - tomcat -c &quot;tomcat /usr/local/tomcat/bin/startup.sh&quot;&apos; &gt;&gt; /etc/rc.local #开机启动`3、Nginx安装配置 `[root@localhost ~]# groupadd nginx [root@localhost ~]# useradd -g nginx -s /sbin/nologin nginx [root@localhost ~]# yum install –y make zlib-devel openssl-devel pcre-devel [root@localhost ~]# tar zxvf nginx-1.4.4.tar.gz [root@localhost ~]# cd nginx-1.4.4 [root@localhost nginx-1.4.4]# ./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_gzip_static_module --with-http_stub_status_module [root@localhost nginx-1.4.4]# make &amp;&amp; make install`具体可以参考我的简书地址：https://www.jianshu.com/p/1795b66b6869 主配置文件配置`[root@localhost ~]# vi /usr/local/nginx/conf/nginx.conf user nginx; worker_processes 1; error_log logs/error.log; pid logs/nginx.pid; events { use epoll; worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #日志格式定义 log_format main &apos;$remote_addr - $remote_user[$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent&quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; keepalive_timeout 65; #gzip压缩功能设置 gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascripttext/css application/xml; gzip_vary on; server { listen 80; server_name www.test.com; location / { #jsp网站程序根目录，一般nginx与tomcat在同一个目录 root /usr/local/tomcat/webapps/ROOT; index index.html index.jsp index.html; } location ~ .*.jsp$ { index index.jsp; proxy_pass http://127.0.0.1:8080; #来自jsp请求交给tomcat处理 proxy_redirect off; proxy_set_header Host $host; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数 proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间 proxy_read_timeout 90; #连接成功后，后端服务器响应时间 proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 6 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 64k;#高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 } location ~ .*\\.(gif|jpg|png|bmp|swf)$ #由nginx处理静态页面 { expires 30d; #使用expires缓存模块，缓存到客户端30天 } location ~ .*\\.(jsp|js|css)?$ { expires 1d; } error_page 404 /404.html; #错误页面 error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } }`编写nginx启动、停止、重启等SysV管理脚本，方便使用`[root@localhost ~]# vi /etc/init.d/nginx #!/bin/bash # chkconfig: 345 99 20 # description: Nginx servicecontrol script PROG=&quot;/usr/local/nginx/sbin/nginx&quot; PIDF=&quot;/usr/local/nginx/logs/nginx.pid&quot; case &quot;$1&quot; in start) $PROG echo &quot;Nginx servicestart success.&quot; ;; stop) kill -s QUIT $(cat $PIDF) echo &quot;Nginx service stopsuccess.&quot; ;; restart) $0 stop $0 start ;; reload) kill -s HUP $(cat $PIDF) echo&quot;reload Nginx configsuccess.&quot; ;; *) echo &quot;Usage: $0{start|stop|restart|reload}&quot; exit 1 esac`如下： `[root@localhost ~]# chmod +x /etc/init.d/nginx [root@localhost ~]# service nginx restart [root@localhost ~]# chkconfig --add nginx [root@localhost ~]# chkconfig nginx on`4、性能测试 下面我们使用的ab压力测试工具，模拟发起一次1万的并发请求，使用的index.html页面是百度首页代码 Nginx测试 Tomcat测试 主要参数说明： Requests per second：平均每秒处理事务数 Time per request：平均事务响应时间 Tranfer rate：平均每秒网络吞吐量 经上面测试得出：nginx每秒处理请求6000次，而tomcat每秒只处理请求1000次。 由此看来，nginx是tomcat6倍的处理能力，如果网站程序静态页面多的话，就应该考虑使用Nginx与Tomcat整合来使用。","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.ithelei.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.ithelei.com/tags/Nginx/"}]},{"title":"Shell脚本监控WEB服务是否正常","slug":"Shell脚本监控WEB服务是否正常","date":"2020-03-01T11:33:45.000Z","updated":"2020-03-01T04:23:52.727Z","comments":true,"path":"2020/03/01/Shell脚本监控WEB服务是否正常/","link":"","permalink":"http://www.ithelei.com/2020/03/01/Shell脚本监控WEB服务是否正常/","excerpt":"","text":"1.安装sendmail来发邮件 # yum -y install sendmail # /etc/init.d/sendmail start # chkconfig sendmail on2.安装mutt邮件客户端，并设置相关信息 `# yum -y install mutt # vim /etc/Muttrc set charset=&quot;utf-8&quot; #设置发邮件编码 set envelope_from=yes set rfc2047_parameters=yes #解决附件乱码问题 set realname=&quot;报警&quot; #发件人别名 set use_from=yes #指定是否显示别名 set from=2515412401@qq.com #发送人地址`3.脚本信息 （1.）url文件如下 # cat url www.baidu.com www.sina.com（2.）脚本如下 `#!/bin/bash while true do Mail=&quot;ithelei@163.com&quot; FailCount=0 Retval=0 GetUrlStatus() { for ((i=1;i&lt;=3;i++)) #使用i++判断访问次数，如果wget两次超时则判断网站异常 do wget -T 3 --tries=1 --spider http://${1} &gt;/dev/null 2&gt;&amp;1 #-T超时时间，--tries尝试1次，--spider蜘蛛 [ $? -ne 0 ] &amp;&amp; let FailCount+=1; #访问超时时，$?不等于0，则FailCount加1 done if [ $FailCount -gt 1 ];then Retval=1 Date=`date +%F&quot; &quot;%H:%M` echo -e &quot;Date : $Date\\nProblem : $url is not running.&quot; | mutt -s &quot;URL Monitor&quot; $Mail else Retval=0 fi return $Retval #如果返回值为0，就正常退出循环，不为0则继续循环 } for url in `cat url | sed &apos;/^#/d&apos;` do #GetUrlStatus $url &amp;&amp; echo yes || echo no GetUrlStatus $url done sleep 2m #死循环，设置没2分钟运行一次 done `","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"}]},{"title":"编译安装Nginx","slug":"Nginx编译安装","date":"2020-03-01T11:33:45.000Z","updated":"2020-03-01T12:47:45.839Z","comments":true,"path":"2020/03/01/Nginx编译安装/","link":"","permalink":"http://www.ithelei.com/2020/03/01/Nginx编译安装/","excerpt":"","text":"编译安装Nginx由于以前写过，这里拿过来。 https://www.jianshu.com/p/1795b66b6869","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.ithelei.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.ithelei.com/tags/Nginx/"}]},{"title":"RAND随机函数使用","slug":"MySQL的基本查询——MySQL RAND随机函数使用","date":"2020-02-29T01:20:45.000Z","updated":"2020-02-29T10:56:10.709Z","comments":true,"path":"2020/02/29/MySQL的基本查询——MySQL RAND随机函数使用/","link":"","permalink":"http://www.ithelei.com/2020/02/29/MySQL的基本查询——MySQL RAND随机函数使用/","excerpt":"","text":"Mysql的RAND()函数在0~1之间产生一个随机数，如： `mysql&gt; select RAND() ,RAND() ,RAND() ;`该函数可以根据实际需求看用在什么地方。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"终端执行SQL方式","slug":"MySQL的基本查询——终端执行SQL方式","date":"2020-02-29T01:20:45.000Z","updated":"2020-02-29T10:51:22.444Z","comments":true,"path":"2020/02/29/MySQL的基本查询——终端执行SQL方式/","link":"","permalink":"http://www.ithelei.com/2020/02/29/MySQL的基本查询——终端执行SQL方式/","excerpt":"","text":"（1） 执行编写好的SQL脚本，命令如下： `mysql&gt; SOURCE d:/test.sql`","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MySQL LIKE与 NOT LIKE的用法","slug":"MySQL的基本查询——MySQL LIKE与 NOT LIKE的用法","date":"2020-02-29T01:20:45.000Z","updated":"2020-02-29T12:57:37.340Z","comments":true,"path":"2020/02/29/MySQL的基本查询——MySQL LIKE与 NOT LIKE的用法/","link":"","permalink":"http://www.ithelei.com/2020/02/29/MySQL的基本查询——MySQL LIKE与 NOT LIKE的用法/","excerpt":"","text":"like的通配符mysql的like语句中的通配符如下： “%”百分号 “_”下划线 “escape”转义 （1）“%”：表示任意个或多个字符，可匹配任意类型和长度的字符 select * from ykxt where kh like ‘%1788’ – kh中末4位都是1788的 select * from ykxt where kh like ‘1788%’ –kh中前4位都是1788的 select * from ykxt where kh like ‘%1788%’ –kh中包含1788的 另外，如果需要找出kh中既有“a” 又有“c”的记录，可以使用and条件 select * from ykxt_jiayou where kh like ‘%a%’ and kh like “%c%” (2) “_”下划线表示任意单个字符。匹配单个任意字符，她常用来限制表达式的字符长度语句（可以代表一个中文字符） select * from jkxt_jiayou where kh like “_” –kh中最多只能是一位的任意字符 select * from jkxt_jiayou where kh like “178835_” –kh中前6位是178835，最后一位可以是任意字符 select * from jkxt_jiayou where kh like “178835_a” –kh中前5位是17883，第六位可以是任意字符，最后一位为a 如果要查%或者_怎么办呢？ 使用ESCAPE进行转义。转义后面的%或者_就不作为通配符了，注意前面没有转义字符的%和_依然起通配符作用。 select * from jkxt_jiayou where kh like ‘%1788/_% ESCAPE ‘/‘’; 语句解释，通过ESCAPE关键字告诉mysql其后面的字符就是起转义作用的字符。在本示例中定义的“/”。在“/”后面的“_”就不再起通配符作用，而是普通的字符 select * from jkxt_jiayou where kh like ‘%1788$%%’ ESCAPE ‘$’; 语句解释： 通过ESCAPE关键字告诉mysql其后面的字符就是起转义作用的字符。在本示例中定义的是“$”。在“$”后面的“%”就不再起通配符作用，而是普通的字符 NOT LIKEMYSQL的 NOT LIKE 逻辑运算操作就是like数据集以外的部分，命令如下 select * from jkxt_jiayou where kh like ‘%a%c%’； 此命令能搜索出，“…a..c..”，但不能搜索出“..ca…”,那么 加一个not又如何呢，命令如下： select * from jkxt_jiayou where kh not like ‘%a%c%’； 这条命令可以检索出…ca…","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"REGEXP正则的使用","slug":"MySQL的基本查询——MySQL REGEXP正则的使用","date":"2020-02-29T01:20:45.000Z","updated":"2020-02-29T12:18:02.374Z","comments":true,"path":"2020/02/29/MySQL的基本查询——MySQL REGEXP正则的使用/","link":"","permalink":"http://www.ithelei.com/2020/02/29/MySQL的基本查询——MySQL REGEXP正则的使用/","excerpt":"","text":"REGEXP的运算符 mysql的REGEXP通配符如下。 （1） “^”字符： 匹配字符串的开始位置，如“^a” 表示以字母a开头的字符串 （2） “$”字符：匹配字符串的结束位置，如“$X”表示以字母X结尾的字符串 （3）“.”字符：就是英文下的点，他匹配任意一个字符，包括回车、换行等 （4）“”字符：“”字符匹配0个或多个字符，在她之前也必须有内容 （5）“+”字符：匹配1个或多个字符，在它之前也必须有内容。 例子： “ba+” 匹配以 b 开头，后 面至少紧跟一个 a ba、bay、bare、battle (6) “？”字符：匹配0次或1次，在他之前也必须有内容。 REGEXP实例select * from menu31 where name REGEXP ‘^基’； select * from menu31 where name REGEXP ‘理$’； select * from menu31 where name REGEXP ‘.’； select * from menu31 where name REGEXP ‘a+’； select * from menu31 where name REGEXP ‘图*’； select * from menu31 where name REGEXP ‘图?’； 查寻name以“图” 开头的记录，命令如下： select name from menu31 where name REGEXP &#39;^图&#39; 查询name以“理” 结尾的记录，命令如下： select name from menu31 where name REGEXP &#39;理$&#39; 查询name包含“理”的字符串的记录，命令如下： select name from menu31 where name REGEXP &#39;理$&#39; … 关于{}的用法{1}、{2，3}这是一个更全面的方法，它可以实现好几种保留字的功能。 a*:可以写成a{0,} a+:可以写成a{1,} a?:可以写成a{0,1} 在{}内只有一个整形参数i,表示字符只能出现i次 {}内有一个整形参数i,后面跟一个“,”，表示字符可以出现i次或者i次以上。 在{}内只有一个整形参数i,后面跟一个“，”在跟一个整形参数j,表示字符只能出现i次以上，j次以下（包括i次和j次）。其中的整形参数必须大于或者等于0，小于或者等RE_DUP_MAX(默认值是255)。如果有两个参数，第二个必须大于或者等于第一个。 关于[] 的用法 [a-dX]:匹配“a” “b” “c” “d”或者 ”X“ [^a-dX]:匹配除了”a“ ”b“ ”c“ ”d“ ”X“以外的字符 [^] 匹配不在括号中的任何字符 ‘[^abc]’ 匹配任何不包 含 a、b 或 c 的字符串 desk、fox、f8ke","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"有多种选择才叫有能力","slug":"有多种选择才叫有能力","date":"2020-02-29T01:20:45.000Z","updated":"2020-02-29T13:38:25.647Z","comments":true,"path":"2020/02/29/有多种选择才叫有能力/","link":"","permalink":"http://www.ithelei.com/2020/02/29/有多种选择才叫有能力/","excerpt":"","text":"有多种选择才叫有能力 做任何事情如果都能有多种选择，你就会很轻松，如果不能有多种选择或者没有选择就会很痛苦。 例如：汇报领导交代的任务提供解决方案时就要给领导多种选择，如果只有一种选择，老大没得选，不叫有能力；如果有两种选择，老大左右为难，也不叫有能力，只有给出三种或更多选择，才叫有能力。 2018俄罗斯世界杯球队踢足球也是如此，让己方拿球的球员选择越多，就越容易进球，所以，每个球员要快速跑动，以免被敌方球员盯住。 越让对方拿球球员没有选择，他们就容易输球。因此，要紧盯对方的每个球员，让拿球的球员脚下的球无处可传。 实际工作中，还有很多人对老大分配的任务直接让老大做问答题，“老大，这件事情要怎么做？”，老板是请你来解决问题的，不是考老板的，这样的员工混得如何结局可想而知。 提方案要让领导做选择题，并且给出多种选择才叫有能力。","categories":[{"name":"能力图谱","slug":"能力图谱","permalink":"http://www.ithelei.com/categories/能力图谱/"}],"tags":[{"name":"能力图谱","slug":"能力图谱","permalink":"http://www.ithelei.com/tags/能力图谱/"}]},{"title":"手动部署Java Web环境","slug":"手动部署Java Web环境","date":"2020-02-28T11:33:45.000Z","updated":"2020-03-01T05:09:02.148Z","comments":true,"path":"2020/02/28/手动部署Java Web环境/","link":"","permalink":"http://www.ithelei.com/2020/02/28/手动部署Java Web环境/","excerpt":"","text":"本篇教程在示例步骤中使用了以下版本的软件。操作时，请您以实际软件版本为准。 操作系统：CentOS 7.4 Tomcat 版本：Tomcat 8.5.50 JDK 版本：JDK 1.8.0_191 操作步骤 手动部署Java Web的操作步骤如下： 步骤一：下载源代码 步骤二：安装前准备 步骤三：安装JDK 步骤四：安装Apache Tomcat 步骤一：下载源代码 下载https://mirrors.aliyun.com/apache/tomcat/tomcat-8/?spm=a2c4g.11186623.2.20.369b7f530bPyHp 下载JDK 下载JDK安装压缩包https://www.oracle.com/cn/java/technologies/javase-downloads.html 步骤二：安装前准备 在安全组入方向添加规则放行所需端口。具体步骤，请参见添加安全组规则。https://help.aliyun.com/document_detail/25471.html?spm=a2c4g.11186623.2.23.7b417f53UyhPBE#concept-sm5-2wz-xdb例如本示例中，SSH协议的22端口和HTTP协议的8080端口。 远程连接Linux实例。具体步骤，请参见https://help.aliyun.com/document_detail/25433.html?spm=a2c4g.11186623.2.24.7b417f53mYrCFJ#concept-sdk-1jx-wdb 关闭防火墙。 运行systemctl status firewalld命令查看当前防火墙的状态。 如果防火墙的状态参数是inactive，则防火墙为关闭状态。 如果防火墙的状态参数是active，则防火墙为开启状态。本示例中防火墙为开启状态，因此需要关闭防火墙 关闭防火墙。如果防火墙为关闭状态可以忽略此步骤。 如果您想临时关闭防火墙，运行命令systemctl stop firewalld。 说明 这只是暂时关闭防火墙，下次重启Linux后，防火墙还会开启 如果您想永久关闭防火墙，运行命令systemctl disable firewalld。 说明 如果您想重新开启防火墙，具体操作，请参见https://firewalld.org/?spm=a2c4g.11186623.2.26.7b417f53SvMkGM 关闭SELinux。 运行命令getenforce查看SELinux的当前状态。 如果SELinux状态参数是Disabled， 则SELinux为关闭状态。 如果SELinux状态参数是Enforcing，则SELinux为开启状态。本示例中SELinux为开启状态，因此需要关闭SELinux。 关闭SELinux。如果SELinux为关闭状态可以忽略此步骤。 如果您想临时关闭SELinux，运行命令setenforce 0。 说明 这只是暂时关闭SELinux，下次重启Linux后，SELinux还会开启。 如果您想永久关闭SELinux，运行命令vi /etc/selinux/config编辑SELinux配置文件。回车后，把光标移动到SELINUX=enforcing这一行，按i键进入编辑模式，修改为SELINUX=disabled， 按Esc键，然后输入:wq并回车来保存并关闭SELinux配置文件。 说明 如果您想重新开启SELinux，具体操作，请参见https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/5/html/deployment_guide/ch-selinux?spm=a2c4g.11186623.2.28.7b417f5326ifjK#s1-SELinux-resources 重启系统使设置生效。 运行以下命令创建一般用户www来运行Tomcat。 useradd www 运行以下命令创建网站根目录。 mkdir -p /data/wwwroot/default 将需要部署的Java Web项目文件WAR包上传到网站根目录下，然后将网站根目录下文件权限改为www。本示例中，将依次运行以下命令直接在网站根目录下新建一个Tomcat测试页面，并将网站根目录下文件权限改为www。 echo Tomcat test &gt; /data/wwwroot/default/index.jsp chown -R www.www /data/wwwroot 步骤三：安装JDK 运行以下命令新建一个目录。 mkdir /usr/java 依次运行以下命令为jdk-8u191-linux-x64.tar.gz添加可执行权限并解压到/usr/java chmod +x jdk-8u191-linux-x64.tar.gz tar xzf jdk-8u191-linux-x64.tar.gz -C /usr/java 设置环境变量。 运行命令vi /etc/profile打开/etc/profile文件。 按下i键，添加以下内容。 `# set java environment export JAVA_HOME=/usr/java/jdk1.8.0_191 export CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib export PATH=$JAVA_HOME/bin:$PATH`按下Esc键，输入:wq并回车以保存并关闭文件。 运行source /etc/profile命令加载环境变量。 运行java -version命令显示JDK版本信息。 返回结果如图所示，表示JDK已经安装成功。 步骤四：安装Apache Tomcat 依次运行以下命令： 解压apache-tomcat-8.5.50.tar.gz。 tar xzf apache-tomcat-8.5.50.tar.gz 重命名Tomcat目录。 mv apache-tomcat-8.5.50 /usr/local/tomcat/ 设置用户权限。 chown -R www.www /usr/local/tomcat/ `在/usr/local/tomcat/目录下： bin：存放Tomcat的一些脚本文件，包含启动和关闭Tomcat服务脚本。 conf：存放Tomcat服务器的各种全局配置文件，其中最重要的是server.xml和web.xml。 webapps：Tomcat的主要Web发布目录，默认情况下把Web应用文件放于此目录。 logs：存放Tomcat执行时的日志文件。`配置server.xml文件 运行以下命令切换到/usr/local/tomcat/conf/目录 cd /usr/local/tomcat/conf/ 运行以下命令重命名server.xml文件 mv server.xml server.xml_bk 新建一个server.xml文件。 运行命令vi server.xml创建server.xml文件。 按下i键，添加以下内容 `&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;Server port=&quot;8006&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot;/&gt; &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot;/&gt; &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot;/&gt; &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot;/&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot;/&gt; &lt;/GlobalNamingResources&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;20&quot; acceptCount=&quot;1000&quot; maxHttpHeaderSize=&quot;65536&quot; debug=&quot;0&quot; disableUploadTimeout=&quot;true&quot; useBodyEncodingForURI=&quot;true&quot; enableLookups=&quot;false&quot; URIEncoding=&quot;UTF-8&quot;/&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;/data/wwwroot/default&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Context path=&quot;&quot; docBase=&quot;/data/wwwroot/default&quot; debug=&quot;0&quot; reloadable=&quot;false&quot; crossContext=&quot;true&quot;/&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt; &lt;/Server&gt;`按Esc 键，输入:wq并回车以保存并关闭文件。 设置JVM内存参数 运行vi /usr/local/tomcat/bin/setenv.sh命令创建/usr/local/tomcat/bin/setenv.sh文件。 按下i键，添加以下内容。 `JAVA_OPTS=&apos;-Djava.security.egd=file:/dev/./urandom -server -Xms256m -Xmx496m -Dfile.encoding=UTF-8&apos; 按下Esc键，输入:wq并回车以保存并关闭文件。 设置Tomcat自启动脚本。 运行以下命令下载脚本。 wget https://github.com/lj2007331/oneinstack/raw/master/init.d/Tomcat-init 运行以下命令重命名Tomcat-init。 `mv Tomcat-init /etc/init.d/tomcat`运行以下命令为/etc/init.d/tomcat添加可执行权限。 chmod +x /etc/init.d/tomcat运行以下命令设置启动脚本JAVA_HOME。 `sed -i &apos;s@^export JAVA_HOME=.*@export JAVA_HOME=/usr/java/jdk1.8.0_191@&apos; /etc/init.d/tomcat`依次运行以下命令设置Tomcat开机自启动。 chkconfig –add tomcat chkconfig tomcat on 运行以下命令启动Tomcat。 service tomcat start 在浏览器地址栏中输入http://公网IP:8080进行访问。 返回页面如下图所示，表示安装成功。 参考地址： https://help.aliyun.com/document_detail/51376.html?spm=a2c4g.11186623.6.1139.7b3876ef1Y1H4r#section-f8m-xqp-3zj","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"}]},{"title":"接入层限流","slug":"Nginx-接入层限流","date":"2020-02-27T01:20:45.000Z","updated":"2020-02-27T12:07:58.134Z","comments":true,"path":"2020/02/27/Nginx-接入层限流/","link":"","permalink":"http://www.ithelei.com/2020/02/27/Nginx-接入层限流/","excerpt":"","text":"接入层限流接入层通常指请求流量的入口，该层的主要目的有：负载均衡、非法请求过滤、请求聚合、缓存、降级、限流、A/B测试、服务质量监控等等，可以参考《使用Nginx+Lua(OpenResty)开发高性能Web应用》。 对于Nginx接入层限流可以使用Nginx自带了两个模块：连接数限流模块ngx_http_limit_conn_module和漏桶算法实现的请求限流模块ngx_http_limit_req_module。还可以使用OpenResty提供的Lua限流模块lua-resty-limit-traffic进行更复杂的限流场景。 limit_conn用来对某个KEY对应的总的网络连接数进行限流，可以按照如IP、域名维度进行限流。limit_req用来对某个KEY对应的请求的平均速率进行限流，并有两种用法：平滑模式（delay）和允许突发模式(nodelay)。 ngx_http_limit_conn_modulelimit_conn是对某个KEY对应的总的网络连接数进行限流。可以按照IP来限制IP维度的总连接数，或者按照服务域名来限制某个域名的总连接数。但是记住不是每一个请求连接都会被计数器统计，只有那些被Nginx处理的且已经读取了整个请求头的请求连接才会被计数器统计。 `http { limit_conn_zone$binary_remote_addr zone=addr:10m; limit_conn_log_level error; limit_conn_status 503; ... server { ... location /limit { limit_conn addr 1; }` limit_conn：要配置存放KEY和计数器的共享内存区域和指定KEY的最大连接数；此处指定的最大连接数是1，表示Nginx最多同时并发处理1个连接； limit_conn_zone：用来配置限流KEY、及存放KEY对应信息的共享内存区域大小；此处的KEY是“$binary_remote_addr”其表示IP地址，也可以使用如$server_name作为KEY来限制域名级别的最大连接数； limit_conn_status：配置被限流后返回的状态码，默认返回503； limit_conn_log_level：配置记录被限流后的日志级别，默认error级别。 limit_conn的主要执行过程如下所示： 请求进入后首先判断当前limit_conn_zone中相应KEY的连接数是否超出了配置的最大连接数； 如果超过了配置的最大大小，则被限流，返回limit_conn_status定义的错误状态码；（否则相应KEY的连接数加1，并注册请求处理完成的回调函数；） 进行请求处理； 在结束请求阶段会调用注册的回调函数对相应KEY的连接数减1。 limt_conn可以限流某个KEY的总并发/请求数，KEY可以根据需要变化。 按照IP限制并发连接数配置示例：首先定义IP维度的限流区域： `limit_conn_zone $binary_remote_addrzone=perip:10m;`接着在要限流的location中添加限流逻辑： `location /limit { limit_conn perip 2; echo &quot;123&quot;; }`即允许每个IP最大并发连接数为2。 使用AB测试工具进行测试，并发数为5个，总的请求数为5个： ab -n 5 -c 5 http://localhost/limit 将得到如下access.log输出： `[08/Jun/2019:20:10:51+0800] [1465373451.802] 200 [08/Jun/2019:20:10:51+0800] [1465373451.803] 200 [08/Jun/2019:20:10:51 +0800][1465373451.803] 503 [08/Jun/2019:20:10:51 +0800][1465373451.803] 503 [08/Jun/2019:20:10:51 +0800][1465373451.803] 503`此处我们把access log格式设置为log_format main ‘[$time_local] [$msec] $status’；分别是“日期 日期秒/毫秒值 响应状态码”。 如果被限流了，则在error.log中会看到类似如下的内容： `2016/06/08 20:10:51 [error] 5662#0: *5limiting connections by zone &quot;perip&quot;, client: 127.0.0.1, server: _,request: &quot;GET /limit HTTP/1.0&quot;, host: &quot;localhost&quot;`按照域名限制并发连接数配置示例：首先定义域名维度的限流区域： `limit_conn_zone $ server_name zone=perserver:10m;`接着在要限流的location中添加限流逻辑： `location /limit { limit_conn perserver 2; echo &quot;123&quot;; }`即允许每个域名最大并发请求连接数为2；这样配置可以实现服务器最大连接数限制。 ngx_http_limit_req_modulelimit_req是漏桶算法实现，用于对指定KEY对应的请求进行限流，比如按照IP维度限制请求速率。 配置示例： `http { limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; limit_conn_log_level error; limit_conn_status 503; ... server { ... location /limit { limit_req zone=one burst=5 nodelay; }` limit_req：配置限流区域、桶容量（突发容量，默认0）、是否延迟模式（默认延迟）； limit_req_zone：配置限流KEY、及存放KEY对应信息的共享内存区域大小、固定请求速率；此处指定的KEY是“$binary_remote_addr”表示IP地址；固定请求速率使用rate参数配置，支持10r/s和60r/m，即每秒10个请求和每分钟60个请求，不过最终都会转换为每秒的固定请求速率（10r/s为每100毫秒处理一个请求；60r/m，即每1000毫秒处理一个请求）。 limit_conn_status：配置被限流后返回的状态码，默认返回503； limit_conn_log_level：配置记录被限流后的日志级别，默认error级别。 limit_req的主要执行过程如下所示： 1、请求进入后首先判断最后一次请求时间相对于当前时间（第一次是0）是否需要限流，如果需要限流则执行步骤2，否则执行步骤3； 2.1、如果没有配置桶容量（burst），则桶容量为0；按照固定速率处理请求；如果请求被限流，则直接返回相应的错误码（默认503）； 2.2、如果配置了桶容量（burst&gt;0）且延迟模式(没有配置nodelay)；如果桶满了，则新进入的请求被限流；如果没有满则请求会以固定平均速率被处理（按照固定速率并根据需要延迟处理请求，延迟使用休眠实现）； 2.3、如果配置了桶容量（burst&gt;0）且非延迟模式（配置了nodelay）；不会按照固定速率处理请求，而是允许突发处理请求；如果桶满了，则请求被限流，直接返回相应的错误码； 3、如果没有被限流，则正常处理请求； 4、Nginx会在相应时机进行选择一些（3个节点）限流KEY进行过期处理，进行内存回收。 场景2.1测试首先定义IP维度的限流区域： `limit_req_zone $binary_remote_addrzone=test:10m rate=500r/s;`限制为每秒500个请求，固定平均速率为2毫秒一个请求。 接着在要限流的location中添加限流逻辑： `location /limit { limit_req zone=test; echo &quot;123&quot;; }`即桶容量为0（burst默认为0），且延迟模式。 使用AB测试工具进行测试，并发数为2个，总的请求数为10个： `ab -n 10 -c 2 http://localhost/limit`将得到如下access.log输出： `[08/Jun/2016:20:25:56+0800] [1465381556.410] 200 [08/Jun/2016:20:25:56 +0800][1465381556.410] 503 [08/Jun/2016:20:25:56 +0800][1465381556.411] 503 [08/Jun/2016:20:25:56+0800] [1465381556.411] 200 [08/Jun/2016:20:25:56 +0800][1465381556.412] 503 [08/Jun/2016:20:25:56 +0800][1465381556.412] 503`虽然每秒允许500个请求，但是因为桶容量为0，所以流入的请求要么被处理要么被限流，无法延迟处理；另外平均速率在2毫秒左右，比如1465381556.410和1465381556.411被处理了；有朋友会说这固定平均速率不是1毫秒嘛，其实这是因为实现算法没那么精准造成的。 如果被限流在error.log中会看到如下内容： `2016/06/08 20:25:56 [error] 6130#0: *1962limiting requests, excess: 1.000 by zone &quot;test&quot;, client: 127.0.0.1,server: _, request: &quot;GET /limit HTTP/1.0&quot;, host:&quot;localhost&quot;`如果被延迟了在error.log（日志级别要INFO级别）中会看到如下内容： `2016/06/10 09:05:23 [warn] 9766#0: *97021delaying request, excess: 0.368, by zone &quot;test&quot;, client: 127.0.0.1,server: _, request: &quot;GET /limit HTTP/1.0&quot;, host:&quot;localhost&quot;`场景2.2测试首先定义IP维度的限流区域： `limit_req_zone $binary_remote_addr zone=test:10m rate=2r/s;`为了方便测试设置速率为每秒2个请求，即固定平均速率是500毫秒一个请求。 接着在要限流的location中添加限流逻辑： `location /limit { limit_req zone=test burst=3; echo &quot;123&quot;; }`固定平均速率为500毫秒一个请求，通容量为3，如果桶满了新的请求被限流，否则可以进入桶中排队并等待（实现延迟模式）。 为了看出限流效果我们写了一个req.sh脚本： `ab -c 6 -n 6 http://localhost/limit sleep 0.3 ab -c 6 -n 6 http://localhost/limit`首先进行6个并发请求6次URL，然后休眠300毫秒，然后再进行6个并发请求6次URL；中间休眠目的是为了能跨越2秒看到效果，如果看不到如下的效果可以调节休眠时间。 将得到如下access.log输出： `[09/Jun/2016:08:46:43+0800] [1465433203.959] 200 [09/Jun/2016:08:46:43 +0800][1465433203.959] 503 [09/Jun/2016:08:46:43 +0800][1465433203.960] 503 [09/Jun/2016:08:46:44+0800] [1465433204.450] 200 [09/Jun/2016:08:46:44+0800] [1465433204.950] 200 [09/Jun/2016:08:46:45 +0800][1465433205.453] 200 [09/Jun/2016:08:46:45 +0800][1465433205.766] 503 [09/Jun/2016:08:46:45 +0800][1465433205.766] 503 [09/Jun/2016:08:46:45 +0800][1465433205.767] 503 [09/Jun/2016:08:46:45+0800] [1465433205.950] 200 [09/Jun/2016:08:46:46+0800] [1465433206.451] 200 [09/Jun/2016:08:46:46+0800] [1465433206.952] 200` 桶容量为3，即桶中在时间窗口内最多流入3个请求，且按照2r/s的固定速率处理请求（即每隔500毫秒处理一个请求）；桶计算时间窗口（1.5秒）=速率（2r/s）/桶容量(3)，也就是说在这个时间窗口内桶最多暂存3个请求。因此我们要以当前时间往前推1.5秒和1秒来计算时间窗口内的总请求数；另外因为默认是延迟模式，所以时间窗内的请求要被暂存到桶中，并以固定平均速率处理请求： 第一轮：有4个请求处理成功了，按照漏桶桶容量应该最多3个才对；这是因为计算算法的问题，第一次计算因没有参考值，所以第一次计算后，后续的计算才能有参考值，因此第一次成功可以忽略；这个问题影响很小可以忽略；而且按照固定500毫秒的速率处理请求。 第二轮：因为第一轮请求是突发来的，差不多都在1465433203.959时间点，只是因为漏桶将速率进行了平滑变成了固定平均速率（每500毫秒一个请求）；而第二轮计算时间应基于1465433203.959；而第二轮突发请求差不多都在1465433205.766时间点，因此计算桶容量的时间窗口应基于1465433203.959和1465433205.766来计算，计算结果为1465433205.766这个时间点漏桶为空了，可以流入桶中3个请求，其他请求被拒绝；又因为第一轮最后一次处理时间是1465433205.453，所以第二轮第一个请求被延迟到了1465433205.950。这里也要注意固定平均速率只是在配置的速率左右，存在计算精度问题，会有一些偏差。 如果桶容量改为1（burst=1），执行req.sh脚本可以看到如下输出： `09/Jun/2016:09:04:30+0800] [1465434270.362] 200 [09/Jun/2016:09:04:30 +0800][1465434270.371] 503 [09/Jun/2016:09:04:30 +0800] [1465434270.372]503 [09/Jun/2016:09:04:30 +0800][1465434270.372] 503 [09/Jun/2016:09:04:30 +0800][1465434270.372] 503 [09/Jun/2016:09:04:30+0800] [1465434270.864] 200 [09/Jun/2016:09:04:31 +0800][1465434271.178] 503 [09/Jun/2016:09:04:31 +0800][1465434271.178] 503 [09/Jun/2016:09:04:31 +0800][1465434271.178] 503 [09/Jun/2016:09:04:31 +0800][1465434271.178] 503 [09/Jun/2016:09:04:31 +0800][1465434271.179] 503 [09/Jun/2016:09:04:31+0800] [1465434271.366] 200`桶容量为1，按照每1000毫秒一个请求的固定平均速率处理请求。 场景2.3测试首先定义IP维度的限流区域： `limit_req_zone $binary_remote_addr zone=test:10m rate=2r/s;`为了方便测试配置为每秒2个请求，固定平均速率是500毫秒一个请求。 接着在要限流的location中添加限流逻辑： `location /limit { limit_req zone=test burst=3 nodelay; echo &quot;123&quot;; }`桶容量为3，如果桶满了直接拒绝新请求，且每秒2最多两个请求，桶按照固定500毫秒的速率以nodelay模式处理请求。 为了看到限流效果我们写了一个req.sh脚本： `ab -c 6 -n 6 http://localhost/limit sleep 1 ab -c 6 -n 6 http://localhost/limit sleep 0.3 ab -c 6 -n 6 http://localhost/limit sleep 0.3 ab -c 6 -n 6 http://localhost/limit sleep 0.3 ab -c 6 -n 6 http://localhost/limit sleep 2 ab -c 6 -n 6 http://localhost/limit`将得到类似如下access.log输出： `[09/Jun/2016:14:30:11+0800] [1465453811.754] 200 [09/Jun/2016:14:30:11+0800] [1465453811.755] 200 [09/Jun/2016:14:30:11+0800] [1465453811.755] 200 [09/Jun/2016:14:30:11+0800] [1465453811.759] 200 [09/Jun/2016:14:30:11 +0800][1465453811.759] 503 [09/Jun/2016:14:30:11 +0800][1465453811.759] 503 [09/Jun/2016:14:30:12+0800] [1465453812.776] 200 [09/Jun/2016:14:30:12+0800] [1465453812.776] 200 [09/Jun/2016:14:30:12 +0800][1465453812.776] 503 [09/Jun/2016:14:30:12 +0800][1465453812.777] 503 [09/Jun/2016:14:30:12 +0800][1465453812.777] 503 [09/Jun/2016:14:30:12 +0800][1465453812.777] 503 [09/Jun/2016:14:30:13 +0800] [1465453813.095]503 [09/Jun/2016:14:30:13 +0800][1465453813.097] 503 [09/Jun/2016:14:30:13 +0800][1465453813.097] 503 [09/Jun/2016:14:30:13 +0800][1465453813.097] 503 [09/Jun/2016:14:30:13 +0800][1465453813.097] 503 [09/Jun/2016:14:30:13 +0800][1465453813.098] 503 [09/Jun/2016:14:30:13+0800] [1465453813.425] 200 [09/Jun/2016:14:30:13 +0800][1465453813.425] 503 [09/Jun/2016:14:30:13 +0800][1465453813.425] 503 [09/Jun/2016:14:30:13 +0800][1465453813.426] 503 [09/Jun/2016:14:30:13 +0800][1465453813.426] 503 [09/Jun/2016:14:30:13 +0800][1465453813.426] 503 [09/Jun/2016:14:30:13+0800] [1465453813.754] 200 [09/Jun/2016:14:30:13 +0800][1465453813.755] 503 [09/Jun/2016:14:30:13 +0800][1465453813.755] 503 [09/Jun/2016:14:30:13 +0800][1465453813.756] 503 [09/Jun/2016:14:30:13 +0800][1465453813.756] 503 [09/Jun/2016:14:30:13 +0800][1465453813.756] 503 [09/Jun/2016:14:30:15+0800] [1465453815.278] 200 [09/Jun/2016:14:30:15+0800] [1465453815.278] 200 [09/Jun/2016:14:30:15+0800] [1465453815.278] 200 [09/Jun/2016:14:30:15 +0800][1465453815.278] 503 [09/Jun/2016:14:30:15 +0800][1465453815.279] 503 [09/Jun/2016:14:30:15 +0800][1465453815.279] 503 [09/Jun/2016:14:30:17+0800] [1465453817.300] 200 [09/Jun/2016:14:30:17+0800] [1465453817.300] 200 [09/Jun/2016:14:30:17+0800] [1465453817.300] 200 [09/Jun/2016:14:30:17+0800] [1465453817.301] 200 [09/Jun/2016:14:30:17 +0800][1465453817.301] 503 [09/Jun/2016:14:30:17 +0800][1465453817.301] 503` 桶容量为3（，即桶中在时间窗口内最多流入3个请求，且按照2r/s的固定速率处理请求（即每隔500毫秒处理一个请求）；桶计算时间窗口（1.5秒）=速率（2r/s）/桶容量(3)，也就是说在这个时间窗口内桶最多暂存3个请求。因此我们要以当前时间往前推1.5秒和1秒来计算时间窗口内的总请求数；另外因为配置了nodelay，是非延迟模式，所以允许时间窗内突发请求的；另外从本示例会看出两个问题： 第一轮和第七轮：有4个请求处理成功了；这是因为计算算法的问题，本示例是如果2秒内没有请求，然后接着突然来了很多请求，第一次计算的结果将是不正确的；这个问题影响很小可以忽略； 第五轮：1.0秒计算出来是3个请求；此处也是因计算精度的问题，也就是说limit_req实现的算法不是非常精准的，假设此处看成相对于2.75的话，1.0秒内只有1次请求，所以还是允许1次请求的。 如果限流出错了，可以配置错误页面： `proxy_intercept_errors on; recursive_error_pages on; error_page 503 //www.jd.com/error.aspx;`limit_conn_zone/limit_req_zone定义的内存不足，则后续的请求将一直被限流，所以需要根据需求设置好相应的内存大小。 此处的限流都是单Nginx的，假设我们接入层有多个nginx，此处就存在和应用级限流相同的问题；那如何处理呢？一种解决办法：建立一个负载均衡层将按照限流KEY进行一致性哈希算法将请求哈希到接入层Nginx上，从而相同KEY的将打到同一台接入层Nginx上；另一种解决方案就是使用Nginx+Lua（OpenResty）调用分布式限流逻辑实现。 lua-resty-limit-traffic之前介绍的两个模块使用上比较简单，指定KEY、指定限流速率等就可以了，如果我们想根据实际情况变化KEY、变化速率、变化桶大小等这种动态特性，使用标准模块就很难去实现了，因此我们需要一种可编程来解决我们问题；而OpenResty提供了lua限流模块lua-resty-limit-traffic，通过它可以按照更复杂的业务逻辑进行动态限流处理了。其提供了limit.conn和limit.req实现，算法与nginx limit_conn和limit_req是一样的。 此处我们来实现ngx_http_limit_req_module中的【场景2.2测试】，不要忘记下载lua-resty-limit-traffic模块并添加到OpenResty的lualib中。 配置用来存放限流用的共享字典： `lua_shared_dict limit_req_store 100m;`以下是实现【场景2.2测试】的限流代码limit_req.lua： `local limit_req = require &quot;resty.limit.req&quot; local rate = 2 --固定平均速率 2r/s local burst = 3 --桶容量 local error_status = 503 local nodelay = false --是否需要不延迟处理 local lim, err = limit_req.new(&quot;limit_req_store&quot;, rate, burst) if not lim then --没定义共享字典 ngx.exit(error_status) end local key = ngx.var.binary_remote_addr --IP维度的限流 --流入请求，如果请求需要被延迟则delay &gt; 0 local delay, err = lim:incoming(key, true) if not delay and err == &quot;rejected&quot; then --超出桶大小了 ngx.exit(error_status) end if delay &gt; 0 then --根据需要决定是延迟或者不延迟处理 if nodelay then --直接突发处理了 else ngx.sleep(delay) --延迟处理 end end`即限流逻辑再nginx access阶段被访问，如果不被限流继续后续流程；如果需要被限流要么sleep一段时间继续后续流程，要么返回相应的状态码拒绝请求。 在分布式限流中我们使用了简单的Nginx+Lua进行分布式限流，有了这个模块也可以使用这个模块来实现分布式限流。 另外在使用Nginx+Lua时也可以获取ngx.var.connections_active进行过载保护，即如果当前活跃连接数超过阈值进行限流保护。 `if tonumber(ngx.var.connections_active) &gt;= tonumber(limit) then //限流 end`nginx也提供了limit_rate用来对流量限速，如limit_rate 50k，表示限制下载速度为50k。 限流用法介绍完，这些算法中有些允许突发，有些会整形为平滑，有些计算算法简单粗暴；其中令牌桶算法和漏桶算法实现上是类似的，只是表述的方向不太一样，对于业务来说不必刻意去区分它们；因此需要根据实际场景来决定如何限流，最好的算法不一定是最适用的。 参考资料https://en.wikipedia.org/wiki/Token_bucket https://en.wikipedia.org/wiki/Leaky_bucket http://redis.io/commands/incr http://nginx.org/en/docs/http/ngx_http_limit_req_module.html http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html https://github.com/openresty/lua-resty-limit-traffic http://nginx.org/en/docs/http/ngx_http_core_module.html#limit_rate","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.ithelei.com/categories/Nginx/"},{"name":"限流","slug":"Nginx/限流","permalink":"http://www.ithelei.com/categories/Nginx/限流/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.ithelei.com/tags/Nginx/"},{"name":"限流","slug":"限流","permalink":"http://www.ithelei.com/tags/限流/"}]},{"title":"MySQLdump备份所有数据库","slug":"MySQLdump备份所有数据库","date":"2020-02-25T13:45:00.000Z","updated":"2020-02-25T14:46:46.321Z","comments":true,"path":"2020/02/25/MySQLdump备份所有数据库/","link":"","permalink":"http://www.ithelei.com/2020/02/25/MySQLdump备份所有数据库/","excerpt":"","text":"MySQLdump备份所有数据库`mysqldump -h192.168.1.112 -u -p --opt --all- databases --default-character-set=gbk|utf8|latin1 &gt; source /db_back/db_name.sql`MySQLdump备份多个数据库`mysqldump -h192.168.1.112 -u -p --opt -- databases --default-character-set=gbk|utf8|latin1 db1 db2 db3&gt; source /db_back/db_name.sql`mysqldump","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MySQL命令恢复mysqldump备份的数据库","slug":"MySQL命令恢复mysqldump备份的数据库","date":"2020-02-25T13:45:00.000Z","updated":"2020-02-29T10:31:32.937Z","comments":true,"path":"2020/02/25/MySQL命令恢复mysqldump备份的数据库/","link":"","permalink":"http://www.ithelei.com/2020/02/25/MySQL命令恢复mysqldump备份的数据库/","excerpt":"","text":"语法 mysql -u 用户名 -p 密码 -h 主机 数据库 &lt;路径 注意：恢复要使用mysql.exe命令 实例首先备份一个数据库，然后创建一个新的数据库，最后将备份的数据库恢复到新的数据库中。 表结构+数据+函数+存储过程 mysqldump -hlocalhost -uroot -proot --opt -R --default-character-set=gbk db_fcms &gt; d:/mysql_dbbk/db_fcms_bf_1.sql 创建一个新的数据库，取名为db_fcms_hf. crate database if not exists db_fcms_hf default set utf-8 collage utf8_general_ci 试试恢复 恢复要用mysql.exe命令恢复mysqldump文件 `mysql -uroot -proot -hlocalhost --default-character-set=gbk db_fcms_hf &lt; d:/mysql_dbbk/db_fcms_bf_1.sql`","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MySQL备份与恢复","slug":"MySQL备份与恢复","date":"2020-02-25T13:45:00.000Z","updated":"2020-02-25T13:41:38.177Z","comments":true,"path":"2020/02/25/MySQL备份与恢复/","link":"","permalink":"http://www.ithelei.com/2020/02/25/MySQL备份与恢复/","excerpt":"","text":"mysql数据备份的多种操作手段数据备份时保证数据安全的最后一道屏障，当出现服务器损坏，数据库已经无法在启用时，在这一时刻，数据库备份特别重要，可以将损失降到最低；加入没有备份，那后果将不堪设想。 使数据库的失效次数减到最少，从而使数据库保持最大的可用性。 当数据库失效后，恢复时间减到最小，使恢复效益达到最高。 当数据库失效后，确保尽量减少数据丢失或者不丢失。 mysqldump常用命令导出某个数据库 ，结构+数据`mysqldump -hlocalhost -u -p --opt --default-character-set=gbk|utf8|latin1 db_name &gt; source/db_bakup/db_name.sql`localhost 为服务器ip地址 -u 数据库的账户名 -p 用户密码 –default-character-set=gbk|utf8|latin1 设定文件导出字符集 source/db_bakup/db_name.sql 导出文件存放位置 导出某个数据库的表，结构+数据+函数+存储过程`mysqldump -hlocalhost -u -p --opt -R --default-character-set=gbk|utf8|latin1 db_name &gt; source/db_bakup/db_name.sql`导出多个数据库 mysqldump -hlocalhost -u -p --opt - databases --default-character-set=gbk|utf8|latin1 &gt; source/db_bakup/db_name.sql 导出所有数据库`mysqldump -hlocalhost -u -p --opt --all- databases --default-character-set=gbk|utf8|latin1 db_name1 db_name2 db_name3 &gt; source/db_bakup/db_name.sql`导出某个数据库的结构`mysqldump -hlocalhost -u -p --opt --no-data db_name &gt; source/db_bakup/db_name.sql`导出某个数据库的数据`mysqldump -hlocalhost -u -p --opt --no-create-info --default-character-set=gbk|utf8|latin1 db_name &gt; source/db_bakup/db_name.sql`导出某个数据库的某张表`mysqldump -hlocalhost -u -p --opt --default-character-set=gbk|utf8|latin1 db_name tb1_name &gt; source/db_bakup/db_name.sql`导出某个数据库的某张表结构`mysqldump -hlocalhost -u -p --opt --no-data db_name ta1_name&gt; source/db_bakup/db_name.sql`导出某个数据库的某张表的数据`mysqldump -hlocalhost -u -p --opt --no-create-info --default-character-set=gbk db_name ta1_name&gt; source/db_bakup/db_name.sql`跨主机备份数据库`mysqldump -hlocalhost1 -u -p --opt -R --default-character-set=gbk/utf8/latin1 sourcedb | mysql -hlocalhost2 -u -p -C --default-character-set=gbk/utf8/latin1 targetdb`","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"一个复杂的团队合作事件","slug":"星球_一个复杂的团队合作事件","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-24T15:11:26.142Z","comments":true,"path":"2020/02/24/星球_一个复杂的团队合作事件/","link":"","permalink":"http://www.ithelei.com/2020/02/24/星球_一个复杂的团队合作事件/","excerpt":"","text":"一，沟通这个事情可以做得更好。 比如 A 的做事理念跟数据，跟工程的同学不一致，如果就事论事地讨论，可能大家谁都无法说服谁。 我的建议是，可以找时间跟他们吃吃饭或喝杯咖啡什么的。 拉近私人关系，总可以使这种事情往正向的方向发展。 二，要有大局观，要考虑整体情况。 有主人翁意识，愿意推动事情是好的，但如果确实推不动，也不能退回来，想着自己一个人扛。 不是说这种想法不好，而是个人能力终究有限，这么做掩盖了问题，最终极有可能造成项目的失败。 三，A应该要对整个事情更有信心。 虽然说服他们不容易，但也不应该轻易放弃，而应该想更多的办法，实在不行，可以将问题上升，我作为上级，可以一起去沟通这个事情。 四，职场中，出现了其他同事对自己的负面反馈，一定要及时关注。 看是自身的原因，还是他人的原因，还仅仅只是一种误解。如果不关注，任其发展，很容易陷入不可挽回的局面。 最后 从这次 A 的事情来看，职场，团队合作，确实还蛮复杂的。 有些事情，不是一眼就可以看得清楚，需要多方沟通，并且花时间，仔细地去梳理其中的来龙去脉，分析本质的原因。 只有找到了事情的根源，才有可能把事情解决好。","categories":[{"name":"心理建设","slug":"心理建设","permalink":"http://www.ithelei.com/categories/心理建设/"}],"tags":[{"name":"心理建设","slug":"心理建设","permalink":"http://www.ithelei.com/tags/心理建设/"}]},{"title":"you are your time","slug":"星球_沈剑you are your time","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-24T15:26:56.550Z","comments":true,"path":"2020/02/24/星球_沈剑you are your time/","link":"","permalink":"http://www.ithelei.com/2020/02/24/星球_沈剑you are your time/","excerpt":"","text":"you are your time 很多时候，我们都认为自己没有选择，或者被迫选择。 选择了工作，就没法立刻回家；选择了聚会，就没办法陪孩子；选择了看电视剧，就没办法看书。 其实，无形之中，我们做了自己的选择：在一些人的内心，工作比家庭重要，友情比亲情重要，娱乐比学习重要。 每个人的价值观不同，选择自然不同，无所谓对错，外人不用去“judge”它。 做自己就好，you are your time 职场","categories":[{"name":"职场","slug":"职场","permalink":"http://www.ithelei.com/categories/职场/"}],"tags":[{"name":"职场","slug":"职场","permalink":"http://www.ithelei.com/tags/职场/"}]},{"title":"前端和技术天花板","slug":"星球_前端和技术天花板","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-24T15:02:25.150Z","comments":true,"path":"2020/02/24/星球_前端和技术天花板/","link":"","permalink":"http://www.ithelei.com/2020/02/24/星球_前端和技术天花板/","excerpt":"","text":"进入移动互联网时代后，前端岗位的需求应该是在下降的。原因显而易见，因为用户的时间都消耗在移动端，消耗在APP上了。 前端市场开始慢慢被客户端市场吞噬。 不过这几年，又显现出了大前端的趋势，有点山水轮流转的感觉。(当然，大前端跟前端有很大不同） 客观来说，前端的天花板是比后台低，就整个技术岗位来说，天花板算排在中上吧。 不过，前端有个独特的优势： 跟产品很接近。前端对交互细节，对产品细节的了解，有时候比产品经理还多。 我接触过的一些前端，最后有不少转岗做了产品，目前小程序的产品负责人，就是前端出身的。 其实每个技术方向的天花板是天然存在的。 就技术层面来说，你通过自身的努力，可以提高自己的技术能力，但最后能够达到的技术高度，除了天赋，努力，也跟方向有关。 我心中的天花板排名： 人工智能（包含数据科学家这种岗位） &gt; 信息安全 &gt; 后台开发 &gt; 客户端开发 &gt; 前端开发 &gt; 数据分析 &gt; 运营开发 &gt; 测试开发(白盒测试) &gt; IT运维 &gt; 黑盒测试。 以上只是我个人观点哈，另外个体是会有特例的，这个排名只是整体来看的。 当然，以上仅是技术天花板排名。 现实中，你最终所取得的成就，赚钱的多少，技术能力只是其中一个因素，并不是全部，还会包括管理能力，业务能力等等。 所以天花板相对低的技术方向的同学，也不用焦虑。 1 相对低，也不是那么容易就能够达到的，当你真达到了你技术方向的天花板再说。 2 工作能力不是单一技术能力，而是各种能力的整合，天花板相对低方向的同学，可以注意多培养除技术之外的能力。 3 如果后期发展确实遇到瓶颈，可以根据方向优势，进行转岗。比如前端转到产品，这是一种天然优势，后台转产品就会相对较难。 4 对于新人，选择方向，建议首先考虑自身喜好，然后再考虑现实情况。因为很多人最终不是停止在了天花板前，而是自己先失去了动力。","categories":[{"name":"心理建设","slug":"心理建设","permalink":"http://www.ithelei.com/categories/心理建设/"}],"tags":[{"name":"心理建设","slug":"心理建设","permalink":"http://www.ithelei.com/tags/心理建设/"}]},{"title":"如何度过自己平淡无奇的青春","slug":"星球_如何度过自己平淡无奇的青春","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-24T15:07:44.024Z","comments":true,"path":"2020/02/24/星球_如何度过自己平淡无奇的青春/","link":"","permalink":"http://www.ithelei.com/2020/02/24/星球_如何度过自己平淡无奇的青春/","excerpt":"","text":"首先，纠正一个问题，平淡无奇是相对的。相对那些伟人，时代的引领者，普通人的青春确实平淡，但相对自己，相对自己周边的人，每个人的青春都是多彩的，充满激情的！1 目标 目标必须有！ 小时候，我们会说自己的理想是当个科学家，宇航员，虽然理想已经远去，但人生的目标还是应该有。 大部分人，人生80%的时间，都是处于迷茫的状态。人之所以迷茫，就是因为缺失了目标。 一个目标，可以是专业技能的提升，可以是升职加薪，可以是一套房子，一辆豪车，一笔通向生活自由的存款….. 目标无所谓高尚与庸俗，毕竟大家都只是普通人，但目标一定要有！ 有目标，才不会迷; 有目标，才会有动力; 有目标，才会有生命的活力！ 2 激情 我不喜欢太丧的年轻人。 那些人觉得人生没有意义，所有的努力最后都会随着生命的逝去，而成为泡影，但活着，经历更多彩的生活，本身就是一种意义！ 我们不用面对战争，温饱问题已经基本解决，相对来说，这是这个不错的时代。 生于这个和平的时代，已经要幸运过很多人，那何必浪费了这么好的运气呢？ 生活需要激情，工作需要激情，人生也需要激情！ 有激情的人，会活得更开心，工作得更顺利，也会有更多的精彩和好运！ 3 耐心 人的坚持，人的耐力，是被慢慢培养起来的。 相比以前，我觉得自己更有耐心了。 刚出来工作的时候，做一件事情，学一样新的技术，都希望能够立马得到正面的反馈。 随着经历的增加，年岁的增长，自己的耐心似乎越来越好，可以等待半年，一年，甚至更长的时间。 如果你觉得自己平淡无奇，没有突出的智力，八面玲珑的情商，我觉得在年轻的时候，不断培养自己的耐心是一个不错的选择。 假以时日，这份超长的耐心，会使你与众不同！ 4 惜时 刚毕业或工作几年后，有不少人会陷入迷茫。 这个其实是正常的状态，很多人都如此。 而如何应对这种状态，决定了自己未来人生的走向。 有人心在迷茫，人也在迷茫，不行动，把时间浪费在抖音，微博上，期待自己脑瓜一闪，就找到新的方向。以我多年的经验，越是这么做，人会越迷茫！ 人之所以迷茫是因为，对自己，对社会了解不足。 所以，要么看书学习，增进对自己的了解；要么出去看看，增进对社会的了解！ 浪费时间是最不可取的！ 5 挫折 问我过去十年，给我带来最大成长的是什么？ 我会说是 : 挫折！ 知识，方法都可以从书本上获得，但心态和经验更多来自实践！ 挫折，是最有价值的实践！ 可能你目前过得艰难，可能你目前面临的压力巨大，但同时也想想，渡过之后，你将可能获得巨大的成长！ 年轻时候的挫折，是一笔宝贵的人生财富！ 最后 岁月无情，年轻就是最大的一笔财富，因为它蕴含着希望和无限的可能。 希望大家在三十，四十，回望自己过往的十年，二十年的时候，都可以不留遗憾！","categories":[{"name":"心理建设","slug":"心理建设","permalink":"http://www.ithelei.com/categories/心理建设/"}],"tags":[{"name":"心理建设","slug":"心理建设","permalink":"http://www.ithelei.com/tags/心理建设/"}]},{"title":"我不会，但我可以学","slug":"星球_沈剑我不会，但我可以学","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-24T15:35:15.377Z","comments":true,"path":"2020/02/24/星球_沈剑我不会，但我可以学/","link":"","permalink":"http://www.ithelei.com/2020/02/24/星球_沈剑我不会，但我可以学/","excerpt":"","text":"“我不会，但我可以学” 一个case。 运营提了一个紧急的需求，做一个活动落地页，实在抽不出来人手，于是安排了一个同学对接。 新同学非常认真负责，和产品运营沟通需求，做技术方案设计。 技术方案评完，新同学来找我：“有很少前端交互的js代码，能不能安排一个FE同事支持项目？” “只有少量的交互，你自己做呢？” “我不会” … 另一个case。 一个项目总结会结束，我让助理同学帮忙发一下纪要。 纪要需要从MySQL里取一些数，我怕她搞不定，问她“SQL会不会？” “我可以学” … 路是人选的，很大程度上，你的态度决定你今后到达的高度。 这个浮躁的社会，只要态度端正，足够努力，很多时候，根本轮不到拼智商。 #职场#","categories":[{"name":"职场","slug":"职场","permalink":"http://www.ithelei.com/categories/职场/"}],"tags":[{"name":"职场","slug":"职场","permalink":"http://www.ithelei.com/tags/职场/"}]},{"title":"危机感","slug":"星球_沈剑职场","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-24T15:26:15.610Z","comments":true,"path":"2020/02/24/星球_沈剑职场/","link":"","permalink":"http://www.ithelei.com/2020/02/24/星球_沈剑职场/","excerpt":"","text":"有时候我会想，如果公司把我换掉，我的团队会不会变得更好。 这样的想法，会立刻消灭我内心的所有沾沾自喜，并让自己立刻有了危机感。 持续学习，持续进步，共勉。 职场","categories":[{"name":"职场","slug":"职场","permalink":"http://www.ithelei.com/categories/职场/"}],"tags":[{"name":"职场","slug":"职场","permalink":"http://www.ithelei.com/tags/职场/"}]},{"title":"比能力更重要的，是你的底层操作系统","slug":"星球_沈剑比能力更重要的，是你的底层操作系统","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-24T15:29:58.052Z","comments":true,"path":"2020/02/24/星球_沈剑比能力更重要的，是你的底层操作系统/","link":"","permalink":"http://www.ithelei.com/2020/02/24/星球_沈剑比能力更重要的，是你的底层操作系统/","excerpt":"","text":"“比能力更重要的，是你的底层操作系统” 什么是普通人？就是快乐没有那么强烈，痛苦也没有那么巨大。所以，他们的人生会在既定的轨道上相对平衡地运行，而不是被快乐和痛苦牵引撕扯，没完没了地折腾。 什么叫有一技之长的人？就是当他在沉下来做某件事的时候，他不厌其烦，乐在其中，完全不理会别人的差异或者不理解。 什么是杰出的人？就是如果他想要的那个，他得不到，他就像万蚁噬心那样痛苦。牺牲什么都可以，他必须得到他想要的那个东西。 如果你赚到了1000万，你有多快乐？ 来自湖畔大学梁宁：https://mp.weixin.qq.com/s/lzxe-9sufcruCn8IsVUfcQ 人生","categories":[{"name":"人生","slug":"人生","permalink":"http://www.ithelei.com/categories/人生/"}],"tags":[{"name":"人生","slug":"人生","permalink":"http://www.ithelei.com/tags/人生/"}]},{"title":"程序员心理建设","slug":"星球_程序员心理建设","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-24T14:54:25.010Z","comments":true,"path":"2020/02/24/星球_程序员心理建设/","link":"","permalink":"http://www.ithelei.com/2020/02/24/星球_程序员心理建设/","excerpt":"","text":"工作是属于公司的，而职业生涯却是属于你自己的！ 你所能犯的最大错误就是相信自己是在为别人工作。这样一来你对工作的安全感已然尽失。职业发展的驱动力一定是来自个体本身。记住：工作是属于公司的，而职业生涯却是属于你自己的。–厄尔·南丁格尔 摘自《软技能：代码之外的生存指南》 这句话说得很有道理，它阐明了工作和职业发展的理念，也使得工作本身被上升到了一个更高的层次。 理念的改变能促使行为模式的改变。我相信这句话，这个理念也能起到这个作用。 这句话阐述了一种更高层次的对待工作，对待职业，对待自身发展的方式，但只是阐明了这种理念，没有给出实际可执行的方法，这里我来说说我的理解和建议： 1 把技术能力当作一个产品来打造 作为技术人员，作为一个程序员，你最好的产品就是你的技术能力。技术能力是伴随你整个职业生涯的，不是在一间公司或两间公司待完就结束了，技术能力地升级打造是一个持续的过程，你也会从中持续地获益。 当把自身的技术能力当作一个产品来打造，你就不会再拘泥于公司的环境。面对每天的 CRUD的时候，你不会一直在纠结要不要继续待在这间公司，而是会从自身的成长考虑，是不是要以 CRUD 作为切入点深入下去，去挖掘背后的东西，去一窥背后那巨大的冰山，丰富自己的经验和见识。 当把自身的技术能力当作一个产品来打造，你的眼界会更加开阔，你不会再纠结，是不是要学好算法，数据结构这些短期内看不到成效的东西，你会放眼去看更广阔的世界。 你会发现那些正真的技术牛人，他们的技术能力都是建立在良好基础知识和基础能力之上的，只有这样打造出来的技术能力才是坚实，可靠的。 应该为了短期的工作目标先去学习急用的知识，但你依然会牢记基础知识和基础能力才是技术最核心的竞争力。 把技术能力当作一个产品来打造，你就会精心地雕琢它，打造他，会持续地改进，持续地升级，像维护一个伟大的产品一样。 2 贯穿整个人生的职业生涯 当记住 工作是属于公司，而职业生涯是属于自己的时候，你内心的焦虑会被极大地缓解。 你可以把自己当作一个公司来运作，你所有的技能就是你这间独特公司的产品，它们都是可以升级迭代的。 当把自己当作一间公司来运作的时候，你会有更长远的规划，你不一定能立马想清楚自己的长远目标和各个阶段的里程碑，但你会开始有意识去思考这个事情。 比如自己做技术要做到什么阶段？在这过程中，自己想要获得什么？钱？声誉？社会地位？更高级的圈子？。 过了一个年龄段，你不再想从事技术的时候，你又会想做什么？比如产品？市场？创业？ 要知道这个不是简单的切换，这是一种延续，有技术背景的产品，有技术背景的销售，有技术背景的创业者，这些都是技术的加成，是你无可比拟的优势，也是技术人员后期发展的优势。 你不知道现在很多的产品同学都希望自己懂技术，有技术背景，因为这样能提高他们的职业天花板，程序员天然具有这个优势，更应该善加利用。 你也可以把自己当成一个稀缺的技术专家来运作，自身技术的精专，稀缺，配合上一些软能力，你也会是极富竞争力的。 高级技术人员的职业生涯是可以很长的，特别是给广大程序员们制造轮子的程序员，估计永远不会失业。他们也可以一直用技术来换取牛奶和面包，直到他们自己想停下来。 3 更广阔的视野 当你把工作当作是公司的，而职业生涯当成是自己的时候，你会有更广阔的视野和更长远的规划。 你会开始去思考，自己是不是要一直做技术，如果是，自己的技术发展目标是怎样的，自己会走过哪些路径，自己可以参照的前辈有哪些。 有了这种更长远的规划，你就会开始思考更多的事情，你会开始去了解你的前辈，去了解他们的经历和发展，结合自身的情况去做比对，去重新了解和不断地调整自身的规划。 如果你的目标一开始就不是一直做技术，而把技术当成是一个敲门砖或者踏板，那也是可以的 。 这个时候，你也应该看得更广，看得更远。 你应该要思考，把技术做到一个什么程度是可以的，技术生涯结束后，下一阶段的事情怎么来衔接。 有很多前人的发展路径可以参考。 比如技术转产品，技术转销售等，都是很正常的职业发展路径，事先的了解，规划，并做适当的准备，可使得你不会犹豫不决，也不会畏畏缩缩，在规划的时间节点到了之后，就坚决地去执行，去转换。 4 安定的内心和长期的坚持 现今的大家都很容易焦虑，焦虑公司的运作，焦虑工作岗位。 竞争无处不在，焦虑很多时候都不可避免。 当了解到职业生涯是属于自己的时候，我觉得一个人的焦虑可以缓解很多。 你会渐渐地明白，一个人的职业生涯是可以很长的。 或许一般程序员的职业生涯就是40岁吧（高级的除外），但你的职业生涯不是。 因为除了技术，你依然可以做很多其它的事情。构建于技术能力基础上的第二波甚至第三波事业，会是你独特的竞争力，是没有技术背景的人士所不具有的竞争力。充分地利用这个特点，能给自身的职业发展带来很大的助益甚至是独特的成功。 当你去思考这个问题，对这个属于自己的职业生涯好好地斟酌，反复地思考，你可能会有惊喜的发现。 思考它，想清楚它，当最关键，最核心的东西被想清楚的时候，你内心的焦虑自然可以慢慢缓解下来，你做事情会更有耐心，也能慢慢摒弃急功近利的心理。 当其他人还在一味的焦虑，而你经过自己的思考和摸索找到合适自己的方向的时候，你会变得从容淡定，你自己也会在这场竞争中慢慢脱颖而出，所谓慢就是快。 结语 工作是属于公司的，而职业生涯却是属于你自己的。这句话细细地斟酌起来，确实能改变一个人对待工作，对到职业的思维方式。 你会变因此变得更加乐观，主动，会看得更加长远，也愿意为更长远的事情做准备。 与其一味的焦虑，纠结，原地打转，还不如真正的把职业生涯当作是自身的东西。对属于自己的东西，你总是会更加的爱护，更加的愿意付出心血去维护它，去雕琢它，使它变得更加的完善和美好！ #程序员心理建设#","categories":[{"name":"心理建设","slug":"心理建设","permalink":"http://www.ithelei.com/categories/心理建设/"}],"tags":[{"name":"心理建设","slug":"心理建设","permalink":"http://www.ithelei.com/tags/心理建设/"}]},{"title":"马云接班人的10条法则，最起码你能做到最后一条","slug":"马云接班人的10条法则，最起码你能做到最后一条","date":"2020-02-24T01:20:45.000Z","updated":"2020-02-29T13:32:57.321Z","comments":true,"path":"2020/02/24/马云接班人的10条法则，最起码你能做到最后一条/","link":"","permalink":"http://www.ithelei.com/2020/02/24/马云接班人的10条法则，最起码你能做到最后一条/","excerpt":"","text":"在成为阿里巴巴CEO之前，张勇曾经是著名会计师事务所的审计，纳斯达克上市公司的首席财务官。但是，相较于那些拥有无数传说的商业领袖，讲究严谨的张勇是一个没有故事的人，连他自己都会在访谈中自嘲无趣，「我讲的都是干巴巴的事情」。 然而，正是这个没有传说的人，创造了一个个新的商业传说。加入阿里巴巴后，他担任过淘宝网首席财务官、首席运营官，后来将天猫几乎从无到有做到今天全球品牌最为青睐的平台，创立了双11购物狂欢节，并逐年将其打造成全球最大的网购狂欢节。他还全面负责阿里巴巴国内、国际业务运营，推动了阿里巴巴成功的移动转型，建立全球物流网络，甚至还主导了许多重要的战略投资。 总是冷静理性的张勇正在给商业生态输入影响，大到生态构建，小到组织结构，他都将自己的工作方式融入其中。连创始人马云都会私下跟他说，似乎自从你来了以后，我们连开会的感觉都不一样了。 那么，这样一个人的成功法则是什么？以下就是他从未在公开场合透露过的独家秘笈。 法则一：投资房子不如投资自己 我来杭州9年了，一直住在酒店里。有次跟苏宁的CEO吃饭，大家聊到房产的事情，因为杭州房价这些年涨了好多，很多人都买房投资。可是我从来没有想过要买房子，我没那功夫。最好的投资不是房子，而是投资自己，所有创新原动力都来自于自己，要不断地挑战自我。 法则二：开会就是捅刀子 我开会的风格是这样的——跟我开会前，所有人的PPT全都发过来。我始终相信，获取信息可以很高效，而开会是其中最差劲的办法。我可以在会议前获得足够的信息输入，而开会时间主要用来讨论、争论、做决定，我管它叫作「捅刀子」。 一般我会先随机问个问题，「随便捅一刀」，看看这个人有没有想法。一刀进去不见血，那很好，说明他准备好了；换个人，一刀进去就见血，说明到处都是洞，问完一个问题我会继续问第二个第三个，捅到体无完肤为止。 每个会议都必须要有会议纪要，也必须要有行动点，或者说决策。没有行动点的会议就不要开了。讲道理的务虚会一年一两次是需要的，但更多日常会议不必分享信息，直接「捅刀子」，捅完刀子大家争论，来做决定就好了。 法则三：正确的KPI考核是一场乘数化分解 在手机淘宝，我们早就不考核GMV（总交易额）了，因为这种KPI分解方式是一种简单化的线性分解。不同的人分工不同，KPI是不一样的，有的人必须考核转化率，有的人必须考核互动性。所以我们考核用户市场的变化，像是每天的访问数、参与互动频率等等。这是一个多元化的乘数化效应，不应该把所有员工统一一个标准来考核。 法则四：敢做不完美的决定 我每天都在面对艰难的抉择，因为容易的决定都轮不到我来做，能够走到我这儿的决定都具有挑战性，甚至可能引发争议。即便如此，总要有人做出判断，决定一下。我们管这个叫做「拍一下」。敢不敢拍一下，这很重要。 对所有团队来讲，他们怕的不是做错决定，做错了可以改，最怕的是不做决定。所以，要敢于做不完美的决定。有些决定无所谓对错，可能事后分析两边都有道理，所谓条条大路通罗马，只要坚持，可能都能做到。但总要选一条路，不然整个团队就没办法往前走了。 法则五：用「重新定义」思考万物 iPhone重新定义了手机，让全世界都习惯于它的大屏幕触摸式设计。这个故事我大概反复讲过不下十次，这是我非常喜欢的一个例子。因为既然iPhone能重新定义手机，很多东西都可以重新定义。我们现在需要的不是通过分析人过去的行为预测未来，而是像曾经的iPhone一样杀出一条谁都没见过的路，重新定义未来的新事物。好的东西即便没有过去，也有未来。 这是我反复讲的另一个词，「重构」。举个例子说，今天中国的购物中心长得都一样，一楼化妆品顶楼特卖会，可为什么女孩子逛百货商场必须要一间一间店去看呢？为什么不能一类品牌一起看？为什么不能有电子货架？重构就是将所有商业元素重新组织，赋予它们新的定义。 如果没有商业元素的重构，简单的1+1没有办法起到大于2的效果，顶多等于2，甚至小于2。所以，一定要创造乘数效应，发生化学反应，才能产生新的事物。今天的时代已经从满足需求转变到创造需求，这种重新定义就是去激发用户原有潜意识里未被发掘的消费领地。 法则六：不要迷信数字的成功 一直以来我们对于成功的评价标准很简单，一个数字就代表了一个规模化的标准，但是现在所有领域都需要一个新的衡量标尺。 像是现在每年双11大家最关注的还是最终成交额。每年都有人让我预测数字，但我从来不说，不光外面不说，内部我也不说，马老师（马云）问我我也不说。我的口头禅是，「做庄的从来不下注」。 我觉得总有一天大家会明白，数字不是一切。今年双十一快到12点结束之前，大屏幕上的数字一度到了1188（亿元），我觉得这个数字就挺好的了。2012年我们的总交易流水达到人民币191亿元，很多人事后跟我说，你稍微加把劲就是200亿，但我觉得留一些遗憾也没什么不好。每个人心里都有一个对成功的判断标准，而对我来说，关键的是有多少东西能够沉淀在商业常态中，这个很重要。 很多时候外界也会用股价涨跌来衡量CEO的工作好坏，但对我来说，这个数字也不重要。要是我每天看着股价，这事就没法弄了，做什么决定都是错的。事实上，股价低的时候未必像人家想象中那么糟糕，股价翻倍的时候也未必如想象中那么好。我觉得更重要的是，承认市场是一个过程，接受这个过程，并始终坚信，最终衡量成功的标准不是这个起伏的过程，而是你所创造的长期价值。而这个长期价值的衡量标准，不应该是一个数字。 法则七：保持快速行动力 在无线时代，快速、简练的小团队才能实现最佳结果。因为面对瞬息万变的商业生态，我们需要保持快速行动力，能够更快速、更锋利地做决定。快速行动力来自不断根据第一线情况进行灵活决策。如果淮海战役没有总决定权，粟裕是不可能赢的。要是什么事情都要电报延安，机会就错过了。必须给战区一线指挥员更多随机应变的权力，更多创新的自由。 在组织设计上，应该尽量避免不必要的协同，避免共同目标不一致的协同。两个人目标终点都不一样，左脚右脚绑在一起跑，怎么可能跑得到终点？我们要尽可能创造一个简单的做事氛围，能一个部门解决的问题不要搞成两个部门决定，更不要搞成十个部门决定，让听得到炮火声的一线指挥官全权做决定。 事实上，互联网时代给管理宽度带来了新的可能性。现在人的沟通可以变成高效率的网状结构。像是今年的双11指挥部，来来回回不超过十个人，里面有总裁也有VP，还有基层员工。并不是说VP一定要在指挥部里，基层员工就一定要在第一线，在每个环节里真正起到核心作用的人都会在重要节点上汇报信息。 法则八：不仅要当老板，还要当老大 我曾经把这句话送给我的团队——老板和老大是有区别的。老板是一个职位，能够管理一个团队，但老大是一种认可，只有他才能真正领导一个团队，产生凝聚力。什么样的人能做老大？做别人不敢做的决定，承担别人不敢承担的责任，搞定别人搞不定的资源。如果这3件事情你都做不了，凭什么让你做老大？你只不过是个老板，面上好听罢了，其实私下大家心里都很忿忿，关键的时候不能挺身而出，要命的时候不能救人于水火，冲锋的时候给不了支持，这要做老大是很难的。 法则九：创造机会，允许失败 我做了这么多年业务，财务也做了这么多年，最大的感受是，数学上两点之间直线距离最短，但这在实际业务中是不成立的。特别是当我们做创新的时候，不可能等着去寻找两点之间的最短距离。CFO的确可以把一切算得清清楚楚，赚多少，亏多少，门儿清。可是等我们把所有事情都算明白了，别人也都明白了，机会就没有了。 我们必须在没想好的时候也要敢做。当然，谁都希望一件事做了就成功，但不可能第一天就画出一个美好的未来图景，直奔图上的目的地就行了。当图不那么清楚的时候，真的就要靠「心」。没有任何成功经验，这时候我们需要用一颗心反复对焦。绝大多数年轻人都想要办成一件事，而不是办糟一件事。我们要对员工有信心，才能一起继续往前走。我们要接受创新可能带来的失败、错误，这是对所有管理者的要求，要敢于创造机会，也要敢于为创新担当。 最高法则：好好睡觉 工作肯定有压力，但压力再大，也必须要睡得着觉。我最大的优势就是再大的问题都必须要睡觉，不仅睡得着，还能按时醒，并且不用闹钟自然醒。 做任何事情还是要举重若轻。就像是休息，你不睡好觉又能怎么样呢？如果完全困在一件件事情里边，很容易让自己深陷其中。只有睡好觉才能有更多精力去处理大大小小的事，才能更好地谋划你的未来。所以既要脚踏实地，踏实地用非常强的执行力做每一件事，又要面向未来，做一个敢做梦的企业，这是非常重要的。我作为CEO义不容辞，必须敢做梦。","categories":[{"name":"职场","slug":"职场","permalink":"http://www.ithelei.com/categories/职场/"}],"tags":[{"name":"职场","slug":"职场","permalink":"http://www.ithelei.com/tags/职场/"}]},{"title":"MYSQL数据库ENUM和SET类型处理","slug":"MYSQL数据库ENUM和SET类型处理","date":"2020-02-17T13:36:45.000Z","updated":"2020-02-24T14:01:41.325Z","comments":true,"path":"2020/02/17/MYSQL数据库ENUM和SET类型处理/","link":"","permalink":"http://www.ithelei.com/2020/02/17/MYSQL数据库ENUM和SET类型处理/","excerpt":"","text":"MYSQL数据库ENUM和SET都是比较特殊的字符串类型，他们都是从一个预先定义好的数据范围内去取值，当给此类型变更值时，不能超出此列预先规定好的那些值。 NUM类型最多可枚举65 535个成员，但只允许出现一个成员————相当于单选（n个单选按钮只能选一个） 我们经常需要给很多表增加一个‘类型’ 字段，比如人的性别有‘男’， ‘女’，学校的类型有‘幼儿园’，‘小学’，‘中学’，‘大学’，汽车的类型有‘轿车’，‘suv’，‘mpv’等，这种字段的本质特点是它们包含 “有限个离散值”。对于这种字段，使用enum数据类型是最合适的 set最多允许64个成员，可以允许这些成员同时出现————相当于复选（n个复选框，可以选n个） set(“足球”，”唱歌”，”跳舞”) set类型通常用于存储表单中的“多选项”的值。 设定形式： set(‘选项值1’, ‘选项值2’, ‘选项值3’, ….) 这些选项值都对应了相应的“索引值”，其索引值从1开始，并“依次翻倍”。 即这些选项的索引值分别为：1， 2， 4， 8， 16， ….. （其实就是2的n次方） set类型最多可设定64个选项值。 SET 类型与 ENUM 类型相似。使用她指定一个 permitted values 列表。但是 SET 类型的字段可以写入列表范围内的多个值。通常，我们在一个字段存储一个值，例如，一个会员拥有一个name,一个town。SET 类型让我们可以在一个字段存储多个值。例如我们可以在一个字段存储会员的多个电话号码。 但是 SET 类型的permitted values数目不能太多，最多只能包含64个值。 创建 teams_new 表，包含teamno，playerno，division字段，其中division字段为 SET 类型`CREATE TABLE teams_new( teamno INTEGER NOT NULL PRIMARY KEY, playerno INTEGER NOT NULL, division SET (&apos;first&apos;,&apos;second&apos;,&apos;third&apos;,&apos;fourth&apos;) ) `小结： 在 SET 关键字后面使用括号列出 permitted values。这些值必须是字符表达式，即使permitted values 是一个数字序列，也必须写成字符字面量形式。permitted values 有时也被称作 elements。divsion 字段由4个 element 组成。 插入数据行时，SET 类型的字段的元素必须在一个字符字面量中并且通过逗号分隔。 `mysql&gt; INSERT INTO teams_new VALUES (1, 27, &apos;first&apos;); Query OK, 1 row affected (0.80 sec) mysql&gt; INSERT INTO teams_new VALUES (2, 27, &apos;first,third&apos;); Query OK, 1 row affected (0.05 sec) mysql&gt; INSERT INTO teams_new VALUES (3, 27, &apos;first,third,sixth&apos;); ERROR 1265 (01000): Data truncated for column &apos;division&apos; at row 1 mysql&gt; INSERT INTO teams_new VALUES (4, 27, &apos;first,fifth&apos;); ERROR 1265 (01000): Data truncated for column &apos;division&apos; at row 1 mysql&gt; INSERT INTO teams_new VALUES (5, 27, NULL); Query OK, 1 row affected (0.07 sec) mysql&gt; INSERT INTO teams_new VALUES (6, 27, 7); Query OK, 1 row affected (0.09 sec) mysql&gt; INSERT INTO teams_new VALUES (7, 27, CONV(1001,2,10)); Query OK, 1 row affected (0.07 sec) mysql&gt; SELECT * FROM teams_new; +--------+----------+--------------------+ | teamno | playerno | division | +--------+----------+--------------------+ | 1 | 27 | first | | 2 | 27 | first,third | | 5 | 27 | NULL | | 6 | 27 | first,second,third | | 7 | 27 | first,fourth | +--------+----------+--------------------+ 5 rows in set (0.00 sec) `小结：第一行值添加了一个值 first,第二行添加了两个值，这两个值不是指定为两个字面量，而是一个字面量，即 ‘first,third’而不是‘first’,’third’.第三行，第四行包含超出范围的值，报错。第五行输入 NULL 。第六行指定了三个值。 同 ENUM 类型一样，SET 类型字段并没有存储实际值，而是存储一个64个长度的二进制字符串。在这个字符串中，如果这个列的第一个值出现了，右数第1位是1，否则就是0。如果集合中第二个值出现了，右数第2位是1，否则就是0，以此类推。 显示 division字段内部类型 `mysql&gt; SELECT teamno teamno,division * 1,BIN(division * 1) FROM teams_new; +--------+--------------+-------------------+ | teamno | division * 1 | BIN(division * 1) | +--------+--------------+-------------------+ | 1 | 1 | 1 | | 2 | 5 | 101 | | 5 | NULL | NULL | | 6 | 7 | 111 | | 7 | 9 | 1001 | +--------+--------------+-------------------+ 5 rows in set (0.00 sec) `小结：通过 divsion * 1 ，我们可以显示内部值。使用 BIN函数把 DECIMAL值转为二进制，并且可以看到MYSQL使用的位模式。注意，这个位模式可以相当长。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MYSQL数据库中DEFAULT（默认）使用技巧","slug":"MYSQL数据库中DEFAULT（默认）使用技巧","date":"2020-02-17T13:36:45.000Z","updated":"2020-02-17T14:55:02.441Z","comments":true,"path":"2020/02/17/MYSQL数据库中DEFAULT（默认）使用技巧/","link":"","permalink":"http://www.ithelei.com/2020/02/17/MYSQL数据库中DEFAULT（默认）使用技巧/","excerpt":"","text":"mysql创建表时，可以使用default来设置表字段的默认值，这样当向表中插入或添加数据时，如果没有为此字段设置任何值，则使用default默认值来填充该字段的值。 在使用create table创建表的时候，为字段设置默认值，如： `create table aa(State char(2) NOT NULL DEFAULT &quot;ky&quot;);`上面sql代码创建了一个aa，该表包含一个State的字段，字段不允许为空且默认值为（DEFAULT）为”KEY”。 当向该表中插入数据时，可以这样使用DEFAULT `INSERT INTO aa (state) VALUE (DEFAULT);`上边sql向aa表中插入一条数据，但没有给state字段设置任何值，这时候DEFAULT就起作用了，将state的值设置为“ky”。 `select * from aa;`","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MYSQL数据库表列的数据类型之_TEXT与BLOG的区别","slug":"MYSQL数据库表列的数据类型之_TEXT与BLOG的区别","date":"2020-02-17T13:36:45.000Z","updated":"2020-02-17T14:10:10.101Z","comments":true,"path":"2020/02/17/MYSQL数据库表列的数据类型之_TEXT与BLOG的区别/","link":"","permalink":"http://www.ithelei.com/2020/02/17/MYSQL数据库表列的数据类型之_TEXT与BLOG的区别/","excerpt":"","text":"一、主要差别 TEXT与BLOB的主要差别就是BLOB保存二进制数据，TEXT保存字符数据。目前几乎所有博客内容里的图片都不是以二进制存储在数据库的，而是把图片上传到服务器然后正文里使用标签引用，这样的博客就可以使用TEXT类型。而BLOB就可以把图片换算成二进制保存到数据库中。 二、类型区别 BLOB有4种类型：TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB。它们只是可容纳值的最大长度不同。 TEXT也有4种类型：TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT。这些类型同BLOB类型一样，有相同的最大长度和存储需求。 三、字符集 BLOB列没有字符集，并且排序和比较基于列值字节的数值值。TEXT列有一个字符集，并且根据字符集的校对规则对值进行排序和比较 四、大小写 在TEXT或BLOB列的存储或检索过程中，不存在大小写转换，都一样！ 五、严格模式 运行在非严格模式时，如果你为BLOB或TEXT列分配一个超过该列类型的最大长度的值值，值被截取以保证适合。如果截掉的字符不是空格，将会产生一条警告。使用严格SQL模式，会产生错误，并且值将被拒绝而不是截取并给出警告。 六、其它 当保存或检索BLOB和TEXT列的值时不删除尾部空格。 对于BLOB和TEXT列的索引，必须指定索引前缀的长度。 BLOB和TEXT列不能有默认值。 当排序时只使用该列的前max_sort_length个字节。max_sort_length的 默认值是1024。 当你想要使超过max_sort_length的字节有意义，对含长值的BLOB或TEXT列使用GROUP BY或ORDER BY的另一种方式是将列值转换为固定长度的对象。标准方法是使用SUBSTRING函数。 BLOB或TEXT对象的最大大小由其类型确定，但在客户端和服务器之间实际可以传递的最大值由可用内存数量和通信缓存区大小确定。你可以通过更改max_allowed_packet变量的值更改消息缓存区的大小，但必须同时修改服务器和客户端程序。 注意： MEDIUMTEXT数据类型，使他存放文章（office的文档）以及其他文档文件。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MYSQL数据库表列的数据类型之_列类型属性UNSIGEND（无符号）与Signed（有符号）","slug":"MYSQL数据库表列的数据类型之_列类型属性UNSIGEND（无符号）与Signed（有符号）","date":"2020-02-17T13:36:45.000Z","updated":"2020-02-17T13:45:36.968Z","comments":true,"path":"2020/02/17/MYSQL数据库表列的数据类型之_列类型属性UNSIGEND（无符号）与Signed（有符号）/","link":"","permalink":"http://www.ithelei.com/2020/02/17/MYSQL数据库表列的数据类型之_列类型属性UNSIGEND（无符号）与Signed（有符号）/","excerpt":"","text":"下面用TINYINT类型字段来说明有符号属性和无符号属性两者之间的差别。在添加UNSIGEND后，字段的取值范围是0255，而Signed的范围是-128127。如果确定不需要负值，通常是不设置Signed，这样会充分利用存储空间。假设使用tinyint来存储一些状态值，0表示删除，1表示付款，2表示已付款，…突然来个需求——增加订单取消，如果用“-1”表示取消的话，结果该列的取值就变为了-128~127.因此一般情况下，不建议用“-1”表示“订单取消”，而可以用“4”或其他非负数表示订单取消。 字段属性设置UNSIGEND后可能出现的问题： 当select a-b from时，a为10，b为12，那这时就会出现异常情况：ERROR 1690(22017):BIGINT UNSIGEND value is out of range in(test.t.a-test.t.b),因此，要注意这种情况的发生。 这两个列属性在性能上是有细微差别的。UNSIGEND的性能更好，当只存储整数的情况下，查询值在 xxxx（代表数值）以下的数据，那么mysql会将范围定义为0xxxxx,而如果是Signed，则查询范围为-2147483648xxxx，这就是性能细微的差别。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MYSQL数据库表列的数据类型之_(数值类型)(字符串类型)","slug":"MYSQL数据库表列的数据类型之_(数值类型)(字符串类型)","date":"2020-02-16T13:36:45.000Z","updated":"2020-02-16T13:01:12.167Z","comments":true,"path":"2020/02/16/MYSQL数据库表列的数据类型之_(数值类型)(字符串类型)/","link":"","permalink":"http://www.ithelei.com/2020/02/16/MYSQL数据库表列的数据类型之_(数值类型)(字符串类型)/","excerpt":"","text":"数值类型数值类型分为整数型和浮点型两类，整数型就是存放没有小数点的数值，如人口统计；浮点型就是用来存放有小数点的数值，如商品价格、失业率等是可以有小数点的，此类数据可以使用浮点型。 整数类型mysql提供了5种整数类型。其中整数类型包括：TINYINT、SMALLINT、MEDIUMINT、INT(INTEGER)、BIGINT 要定义一个整数类型时，要给他指定一个显示宽度，注意这个只是一个以多少字节宽度来显示列的内容，并不是数值的宽度。数据所占空间还是固定的。列入将bigint设置为显示4字节宽，那就这样来写bigint(4)，这并不意味着其所占空间宽度为4字节，事实上它所占的空间还是8个字节，而且她的最大取值还是不变的。 浮点类型浮点数类型包括：FLOAT、DOUBLE 定点数类型包括：DECIMAL(DEC)(M,D) 字符串类型 char与varchar的区别char与varchar是常用的类型，char长度是固定的；varchar长度是可变的；在char (M)类型的数据列内，每个值要占M个字节，若小于M，则mysql会在他 的右边用空格来补足，但在查询时，这些空格会被去掉，而在varchar（m）类型的数据列里，除了存放数据所占用的字节，还会占用一个字节记录其内容长度（L+1个字节），多余空格将会在以后插入操作的过程中被去掉。 采用char会多占用空间，造成空间的浪费。 如果定义了char（100），最多可存放100个“a”或100个汉字，如实际存放一个“a”,或一个汉字“我”，那么此列实际占用的空间还是100，多出去的99个长补空格。浪费空间。 如果采用varchar，则节省空间。我们还用上边的例子，把char（100）改成varchar（100），情况完全不一样了。如果实际存放一个“a”,或一个汉字“我”，那此列实际占用的空间就是1个。 因此：char 类型可以舍弃而改用varchar。 当实际的长度超出超出定义的长度时，二者均不允许。则会报错。 如果定义了char(100)，最多可存放100个“a”,或100个汉字。如果实际存放101个“a”,或更多，或更多个汉字“我”，情况会怎样呢？ sql语句会报错。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MYSQL列类型属性ZEROFILL(填充0)","slug":"mysql中定义字段时zerofill属性","date":"2020-02-16T13:36:45.000Z","updated":"2020-02-16T13:24:06.897Z","comments":true,"path":"2020/02/16/mysql中定义字段时zerofill属性/","link":"","permalink":"http://www.ithelei.com/2020/02/16/mysql中定义字段时zerofill属性/","excerpt":"","text":"列类型属性ZEROFILL(填充0)如果定义列的时候指定zerofill属性，那么当数值的实际宽度小于指定的列宽度时，则默认补充的空格用0代替。 注意：实际存储在表中的数据并非用“0”取代后的结果。 `create table t (id int(12) zerofill);`","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MYSQL数据库中的权限列表","slug":"MYSQL数据库中的权限列表","date":"2020-02-09T13:36:45.000Z","updated":"2020-02-09T14:29:36.898Z","comments":true,"path":"2020/02/09/MYSQL数据库中的权限列表/","link":"","permalink":"http://www.ithelei.com/2020/02/09/MYSQL数据库中的权限列表/","excerpt":"","text":"mysql数据库拥有的权限，既可以分配给数据库账户的操作权力。数据库中的权限见表 | 序号 | 权限 | 权限级别 | 权限说明| | 1 | CREATE | 数据库表或者索引 |创建数据库表或者索引权限| | 2 | DROP | 数据库或表 |删除数据库或者表权限| | 3 | GRANT OPTION | 数据库、表或保存的程序 |赋予权限选项| | 4 | REFERENCES| 数据库、表 |将一个表（父表）的字段作为另外一个表（子表）的外键约束| | 5 | ALTER |表|更改表、如添加字段、索引等| | 6 | DELETE |表|删除数据权限| | 7 | INDEX |表|索引权限| | 8 | INSERT |表|插入权限| | 9 | SELECT |表|查询权限| | 10 | UPDATE |表|更新权限| | 11 | CREATE VIEW |视图|创建视图权限| | 12 | SHOW VIEW |视图|查看视图权限| | 13 | ALTER ROUTINE |存储过程|更改存储过程的权限| | 14 | CREATE ROUTINE |存储过程|创建存储过程的权限| | 15 | EXCUTE |存储过程|执行存储过程的权限| | 16 | FILE |服务器主机上的文件访问|文件访问权限| | 17 | CREATE TEMPORARY TABLES |服务器管理|创建临时表权限| | 18 | LOCK TABLES |服务器管理|锁表权限| | 19 | CREATE USER |服务器管理|创建用户权限| | 20 | PROCESS|服务器管理|查看进程权限| | 21 | RELOAD|服务器管理|执行flush-hosts、reload等命令的权限| | 22 | REPLICATION CLIENT|服务器管理|复制权限| | 23 | REPLICATION SLAVE|服务器管理|复制权限| | 24 | show databases|服务器管理|查看数据库权限| | 25 | SHUTDOWN|服务器管理|关闭数据库权限| | 26 | SUPER|服务器管理|执行kill线程权限| mysql数据库的权限分布| 权限分布|可能的设置权限| | 表权限|select、insert、update、delete、create、drop、grant、index、alter、references| | 列权限|select、insert、update、references| |存储过程权限|EXECUTE、ALTER、ROUTINE、GRANT| mysql为用户设置权限的原则权限控制主要是因为安全考虑，因此需要遵循以下几个原则。 只授予能满足需要的最小权限，防止用户与自己无关的事情。如果用户只是查询，那就只给select权限就可以了，不要给用户赋予update/insert/delete权限。 创建用户的时候限制用户的登录主机，一般是限制指定ip或者内网ip段 初始化数据库的时候删除没有密码的用户。 为每个用户设置复杂的密码 定期清理不需要的用户，回收权限或者删除用户。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MYSQL数据库网站中常用数据类型介绍","slug":"MYSQL数据库网站中常用数据类型介绍","date":"2020-02-09T13:36:45.000Z","updated":"2020-02-24T13:26:03.314Z","comments":true,"path":"2020/02/09/MYSQL数据库网站中常用数据类型介绍/","link":"","permalink":"http://www.ithelei.com/2020/02/09/MYSQL数据库网站中常用数据类型介绍/","excerpt":"","text":"关于网站中常用的mysql数据库列的数据类型，只能从一般意义而言。像int,varchar,text,decimal,datetime等。关于网站中常用的数据类型使用，一切从实际出发，在充分掌握了他们的特性之后，依据实际情况采用何种数据类型，如身份证号18位，可采用char（18）。 数据类型的使用数值类型可以分为整形和浮点十进制类型。所谓的“十进制”是指，DECIMAL和Numeric，他们是同一类型的。一般来说，这种类型会消耗大量的存储空间，但他的优点是不会失去做浮点数的计算精度，他更适合一些计算精度要求高的场合，如价格，比率，折算等。而float或double的优点是可以表示更小的数。float的最小值为1.17E-38（0.000···0117；小数点后37位）double表达更小的数，最小的数约为2.22e-308(0.000···0222，小数点后307位)的小数。 float和double分别为4字节和8字节的存储空间。 对于整形，在mysql中有很多不同类型的整数。在设计数据库表时，可以有一个字节TINYINT到BIGINT的选择（TINYINT-1字节、SMALLINT-2字节、MEDIUMINT3Z字节、INT-4字节、BIGINT-8字节），所以因该把过多的考虑放在采用哪个类型以活得最小的存储空间，但又不失去任何准确性。 对于无符号整数，这些类型能表述的最大整数分别为255，65535，16777215，42949672951844674403709551615。如果需要保存用户的年龄，TINYINT就够了；如果是自增的id,应该使用MEDIUMINT而不是INT,INT还是太大了。很多数据表不会达到MEDIUMINT的范围。 关于日期和时间类型如date、time、datetime、timestamp、和year都是日期和时间类型。只需要关系日期，没有分秒，那就应该使用date而不是datetime;其中datetime是常用的，一切按实际需求设计。 字符类型（不要以为字符类型仅仅是char）char和varchar的区别是-char是固定长度。如果定义一个字段char(10)，那么无论多少字节的数，这将需要10个字节的空间；对于18位的身份号码，则应该使用char(18)。varchar是可变长度的，如果有一个字段的值有不同的长度，那么应该使用varchar。 枚举（enum）和集合(set)类型枚举（enum）最多可以定义到65535个不同的字符串从中做出选择，相当于单选；集合(set)类型，最多可以有64个不同的成员，可以选择零个或者多个成员，相当于复选。假设可以用枚举enum（“男”，“女”）来限定字段值只能在“男”“女”之间做出选择，这样可以节约大约数据库空间。 网站中“评论” “留言” “新闻” 应采用的数据类型目前，大部分网站都提供“留言” “评论” “新闻” 等功能，网站对这些内容的篇幅没有限制，允许任意大。那么采用什么数据类型来存储这些内容呢？一般采用MEDIUMTEXT数据类型","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"Git常用指令一览表","slug":"Git常用指令一览表","date":"2020-02-03T01:20:45.000Z","updated":"2020-02-07T14:46:46.987Z","comments":true,"path":"2020/02/03/Git常用指令一览表/","link":"","permalink":"http://www.ithelei.com/2020/02/03/Git常用指令一览表/","excerpt":"","text":"Git总共提供了超过100个以上的指令让我们执行各种操作（可以使用”git help -a”指令显示完整的指令列表），每一个指令又有许多选项可以搭配，但是我们不可能，也不需要完全记住这些指令。就实用性而言，只要熟练部分指令和选项的用法，就可以满足一般应用的需求。 git add . 将全部文件的内容加到Git索引，以便执行commit。这个指令不会检查文件夹中是否有文件被删除。要注意的是，只有执行“git add” 时，文件内容会被加入Git索引。如果后来又修改了文件，新的文件内容不会在git索引中。我们必须重新执行“git add”指令，才会更新git索引。 git add 文件名 文件名 。。。 将指定的文件内容加到git索引，以便执行commit操作。要注意的是，只有执行“git add” 时，文件内容才会被加入Git索引。如果后来又修改了文件，新的文件内容不会在git索引中。我们必须重新执行“git add”指令，才会更新git索引。 git add -A 除了把全部文件的内容加到git索引以外，也会检查文件中是否有文件被删除。这些被删除的文件会标记在git索引中。当执行commit指令的时候，被标记删除的文件也会从新的commit节点中被删除。我们可以从git文档库的历史版本中找回被删除的文件。 git add –update 或者 git add -u 对比当前文件夹中的文件内容和git文档库中的文件内容，把有修改的部分和删除的文件加到git索引，以便执行commit。这个指令不会增加新的文件到git索引，只会更新或者是删除文件。 git blame 文件名 或是 git blame -L 起始行，结束行 文件名 或是 git blame -L 起始行， 文件名 或是 git blame -L 结束行， 文件名 显示文件的每一行是由谁修改。可以搭配“-L”选项，指定要从哪一行开始到哪一行结束。如果没有指定起始行，表示是从文件的第一行开始。如果没有指定结束行，表示要到文件的最后一行。 git branch 自己取的分支名称 \\ commit 节点标识符或是标签 按照参数的多少，会有不同的功能。 1、如果最后指定了commit节点标识符或者是标签，就会从该节点“长”出分支；如果没有指定commit节点，就会从最新的commit“长”出分支。 2、“git branch” 指令后边没有接任何参数时，会列出当前文档库中正在开发的所有分支。 git branch 新分支名称 已经存在的分支 从特定的分支，在长出另一个分支 git branch -a 列出文档库和远程文档库中的所有分支 git branch -d 删除指定的分支。必须先切换到另一个分支，才能执行这个命令 git branch -D 要删除的分支名称 在一般情况下，分支应该先合并到另一个分支，之后才能被删除。如果我们要删除还没有合并的分支，git会会显示错误信息。并且停止删除分支的操作。如果确定要删除还没有合并的分支，可以使用“-D”选项，要求git强制执行删除分支的操作。 git branch –list 分支名称样板 显示符合“分支名称样板”的所有分支，例如以下指令范例会显示所有分支以“bug/” 开头的分支： git branch –list bug/* git branch -m 新的分支名称 更改分支的名称，必须先切换到该分支。才能够执行这个指令。 git checkout 文件1 文件2 … 或者 git checkout . git会先找索引中有没有该文件，如果有就把他取出；如果没有，就从最新的commit节点开始。按照时间顺序往前寻找，然后取出第一个找到的文件版本，每一个文件都用同样的方式处理。 如果取出文档库中全部文件的最新版本，可以执行“git checkout .”。 git checkout commit 节点标识符或者标签 \\ 文件1 文件2 … 从git文档库的commit节点取出指定的文件。如果取出的文件和当前文档库中最新commit的文件的内容不同，这个取出的文件内容会自动记录在git索引中。下次执行“git commit” 指令时，这个取出的文件内容就会存入文档库中成为新的版本。如果要避免这种情况发生，可以在执行“git checout” 指令之后，立刻执行“git reset HEAD” 来清楚git索引。 git checkout 分支名称 将当前操作的分支切换到指定的分支。 251","categories":[{"name":"Git","slug":"Git","permalink":"http://www.ithelei.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://www.ithelei.com/tags/Git/"}]},{"title":"安全修改表","slug":"安全修改表","date":"2020-02-01T13:36:45.000Z","updated":"2020-02-07T16:26:46.721Z","comments":true,"path":"2020/02/01/安全修改表/","link":"","permalink":"http://www.ithelei.com/2020/02/01/安全修改表/","excerpt":"","text":"ALTER table 命令可以对已经创建的表进行修改，如增加字段，删除字段，更改字段，增加主键等。 新增字段， ALTER TABLE t_logs ADD COLUMN click_num INT NULL AFTER created; 删除字段 ALTER TABLE t_logs drop COLUMN click_num ; 查看表结构DESCRIBE t_logs; 3.修改字段 更改字段信息可使用CHANGE关键字，如将 click_num 列的类型转为 MEDIUMINT型。命令如下 `ALTER TABLE t_logs CHANGE click_num click_num MEDIUMINT(11) NULL;` 查看表结构 DESCRIBE t_logs; mysql修改字段的另外一种语法： `ALTER TABLE t_logs modify created BIGINT(32) NULL`mysql 修改字段长度 如：news 表里的title 字段 原来长度是 100个字符，现长度要改成130个字符 `alter table news modify column title varchar(130);`如修改mysql字段类型 `alter table user modify column photo longtext ;`4.增加主键 `Alter table t_logs CHANGE id id int(11) not NULL ,drop PRIMARY key;`然后将id设置主键 `Alter table t_logs add PRIMARY KEY(id);`","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"安全复制表","slug":"安全复制表","date":"2020-02-01T13:36:45.000Z","updated":"2020-02-07T15:32:07.891Z","comments":true,"path":"2020/02/01/安全复制表/","link":"","permalink":"http://www.ithelei.com/2020/02/01/安全复制表/","excerpt":"","text":"用户可以将已有表中的全部或部分信息放在一个新表中，这样就实现了表的复制。 `create table new_table1 select * from t_comments` 然后查看下表信息，可以看出复制表成功了。 注意： 使用select 方式复制是不能复制键（Key）的。 上面演示了整个表的复制，当然也可以只复制特定的列或特定行的内容。 mysql还有一种复制表的方法—-like方法,但他不能复制表的内容，只能复制表的结构。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"怎么理解Linux软中断？","slug":"怎么理解Linux软中断？","date":"2019-09-15T01:20:45.000Z","updated":"2019-09-15T06:29:22.462Z","comments":true,"path":"2019/09/15/怎么理解Linux软中断？/","link":"","permalink":"http://www.ithelei.com/2019/09/15/怎么理解Linux软中断？/","excerpt":"","text":"从“取外卖”看中断说到中断，我在前面关于“上下文切换”的文章，简单说过中断的含义，先来回顾一下。中断是系统用来响应硬件设备请求的一种机制，它会打断进程的正常调度和执行，然后调用内核中的中断处理程序来响应设备的请求。 你可能要问了，为什么要有中断呢？我可以举个生活中的例子，让你感受一下中断的魅力。 比如说你订了一份外卖，但是不确定外卖什么时候送到，也没有别的方法了解外卖的进度，但是，配送员送外卖是不等人的，到了你这儿没人取的话，就直接走人了。所以你只能苦苦等着，时不时去门口看看外卖送到没，而不能干其他事情。 不过呢，如果在订外卖的时候，你就跟配送员约定好，让他送到后给你打个电话，那你就不用苦苦等待了，就可以去忙别的事情，直到电话一响，接电话、取外卖就可以了。 这里的“打电话”，其实就是一个中断。没接到电话的时候，你可以做其他的事情；只有接到了电话（也就是发生中断），你才要进行另一个动作：取外卖。 这个例子你就可以发现，中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。 由于中断处理程序会打断其他进程的运行，所以，为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。如果中断本身要做的事情不多，那么处理起来也不会有太大问题；但如果中断要处理的事情很多，中断服务程序就有可能要运行很长时间。 特别是，中断处理程序在响应中断时，还会临时关闭中断。这就会导致上一次中断处理完成之前，其他中断都不能响应，也就是说中断有可能会丢失。 那么还是以取外卖为例。假如你订了 2 份外卖，一份主食和一份饮料，并且是由 2 个不同的配送员来配送。这次你不用时时等待着，两份外卖都约定了电话取外卖的方式。但是，问题又来了。 当第一份外卖送到时，配送员给你打了个长长的电话，商量发票的处理方式。与此同时，第二个配送员也到了，也想给你打电话。 但是很明显，因为电话占线（也就是关闭了中断响应），第二个配送员的电话是打不通的。所以，第二个配送员很可能试几次后就走掉了（也就是丢失了一次中断）。 软中断如果你弄清楚了“取外卖”的模式，那对系统的中断机制就很容易理解了。事实上，为了解决中断处理程序执行过长和中断丢失的问题，Linux 将中断处理过程分成了两个阶段，也就是上半部和下半部： 上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。 下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。 比如说前面取外卖的例子，上半部就是你接听电话，告诉配送员你已经知道了，其他事儿见面再说，然后电话就可以挂断了；下半部才是取外卖的动作，以及见面后商量发票处理的动作。 这样，第一个配送员不会占用你太多时间，当第二个配送员过来时，照样能正常打通你的电话。 除了取外卖，我再举个最常见的网卡接收数据包的例子，让你更好地理解。 网卡接收到数据包后，会通过硬件中断的方式，通知内核有新的数据到了。这时，内核就应该调用中断处理程序来响应它。你可以自己先想一下，这种情况下的上半部和下半部分别负责什么工作呢？ 对上半部来说，既然是快速处理，其实就是要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态（表示数据已经读好了），最后再发送一个软中断信号，通知下半部做进一步的处理。 而下半部被软中断信号唤醒后，需要从内存中找到网络数据，再按照网络协议栈，对数据进行逐层解析和处理，直到把它送给应用程序。 所以，这两个阶段你也可以这样理解： 上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行； 而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。 实际上，上半部会打断 CPU 正在执行的任务，然后立即执行中断处理程序。而下半部以内核线程的方式执行，并且每个 CPU 都对应一个软中断内核线程，名字为 “ksoftirqd/CPU 编号”，比如说， 0 号 CPU 对应的软中断内核线程的名字就是 ksoftirqd/0。 不过要注意的是，软中断不只包括了刚刚所讲的硬件设备中断处理程序的下半部，一些内核自定义的事件也属于软中断，比如内核调度和 RCU 锁（Read-Copy Update 的缩写，RCU 是 Linux 内核中最常用的锁之一）等。 那要怎么知道你的系统里有哪些软中断呢？ 查看软中断和内核线程不知道你还记不记得，前面提到过的 proc 文件系统。它是一种内核空间和用户空间进行通信的机制，可以用来查看内核的数据结构，或者用来动态修改内核的配置。其中： /proc/softirqs 提供了软中断的运行情况； /proc/interrupts 提供了硬中断的运行情况。 运行下面的命令，查看 /proc/softirqs 文件的内容，你就可以看到各种类型软中断在不同 CPU 上的累积运行次数： `cat /proc/softirqs CPU0 CPU1 HI: 0 0 TIMER: 811613 1972736 NET_TX: 49 7 NET_RX: 1136736 1506885 BLOCK: 0 0 IRQ_POLL: 0 0 TASKLET: 304787 3691 SCHED: 689718 1897539 HRTIMER: 0 0 RCU: 1330771 1354737 `在查看 /proc/softirqs 文件内容时，你要特别注意以下这两点。 第一，要注意软中断的类型，也就是这个界面中第一列的内容。从第一列你可以看到，软中断包括了 10 个类别，分别对应不同的工作类型。比如 NETRX 表示网络接收中断，而 NETTX 表示网络发送中断。 第二，要注意同一种软中断在不同 CPU 上的分布情况，也就是同一行的内容。正常情况下，同一种中断在不同 CPU 上的累积次数应该差不多。比如这个界面中，NETRX 在 CPU0 和 CPU1 上的中断次数基本是同一个数量级，相差不大。 不过你可能发现，TASKLET 在不同 CPU 上的分布并不均匀。TASKLET 是最常用的软中断实现机制，每个 TASKLET 只运行一次就会结束 ，并且只在调用它的函数所在的 CPU 上运行。 因此，使用 TASKLET 特别简便，当然也会存在一些问题，比如说由于只在一个 CPU 上运行导致的调度不均衡，再比如因为不能在多个 CPU 上并行运行带来了性能限制。 另外，刚刚提到过，软中断实际上是以内核线程的方式运行的，每个 CPU 都对应一个软中断内核线程，这个软中断内核线程就叫做 ksoftirqd/CPU 编号。那要怎么查看这些线程的运行状况呢？ 其实用 ps 命令就可以做到，比如执行下面的指令： `ps aux | grep softirq root 7 0.0 0.0 0 0 ? S Oct10 0:01 [ksoftirqd/0] root 16 0.0 0.0 0 0 ? S Oct10 0:01 [ksoftirqd/1] `注意，这些线程的名字外面都有中括号，这说明 ps 无法获取它们的命令行参数（cmline）。一般来说，ps 的输出中，名字括在中括号里的，一般都是内核线程。 小结Linux 中的中断处理程序分为上半部和下半部： 上半部对应硬件中断，用来快速处理中断。 下半部对应软中断，用来异步处理上半部未完成的工作。 Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型，可以通过查看 /proc/softirqs 来观察软中断的运行情况。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"}]},{"title":"系统中出现大量不可中断进程和僵尸进程怎么办？（上）","slug":"系统中出现大量不可中断进程和僵尸进程怎么办？（上）","date":"2019-09-15T01:20:45.000Z","updated":"2019-09-15T05:34:08.608Z","comments":true,"path":"2019/09/15/系统中出现大量不可中断进程和僵尸进程怎么办？（上）/","link":"","permalink":"http://www.ithelei.com/2019/09/15/系统中出现大量不可中断进程和僵尸进程怎么办？（上）/","excerpt":"","text":"进程状态当 iowait 升高时，进程很可能因为得不到硬件的响应，而长时间处于不可中断状态。从 ps 或者 top 命令的输出中，你可以发现它们都处于 D 状态，也就是不可中断状态（Uninterruptible Sleep）。既然说到了进程的状态，进程有哪些状态你还记得吗？我们先来回顾一下。 top 和 ps 是最常用的查看进程状态的工具，我们就从 top 的输出开始。下面是一个 top 命令输出的示例，S 列（也就是 Status 列）表示进程的状态。从这个示例里，你可以看到 R、D、Z、S、I 等几个状态，它们分别是什么意思呢？ `top PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 28961 root 20 0 43816 3148 4040 R 3.2 0.0 0:00.01 top 620 root 20 0 37280 33676 908 D 0.3 0.4 0:00.01 app 1 root 20 0 160072 9416 6752 S 0.0 0.1 0:37.64 systemd 1896 root 20 0 0 0 0 Z 0.0 0.0 0:00.00 devapp 2 root 20 0 0 0 0 S 0.0 0.0 0:00.10 kthreadd 4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/0:0H 6 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 mm_percpu_wq 7 root 20 0 0 0 0 S 0.0 0.0 0:06.37 ksoftirqd/0 `我们挨个来看一下： R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。 D 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。 Z 是 Zombie 的缩写，如果你玩过“植物大战僵尸”这款游戏，应该知道它的意思。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。 S 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。 I 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。 当然了，上面的示例并没有包括进程的所有状态。除了以上 5 个状态，进程还包括下面这 2 个状态。 第一个是 T 或者 t，也就是 Stopped 或 Traced 的缩写，表示进程处于暂停或者跟踪状态。 向一个进程发送 SIGSTOP 信号，它就会因响应这个信号变成暂停状态（Stopped）；再向它发送 SIGCONT 信号，进程又会恢复运行（如果进程是终端里直接启动的，则需要你用 fg 命令，恢复到前台运行）。 而当你用调试器（如 gdb）调试一个进程时，在使用断点中断进程后，进程就会变成跟踪状态，这其实也是一种特殊的暂停状态，只不过你可以用调试器来跟踪并按需要控制进程的运行。 另一个是 X，也就是 Dead 的缩写，表示进程已经消亡，所以你不会在 top 或者 ps 命令中看到它。 了解了这些，我们再回到今天的主题。先看不可中断状态，这其实是为了保证进程数据与硬件状态一致，并且正常情况下，不可中断状态在很短时间内就会结束。所以，短时的不可中断状态进程，我们一般可以忽略。 但如果系统或硬件发生了故障，进程可能会在不可中断状态保持很久，甚至导致系统中出现大量不可中断进程。这时，你就得注意下，系统是不是出现了 I/O 等性能问题。 再看僵尸进程，这是多进程应用很容易碰到的问题。正常情况下，当一个进程创建了子进程后，它应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源；而子进程在结束时，会向它的父进程发送 SIGCHLD 信号，所以，父进程还可以注册 SIGCHLD 信号的处理函数，异步回收资源。 如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。换句话说，父亲应该一直对儿子负责，善始善终，如果不作为或者跟不上，都会导致“问题少年”的出现。 通常，僵尸进程持续的时间都比较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由 init 进程回收后也会消亡。 一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免。 案例分析接下来，我将用一个多进程应用的案例，带你分析大量不可中断状态和僵尸状态进程的问题。这个应用基于 C 开发，由于它的编译和运行步骤比较麻烦，我把它打包成了一个 Docker 镜像。这样，你只需要运行一个 Dockerhttps://github.com/feiskyer/linux-perf-examples/tree/master/high-iowait-process 容器就可以得到模拟环境。 准备下面的案例仍然基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。我使用的案例环境如下所示： 机器配置：2 CPU，8GB 内存 预先安装 docker、sysstat、dstat 等工具，如 apt install docker.io dstat sysstat 这里，dstat 是一个新的性能工具，它吸收了 vmstat、iostat、ifstat 等几种工具的优点，可以同时观察系统的 CPU、磁盘 I/O、网络以及内存使用情况。 接下来，我们打开一个终端，SSH 登录到机器上，并安装上述工具。 注意，以下所有命令都默认以 root 用户运行，如果你用普通用户身份登陆系统，请运行 sudo su root 命令切换到 root 用户。 如果安装过程有问题，你可以先上网搜索解决，实在解决不了的，记得在留言区向我提问。 温馨提示：案例应用的核心代码逻辑比较简单，你可能一眼就能看出问题，但实际生产环境中的源码就复杂多了。所以，我依旧建议，操作之前别看源码，避免先入为主，而要把它当成一个黑盒来分析，这样你可以更好地根据现象分析问题。你姑且当成你工作中的一次演练，这样效果更佳。 操作和分析安装完成后，我们首先执行下面的命令运行案例应用： `docker run --privileged --name=app -itd feisky/app:iowait `然后，输入 ps 命令，确认案例应用已正常启动。如果一切正常，你应该可以看到如下所示的输出： `ps aux | grep /app root 4009 0.0 0.0 4376 1008 pts/0 Ss+ 05:51 0:00 /app root 4287 0.6 0.4 37280 33660 pts/0 D+ 05:54 0:00 /app root 4288 0.6 0.4 37280 33668 pts/0 D+ 05:54 0:00 /app `从这个界面，我们可以发现多个 app 进程已经启动，并且它们的状态分别是 Ss+ 和 D+。其中，S 表示可中断睡眠状态，D 表示不可中断睡眠状态，我们在前面刚学过，那后面的 s 和 + 是什么意思呢？不知道也没关系，查一下 man ps 就可以。现在记住，s 表示这个进程是一个会话的领导进程，而 + 表示前台进程组。 这里又出现了两个新概念，进程组和会话。它们用来管理一组相互关联的进程，意思其实很好理解。 进程组表示一组相互关联的进程，比如每个子进程都是父进程所在组的成员； 而会话是指共享同一个控制终端的一个或多个进程组。 比如，我们通过 SSH 登录服务器，就会打开一个控制终端（TTY），这个控制终端就对应一个会话。而我们在终端中运行的命令以及它们的子进程，就构成了一个个的进程组，其中，在后台运行的命令，构成后台进程组；在前台运行的命令，构成前台进程组。 明白了这些，我们再用 top 看一下系统的资源使用情况： `# 按下数字 1 切换到所有 CPU 的使用情况，观察一会儿按 Ctrl+C 结束 $ top top - 05:56:23 up 17 days, 16:45, 2 users, load average: 2.00, 1.68, 1.39 Tasks: 247 total, 1 running, 79 sleeping, 0 stopped, 115 zombie %Cpu0 : 0.0 us, 0.7 sy, 0.0 ni, 38.9 id, 60.5 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 : 0.0 us, 0.7 sy, 0.0 ni, 4.7 id, 94.6 wa, 0.0 hi, 0.0 si, 0.0 st ... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 4340 root 20 0 44676 4048 3432 R 0.3 0.0 0:00.05 top 4345 root 20 0 37280 33624 860 D 0.3 0.0 0:00.01 app 4344 root 20 0 37280 33624 860 D 0.3 0.4 0:00.01 app 1 root 20 0 160072 9416 6752 S 0.0 0.1 0:38.59 systemd ... `从这里你能看出什么问题吗？细心一点，逐行观察，别放过任何一个地方。忘了哪行参数意思的话。 好的，如果你已经有了答案，那就继续往下走，看看跟我找的问题是否一样。这里，我发现了四个可疑的地方。 先看第一行的平均负载（ Load Average），过去 1 分钟、5 分钟和 15 分钟内的平均负载在依次减小，说明平均负载正在升高；而 1 分钟内的平均负载已经达到系统的 CPU 个数，说明系统很可能已经有了性能瓶颈。 再看第二行的 Tasks，有 1 个正在运行的进程，但僵尸进程比较多，而且还在不停增加，说明有子进程在退出时没被清理。 接下来看两个 CPU 的使用率情况，用户 CPU 和系统 CPU 都不高，但 iowait 分别是 60.5% 和 94.6%，好像有点儿不正常。 最后再看每个进程的情况， CPU 使用率最高的进程只有 0.3%，看起来并不高；但有两个进程处于 D 状态，它们可能在等待 I/O，但光凭这里并不能确定是它们导致了 iowait 升高。 我们把这四个问题再汇总一下，就可以得到很明确的两点： 第一点，iowait 太高了，导致系统的平均负载升高，甚至达到了系统 CPU 的个数。 第二点，僵尸进程在不断增多，说明有程序没能正确清理子进程的资源。 小结熟悉了几个必备的进程状态。用我们最熟悉的 ps 或者 top ，可以查看进程的状态，这些状态包括运行（R）、空闲（I）、不可中断睡眠（D）、可中断睡眠（S）、僵尸（Z）以及暂停（T）等。 其中，不可中断状态和僵尸状态，是我们今天学习的重点。 不可中断状态，表示进程正在跟硬件交互，为了保护进程数据和硬件的一致性，系统不允许其他进程或中断打断这个进程。进程长时间处于不可中断状态，通常表示系统有 I/O 性能问题。 僵尸进程表示进程已经退出，但它的父进程还没有回收子进程占用的资源。短暂的僵尸状态我们通常不必理会，但进程长时间处于僵尸状态，就应该注意了，可能有应用程序没有正常处理子进程的退出。","categories":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/categories/CPU/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/tags/CPU/"}]},{"title":"系统中出现大量不可中断进程和僵尸进程怎么办？（下）","slug":"系统中出现大量不可中断进程和僵尸进程怎么办？（下）","date":"2019-09-15T01:20:45.000Z","updated":"2019-09-15T06:06:23.953Z","comments":true,"path":"2019/09/15/系统中出现大量不可中断进程和僵尸进程怎么办？（下）/","link":"","permalink":"http://www.ithelei.com/2019/09/15/系统中出现大量不可中断进程和僵尸进程怎么办？（下）/","excerpt":"","text":"使用 ps 或者 top 可以查看进程的状态，这些状态包括运行、空闲、不可中断睡眠、可中断睡眠、僵尸以及暂停等。其中，我们重点学习了不可中断状态和僵尸进程： 不可中断状态，一般表示进程正在跟硬件交互，为了保护进程数据与硬件一致，系统不允许其他进程或中断打断该进程。 僵尸进程表示进程已经退出，但它的父进程没有回收该进程所占用的资源。 上一节的最后，我用一个案例展示了处于这两种状态的进程。通过分析 top 命令的输出，我们发现了两个问题： 第一，iowait 太高了，导致系统平均负载升高，并且已经达到了系统 CPU 的个数。 第二，僵尸进程在不断增多，看起来是应用程序没有正确清理子进程的资源。 相信你一定认真思考过这两个问题，找出根源。 首先，请你打开一个终端，登录到上次的机器中。然后执行下面的命令，重新运行这个案例： `# 先删除上次启动的案例 $ docker rm -f app # 重新运行案例 $ docker run --privileged --name=app -itd feisky/app:iowait `iowait 分析我们先来看一下 iowait 升高的问题。 我相信，一提到 iowait 升高，你首先会想要查询系统的 I/O 情况。我一般也是这种思路，那么什么工具可以查询系统的 I/O 情况呢？ 这里，我推荐的正是上节课要求安装的 dstat ，它的好处是，可以同时查看 CPU 和 I/O 这两种资源的使用情况，便于对比分析。 那么，我们在终端中运行 dstat 命令，观察 CPU 和 I/O 的使用情况： `# 间隔 1 秒输出 10 组数据 $ dstat 1 10 You did not select any stats, using -cdngy by default. --total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system-- usr sys idl wai stl| read writ| recv send| in out | int csw 0 0 96 4 0|1219k 408k| 0 0 | 0 0 | 42 885 0 0 2 98 0| 34M 0 | 198B 790B| 0 0 | 42 138 0 0 0 100 0| 34M 0 | 66B 342B| 0 0 | 42 135 0 0 84 16 0|5633k 0 | 66B 342B| 0 0 | 52 177 0 3 39 58 0| 22M 0 | 66B 342B| 0 0 | 43 144 0 0 0 100 0| 34M 0 | 200B 450B| 0 0 | 46 147 0 0 2 98 0| 34M 0 | 66B 342B| 0 0 | 45 134 0 0 0 100 0| 34M 0 | 66B 342B| 0 0 | 39 131 0 0 83 17 0|5633k 0 | 66B 342B| 0 0 | 46 168 0 3 39 59 0| 22M 0 | 66B 342B| 0 0 | 37 134 `从 dstat 的输出，我们可以看到，每当 iowait 升高（wai）时，磁盘的读请求（read）都会很大。这说明 iowait 的升高跟磁盘的读请求有关，很可能就是磁盘读导致的。 那到底是哪个进程在读磁盘呢？不知道你还记不记得，上节在 top 里看到的不可中断状态进程，我觉得它就很可疑，我们试着来分析下。 我们继续在刚才的终端中，运行 top 命令，观察 D 状态的进程： `# 观察一会儿按 Ctrl+C 结束 $ top ... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 4340 root 20 0 44676 4048 3432 R 0.3 0.0 0:00.05 top 4345 root 20 0 37280 33624 860 D 0.3 0.0 0:00.01 app 4344 root 20 0 37280 33624 860 D 0.3 0.4 0:00.01 app ... `我们从 top 的输出找到 D 状态进程的 PID，你可以发现，这个界面里有两个 D 状态的进程，PID 分别是 4344 和 4345。 接着，我们查看这些进程的磁盘读写情况。对了，别忘了工具是什么。一般要查看某一个进程的资源使用情况，都可以用我们的老朋友 pidstat，不过这次记得加上 -d 参数，以便输出 I/O 使用情况。 比如，以 4344 为例，我们在终端里运行下面的 pidstat 命令，并用 -p 4344 参数指定进程号： `# -d 展示 I/O 统计数据，-p 指定进程号，间隔 1 秒输出 3 组数据 $ pidstat -d -p 4344 1 3 06:38:50 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:38:51 0 4344 0.00 0.00 0.00 0 app 06:38:52 0 4344 0.00 0.00 0.00 0 app 06:38:53 0 4344 0.00 0.00 0.00 0 app `在这个输出中， kBrd 表示每秒读的 KB 数， kBwr 表示每秒写的 KB 数，iodelay 表示 I/O 的延迟（单位是时钟周期）。它们都是 0，那就表示此时没有任何的读写，说明问题不是 4344 进程导致的。 可是，用同样的方法分析进程 4345，你会发现，它也没有任何磁盘读写。 那要怎么知道，到底是哪个进程在进行磁盘读写呢？我们继续使用 pidstat，但这次去掉进程号，干脆就来观察所有进程的 I/O 使用情况。 在终端中运行下面的 pidstat 命令： `# 间隔 1 秒输出多组数据 (这里是 20 组) $ pidstat -d 1 20 ... 06:48:46 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:48:47 0 4615 0.00 0.00 0.00 1 kworker/u4:1 06:48:47 0 6080 32768.00 0.00 0.00 170 app 06:48:47 0 6081 32768.00 0.00 0.00 184 app 06:48:47 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:48:48 0 6080 0.00 0.00 0.00 110 app 06:48:48 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:48:49 0 6081 0.00 0.00 0.00 191 app 06:48:49 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:48:50 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:48:51 0 6082 32768.00 0.00 0.00 0 app 06:48:51 0 6083 32768.00 0.00 0.00 0 app 06:48:51 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:48:52 0 6082 32768.00 0.00 0.00 184 app 06:48:52 0 6083 32768.00 0.00 0.00 175 app 06:48:52 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:48:53 0 6083 0.00 0.00 0.00 105 app ... `观察一会儿可以发现，的确是 app 进程在进行磁盘读，并且每秒读的数据有 32 MB，看来就是 app 的问题。不过，app 进程到底在执行啥 I/O 操作呢？ 这里，我们需要回顾一下进程用户态和内核态的区别。进程想要访问磁盘，就必须使用系统调用，所以接下来，重点就是找出 app 进程的系统调用了。 strace 正是最常用的跟踪进程系统调用的工具。所以，我们从 pidstat 的输出中拿到进程的 PID 号，比如 6082，然后在终端中运行 strace 命令，并用 -p 参数指定 PID 号： `strace -p 6082 strace: attach: ptrace(PTRACE_SEIZE, 6082): Operation not permitted `这儿出现了一个奇怪的错误，strace 命令居然失败了，并且命令报出的错误是没有权限。按理来说，我们所有操作都已经是以 root 用户运行了，为什么还会没有权限呢？你也可以先想一下，碰到这种情况，你会怎么处理呢？ 一般遇到这种问题时，我会先检查一下进程的状态是否正常。比如，继续在终端中运行 ps 命令，并使用 grep 找出刚才的 6082 号进程： `ps aux | grep 6082 root 6082 0.0 0.0 0 0 pts/0 Z+ 13:43 0:00 [app] &lt;defunct&gt; `果然，进程 6082 已经变成了 Z 状态，也就是僵尸进程。僵尸进程都是已经退出的进程，所以就没法儿继续分析它的系统调用。关于僵尸进程的处理方法，我们一会儿再说，现在还是继续分析 iowait 的问题。 到这一步，你应该注意到了，系统 iowait 的问题还在继续，但是 top、pidstat 这类工具已经不能给出更多的信息了。这时，我们就应该求助那些基于事件记录的动态追踪工具了。 你可以用 perf top 看看有没有新发现。再或者，可以像我一样，在终端中运行 perf record，持续一会儿（例如 15 秒），然后按 Ctrl+C 退出，再运行 perf report 查看报告： `perf record -g $ perf report `接着，找到我们关注的 app 进程，按回车键展开调用栈，你就会得到下面这张调用关系图： 这个图里的 swapper 是内核中的调度进程，你可以先忽略掉。 我们来看其他信息，你可以发现， app 的确在通过系统调用 sysread() 读取数据。并且从 newsyncread 和 blkdevdirectIO 能看出，进程正在对磁盘进行直接读，也就是绕过了系统缓存，每个读请求都会从磁盘直接读，这就可以解释我们观察到的 iowait 升高了。 看来，罪魁祸首是 app 内部进行了磁盘的直接 I/O 啊！ 下面的问题就容易解决了。我们接下来应该从代码层面分析，究竟是哪里出现了直接读请求。查看源码文件 app.c，你会发现它果然使用了 ODIRECT 选项打开磁盘，于是绕过了系统缓存，直接对磁盘进行读写。 `open(disk, O_RDONLY|O_DIRECT|O_LARGEFILE, 0755) `直接读写磁盘，对 I/O 敏感型应用（比如数据库系统）是很友好的，因为你可以在应用中，直接控制磁盘的读写。但在大部分情况下，我们最好还是通过系统缓存来优化磁盘 I/O，换句话说，删除 ODIRECT 这个选项就是了。 app-fix1.c https://github.com/feiskyer/linux-perf-examples/blob/master/high-iowait-process/app-fix1.c就是修改后的文件，我也打包成了一个镜像文件，运行下面的命令，你就可以启动它了： `# 首先删除原来的应用 $ docker rm -f app # 运行新的应用 $ docker run --privileged --name=app -itd feisky/app:iowait-fix1 `最后，再用 top 检查一下： `top top - 14:59:32 up 19 min, 1 user, load average: 0.15, 0.07, 0.05 Tasks: 137 total, 1 running, 72 sleeping, 0 stopped, 12 zombie %Cpu0 : 0.0 us, 1.7 sy, 0.0 ni, 98.0 id, 0.3 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 : 0.0 us, 1.3 sy, 0.0 ni, 98.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st ... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3084 root 20 0 0 0 0 Z 1.3 0.0 0:00.04 app 3085 root 20 0 0 0 0 Z 1.3 0.0 0:00.04 app 1 root 20 0 159848 9120 6724 S 0.0 0.1 0:09.03 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root 20 0 0 0 0 I 0.0 0.0 0:00.40 kworker/0:0 ... `你会发现， iowait 已经非常低了，只有 0.3%，说明刚才的改动已经成功修复了 iowait 高的问题，大功告成！不过，别忘了，僵尸进程还在等着你。仔细观察僵尸进程的数量，你会郁闷地发现，僵尸进程还在不断的增长中。 僵尸进程接下来，我们就来处理僵尸进程的问题。既然僵尸进程是因为父进程没有回收子进程的资源而出现的，那么，要解决掉它们，就要找到它们的根儿，也就是找出父进程，然后在父进程里解决。 父进程的找法我们前面讲过，最简单的就是运行 pstree 命令： `# -a 表示输出命令行选项 # p 表 PID # s 表示指定进程的父进程 $ pstree -aps 3084 systemd,1 └─dockerd,15006 -H fd:// └─docker-containe,15024 --config /var/run/docker/containerd/containerd.toml └─docker-containe,3991 -namespace moby -workdir... └─app,4009 └─(app,3084) `运行完，你会发现 3084 号进程的父进程是 4009，也就是 app 应用。 所以，我们接着查看 app 应用程序的代码，看看子进程结束的处理是否正确，比如有没有调用 wait() 或 waitpid() ，抑或是，有没有注册 SIGCHLD 信号的处理函数。 现在我们查看修复 iowait 后的源码文件 app-fix1.chttps://github.com/feiskyer/linux-perf-examples/blob/master/high-iowait-process/app-fix1.c ，找到子进程的创建和清理的地方： `int status = 0; for (;;) { for (int i = 0; i &lt; 2; i++) { if(fork()== 0) { sub_process(); } } sleep(5); } while(wait(&amp;status)&gt;0); ` 循环语句本来就容易出错，你能找到这里的问题吗？这段代码虽然看起来调用了 wait() 函数等待子进程结束，但却错误地把 wait() 放到了 for 死循环的外面，也就是说，wait() 函数实际上并没被调用到，我们把它挪到 for 循环的里面就可以了。 修改后的文件我放到了 app-fix2.c https://github.com/feiskyer/linux-perf-examples/blob/master/high-iowait-process/app-fix2.c中，也打包成了一个 Docker 镜像，运行下面的命令，你就可以启动它： `# 先停止产生僵尸进程的 app $ docker rm -f app # 然后启动新的 app $ docker run --privileged --name=app -itd feisky/app:iowait-fix2 `启动后，再用 top 最后来检查一遍： `top top - 15:00:44 up 20 min, 1 user, load average: 0.05, 0.05, 0.04 Tasks: 125 total, 1 running, 72 sleeping, 0 stopped, 0 zombie %Cpu0 : 0.0 us, 1.7 sy, 0.0 ni, 98.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 : 0.0 us, 1.3 sy, 0.0 ni, 98.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st ... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3198 root 20 0 4376 840 780 S 0.3 0.0 0:00.01 app 2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd 3 root 20 0 0 0 0 I 0.0 0.0 0:00.41 kworker/0:0 ... `好了，僵尸进程（Z 状态）没有了， iowait 也是 0，问题终于全部解决了。 小结 今天我用一个多进程的案例，带你分析系统等待 I/O 的 CPU 使用率（也就是 iowait%）升高的情况。 虽然这个案例是磁盘 I/O 导致了 iowait 升高，不过， iowait 高不一定代表 I/O 有性能瓶颈。当系统中只有 I/O 类型的进程在运行时，iowait 也会很高，但实际上，磁盘的读写远没有达到性能瓶颈的程度。 因此，碰到 iowait 升高时，需要先用 dstat、pidstat 等工具，确认是不是磁盘 I/O 的问题，然后再找是哪些进程导致了 I/O。 等待 I/O 的进程一般是不可中断状态，所以用 ps 命令找到的 D 状态（即不可中断状态）的进程，多为可疑进程。但这个案例中，在 I/O 操作后，进程又变成了僵尸进程，所以不能用 strace 直接分析这个进程的系统调用。 这种情况下，我们用了 perf 工具，来分析系统的 CPU 时钟事件，最终发现是直接 I/O 导致的问题。这时，再检查源码中对应位置的问题，就很轻松了。 而僵尸进程的问题相对容易排查，使用 pstree 找出父进程后，去查看父进程的代码，检查 wait() / waitpid() 的调用，或是 SIGCHLD 信号处理函数的注册就行了。","categories":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/categories/CPU/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/tags/CPU/"}]},{"title":"产业互联网时代的企业数字化","slug":"产业互联网时代的企业数字化","date":"2019-09-08T01:20:45.000Z","updated":"2019-09-08T13:14:27.365Z","comments":true,"path":"2019/09/08/产业互联网时代的企业数字化/","link":"","permalink":"http://www.ithelei.com/2019/09/08/产业互联网时代的企业数字化/","excerpt":"","text":"企业数字化的主要特征包括3个方面：第一是连接，连接员工、连接客户、连接机器设备；第二是数据，也就是连接之后实时产生的数据；第三是智能，是数据驱动的智能应用。 以阿里巴巴为例，首先，阿里巴巴通过天猫、高德地图、饿了么等业务前端，连接了众多消费者；然后，通过连接产生的实时数据，沉淀了大量的智能服务，例如千人千面的个性化推荐、商家的生意参谋等，以此来帮助企业做品牌推广、商品推荐、精准营销、运行分析等。 产业互联网是时代，企业数字化转型将成为一种趋势。全球知名调研机构IDC此前的一项调查显示，到2018年，全球1000强企业中的67%和中国1000强企业中的50%都把数字化转型作为企业的战略核心。对于传统企业，数字化转型已经不再是一道选择题，而是一道生存题。越来越多的企业将“数字”视为核心资产、新资源和新财富。 随着人工智能、云计算、大数据、机器学习等一系列前沿技术的不断发展、并深入到医疗、制造、安防等传统行业领域，企业数字化转型逐渐在各个行业爆发。中国宏观经济面临下行压力，经济结构的转型升级推动生产要素成本提升，同时激烈的市场竞争、用户多元化消费习惯的养成、行业赢利点的转变等也倒逼企业进行数字化转型。在此背景下，中国涌现出阿里巴巴、腾讯、华为、新华三、信融科技百度等一批优秀的数字化转型实践者，从营销、供应链、生产制造、内部管理等多方面为企业提供数字化转型解决方案。企业数字化转型行业生态初步形成，中国正在逐步成为数字化变革的引领者， 未来 3~5年 ，企业数字化将成为中国企业普及化应用。","categories":[{"name":"产业互联网","slug":"产业互联网","permalink":"http://www.ithelei.com/categories/产业互联网/"}],"tags":[{"name":"产业互联网","slug":"产业互联网","permalink":"http://www.ithelei.com/tags/产业互联网/"}]},{"title":"中台成为构架企业数字营销的主要模式","slug":"中台成为构架企业数字营销的主要模式","date":"2019-09-08T01:20:45.000Z","updated":"2019-09-08T14:51:07.944Z","comments":true,"path":"2019/09/08/中台成为构架企业数字营销的主要模式/","link":"","permalink":"http://www.ithelei.com/2019/09/08/中台成为构架企业数字营销的主要模式/","excerpt":"","text":"在产业互联网时代，当数字化成为企业的核心战略后，如何实现业务数据化?如何使数据赋能企业推动业务转型升级?如何提升企业数字资产的价值?这些都成为制约企业发展的难题。在此背景下，数字中台成为指导企业数字化转型、实现数字营销的主流方法。 数字中台是基于企业级互联网及大数据架构打造的数字化创新平台，包含业务中台和数据中台。 一方面，数字中台可以在云厂商提供的运行机制和基础架构之上,支撑企业营销业务应用的标准化及快速定制化,同时为企业提供大数据,数据采集、清洗、管理和分析能力。实现数据精细化运营。数据中台可以将企业内外割裂的数据进行汇聚、治理、建模加工，消除数据孤岛实现数据资产化，为企业提供客户立体画像、商品智能推荐、业务实时监控，助力企业实现数据驱动业务。 另一方面，业务中台不仅可以将原本不同系统相同功能的服务聚合起来，统一标准，统一规范，统一出口，实现企业业务的整合;还可以通过服务的聚合实现资源与能力共享，支撑新应用与新业务的快速开发与跌代，以满足快速变化的用户需求。 数字中台模式是将共性业务服务和技术予以沉淀，避免相同功能重复建设和维护带来的资源浪费。集合了技术和产品能力的业务中台能快速，低成本地完成业务创新。数据中台则能实现数据资源的共享。未来，全面建立一个服务化架构的数字中台将会成为传统大型企业全面数字化转型的最佳解决方案，甚至成为未来数字营销的主导方案。同时，企业数字中台将朝着跨终端、全渠道、全域运营方向发展，基于云原生技术实现中台弹性扩容，依靠平台能力为各个系统产品输出统一管理能力，帮助企业实现业务数据化、数据业务化，赋能企业智能化营销。","categories":[{"name":"中台","slug":"中台","permalink":"http://www.ithelei.com/categories/中台/"}],"tags":[{"name":"中台","slug":"中台","permalink":"http://www.ithelei.com/tags/中台/"}]},{"title":"数字营销是企业数字化转型的重要突破口","slug":"数字营销是企业数字化转型的重要突破口","date":"2019-09-08T01:20:45.000Z","updated":"2019-09-08T14:12:57.377Z","comments":true,"path":"2019/09/08/数字营销是企业数字化转型的重要突破口/","link":"","permalink":"http://www.ithelei.com/2019/09/08/数字营销是企业数字化转型的重要突破口/","excerpt":"","text":"企业数字化涉及企业的方方面面，我们可以从企业连接的对象来划分涉及的领域，具体可以分为数字营销、数字管理、工业大数据。其中： 连接消费者或客户，从企业的商品到消费者或客户的过程属于营销，连接的是企业的消费者或客户。营销的数字化，归结为数字营销领域。 连接员工，企业从订单到生产计划的过程属于企业内部管理，连接的是员工，让所有的员工在链路上协同，这是ERP管理的范畴。内部管理的数字化，属于数字管理领域。 连接设备和产品，生产计划下达后，从生产计划到MES系统生产线的过程连接的是生产设备。比如每一台设备怎么去生产，每道工序中给每一个产品拍照片，然后通过数据解析来控制质量、工艺水平等。生产部分的数字化，属于工业大数据领域。 其中，数字营销（ERP）领域，应用已经比较成熟；工业大数据领域的应用还处于热点期，部分企业也在尝试，这个领域范畴大且难，大部分企业还在观望；相对其他两个领域，数字营销是一个新的领域，很多企业都没有做过，这是互联网企业比较看好且容易出效率。出价值的领域是企业数字化转型的突破口。 数字营销，用“技术+数据” 助力企业业务提升数字营销是以“技术+数据为双驱动，对传统营销进行互联网化、数字化和智能化改造，进而帮助企业构建消费者全渠道触达，实现精准互动和交易的过程” 其本质是借助数据、算法以及营销资源、依靠实时数据跟踪、实现营销由粗放集约发展；依靠中台的强大连接能力，实现渠道从单一向多元化发展；内容策划和投放依靠数据算法的预测，从经验决策变为智能决策。最终帮助企业实现营销资源利用高效，推广费用大幅降低。 数字营销是实现以消费者为需求核心的数字化体验创新，也是最终实现面向最终客户体验的触点创新。数字营销强调的是对新技术的运用、互联网业务逻辑的分析能力。数字营销赋予了营销组合新的内涵，是数字经济时代企业的主流营销方式和发展趋势。 企业做数字营销的目的或者价值是什么？收入增长。阿里的使命是“让天下没有难做的生意”。信融科技引领企业数字化创新，助力企业业务提升","categories":[{"name":"数字营销","slug":"数字营销","permalink":"http://www.ithelei.com/categories/数字营销/"}],"tags":[{"name":"数字营销","slug":"数字营销","permalink":"http://www.ithelei.com/tags/数字营销/"}]},{"title":"和阿里云技术人员讨论方案","slug":"阿里讨论技术方案","date":"2019-09-05T01:20:45.000Z","updated":"2019-09-15T13:48:42.034Z","comments":true,"path":"2019/09/05/阿里讨论技术方案/","link":"","permalink":"http://www.ithelei.com/2019/09/05/阿里讨论技术方案/","excerpt":"","text":"了解最前沿的技术,并实施落地。","categories":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/categories/峰会/"}],"tags":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/tags/峰会/"}]},{"title":"某个应用的CPU使用率居然打满,我该怎么办？","slug":"CPU使用率居然打满","date":"2019-09-02T01:20:45.000Z","updated":"2019-09-08T11:54:18.694Z","comments":true,"path":"2019/09/02/CPU使用率居然打满/","link":"","permalink":"http://www.ithelei.com/2019/09/02/CPU使用率居然打满/","excerpt":"","text":"CPU 使用率是单位时间内 CPU 使用情况的统计，以百分比的方式展示。那么，作为最常用也是最熟悉的 CPU 指标，你能说出 CPU 使用率到底是怎么算出来的吗？再有，诸如 top、ps 之类的性能工具展示的 %user、%nice、 %system、%iowait 、%steal 等等 CPU 使用率在上一篇文章我曾提到，Linux 作为一个多任务操作系统，将每个 CPU 的时间划分为很短的时间片，再通过调度器轮流分配给各个任务使用，因此造成多任务同时运行的错觉。 为了维护 CPU 时间，Linux 通过事先定义的节拍率（内核中表示为 HZ），触发时间中断，并使用全局变量 Jiffies 记录了开机以来的节拍数。每发生一次时间中断，Jiffies 的值就加 1。 节拍率 HZ 是内核的可配选项，可以设置为 100、250、1000 等。不同的系统可能设置不同数值，你可以通过查询 /boot/config 内核选项来查看它的配置值。比如在我的系统中，节拍率设置成了 250，也就是每秒钟触发 250 次时间中断。 `grep &apos;CONFIG_HZ=&apos; /boot/config-$(uname -r) CONFIG_HZ=250 `同时，正因为节拍率 HZ 是内核选项，所以用户空间程序并不能直接访问。为了方便用户空间程序，内核还提供了一个用户空间节拍率 USERHZ，它总是固定为 100，也就是 1/100 秒。这样，用户空间程序并不需要关心内核中 HZ 被设置成了多少，因为它看到的总是固定值 USERHZ。 Linux 通过 /proc 虚拟文件系统，向用户空间提供了系统内部状态的信息，而 /proc/stat 提供的就是系统的 CPU 和任务统计信息。比方说，如果你只关注 CPU 的话，可以执行下面的命令： `# 只保留各个 CPU 的数据 $ cat /proc/stat | grep ^cpu cpu 280580 7407 286084 172900810 83602 0 583 0 0 0 cpu0 144745 4181 176701 86423902 52076 0 301 0 0 0 cpu1 135834 3226 109383 86476907 31525 0 282 0 0 0 `这里的输出结果是一个表格。其中，第一列表示的是 CPU 编号，如 cpu0、cpu1 ，而第一行没有编号的 cpu ，表示的是所有 CPU 的累加。其他列则表示不同场景下 CPU 的累加节拍数，它的单位是 USERHZ，也就是 10 ms（1/100 秒），所以这其实就是不同场景下的 CPU 时间。 当然，这里每一列都要记住，有需要的时候，查询 man proc 就可以。不过，你要清楚 man proc 文档里每一列的涵义，它们都是 CPU 使用率相关的重要指标，你还会在很多其他的性能工具中看到它们。下面，我来依次解读一下。 user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。 nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。 system（通常缩写为 sys），代表内核态 CPU 时间。 idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）。 iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间。 irq（通常缩写为 hi），代表处理硬中断的 CPU 时间。 softirq（通常缩写为 si），代表处理软中断的 CPU 时间。 steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。 guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。 guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间。 而我们通常所说的CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时间的百分比，用公式来表示就是： 根据这个公式，我们就可以从 /proc/stat 中的数据，很容易地计算出 CPU 使用率。当然，也可以用每一个场景的 CPU 时间，除以总的 CPU 时间，计算出每个场景的 CPU 使用率。 不过先不要着急计算，你能说出，直接用 /proc/stat 的数据，算的是什么时间段的 CPU 使用率吗？ 看到这里，你应该想起来了，这是开机以来的节拍数累加值，所以直接算出来的，是开机以来的平均 CPU 使用率，一般没啥参考价值。 事实上，为了计算 CPU 使用率，性能工具一般都会取间隔一段时间（比如 3 秒）的两次值，作差后，再计算出这段时间内的平均 CPU 使用率，即 这个公式，就是我们用各种性能工具所看到的 CPU 使用率的实际计算方法。 现在，我们知道了系统 CPU 使用率的计算方法，那进程的呢？跟系统的指标类似，Linux 也给每个进程提供了运行情况的统计信息，也就是 /proc/[pid]/stat。不过，这个文件包含的数据就比较丰富了，总共有 52 列的数据。 当然，不用担心，因为你并不需要掌握每一列的含义。还是那句话，需要的时候，查 man proc 就行。 回过头来看，是不是说要查看 CPU 使用率，就必须先读取 /proc/stat 和 /proc/[pid]/stat 这两个文件，然后再按照上面的公式计算出来呢？ 当然不是，各种各样的性能分析工具已经帮我们计算好了。不过要注意的是，性能分析工具给出的都是间隔一段时间的平均 CPU 使用率，所以要注意间隔时间的设置，特别是用多个工具对比分析时，你一定要保证它们用的是相同的间隔时间。 比如，对比一下 top 和 ps 这两个工具报告的 CPU 使用率，默认的结果很可能不一样，因为 top 默认使用 3 秒时间间隔，而 ps 使用的却是进程的整个生命周期。 怎么查看 CPU 使用率知道了 CPU 使用率的含义后，我们再来看看要怎么查看 CPU 使用率。说到查看 CPU 使用率的工具，我猜你第一反应肯定是 top 和 ps。的确，top 和 ps 是最常用的性能分析工具： top 显示了系统总体的 CPU 和内存使用情况，以及各个进程的资源使用情况。 ps 则只显示了每个进程的资源使用情况。 比如，top 的输出格式为： `# 默认每 3 秒刷新一次 $ top top - 11:58:59 up 9 days, 22:47, 1 user, load average: 0.03, 0.02, 0.00 Tasks: 123 total, 1 running, 72 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 8169348 total, 5606884 free, 334640 used, 2227824 buff/cache KiB Swap: 0 total, 0 free, 0 used. 7497908 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 78088 9288 6696 S 0.0 0.1 0:16.83 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.05 kthreadd 4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/0:0H ... `这个输出结果中，第三行 %Cpu 就是系统的 CPU 使用率，具体每一列的含义上一节都讲过，只是把 CPU 时间变换成了 CPU 使用率，我就不再重复讲了。不过需要注意，top 默认显示的是所有 CPU 的平均值，这个时候你只需要按下数字 1 ，就可以切换到每个 CPU 的使用率了。 继续往下看，空白行之后是进程的实时信息，每个进程都有一个 %CPU 列，表示进程的 CPU 使用率。它是用户态和内核态 CPU 使用率的总和，包括进程用户空间使用的 CPU、通过系统调用执行的内核空间 CPU 、以及在就绪队列等待运行的 CPU。在虚拟化环境中，它还包括了运行虚拟机占用的 CPU。 所以，到这里我们可以发现， top 并没有细分进程的用户态 CPU 和内核态 CPU。那要怎么查看每个进程的详细情况呢？你应该还记得上一节用到的 pidstat 吧，它正是一个专门分析每个进程 CPU 使用情况的工具。 比如，下面的 pidstat 命令，就间隔 1 秒展示了进程的 5 组 CPU 使用率，包括： 用户态 CPU 使用率 （%usr）； 内核态 CPU 使用率（%system）； 运行虚拟机 CPU 使用率（%guest）； 等待 CPU 使用率（%wait）； 以及总的 CPU 使用率（%CPU） 最后的 Average 部分，还计算了 5 组数据的平均值。 `# 每隔 1 秒输出一组数据，共输出 5 组 $ pidstat 1 5 15:56:02 UID PID %usr %system %guest %wait %CPU CPU Command 15:56:03 0 15006 0.00 0.99 0.00 0.00 0.99 1 dockerd ... Average: UID PID %usr %system %guest %wait %CPU CPU Command Average: 0 15006 0.00 0.99 0.00 0.00 0.99 - dockerd `CPU 使用率过高怎么办？通过 top、ps、pidstat 等工具，你能够轻松找到 CPU 使用率较高（比如 100% ）的进程。接下来，你可能又想知道，占用 CPU 的到底是代码里的哪个函数呢？找到它，你才能更高效、更针对性地进行优化。 我猜你第一个想到的，应该是 GDB（The GNU Project Debugger）， 这个功能强大的程序调试利器。的确，GDB 在调试程序错误方面很强大。但是，我又要来“挑刺”了。请你记住，GDB 并不适合在性能分析的早期应用。 为什么呢？因为 GDB 调试程序的过程会中断程序运行，这在线上环境往往是不允许的。所以，GDB 只适合用在性能分析的后期，当你找到了出问题的大致函数后，线下再借助它来进一步调试函数内部的问题。 那么哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf。perf 是 Linux 2.6.31 以后内置的性能分析工具。它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。 使用 perf 分析 CPU 性能问题，我来说两种最常见、也是我最喜欢的用法。 第一种常见用法是 perf top，类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数，使用界面如下所示： `perf top Samples: 833 of event &apos;cpu-clock&apos;, Event count (approx.): 97742399 Overhead Shared Object Symbol 7.28% perf [.] 0x00000000001f78a4 4.72% [kernel] [k] vsnprintf 4.32% [kernel] [k] module_get_kallsym 3.65% [kernel] [k] _raw_spin_unlock_irqrestore ... `输出结果中，第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数量（Event count）。比如这个例子中，perf 总共采集了 833 个 CPU 时钟事件，而总事件数则为 97742399。 另外，采样数需要我们特别注意。如果采样数过少（比如只有十几个），那下面的排序和百分比就没什么实际参考价值了。 再往下看是一个表格式样的数据，每一行包含四列，分别是： 第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示。 第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等。 第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间。 最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。 还是以上面的输出为例，我们可以看到，占用 CPU 时钟最多的是 perf 工具自身，不过它的比例也只有 7.28%，说明系统并没有 CPU 性能问题。 perf top 的使用你应该很清楚了吧。 接着再来看第二种常见用法，也就是 perf record 和 perf report。 perf top 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。而 perf record 则提供了保存数据的功能，保存后的数据，需要你用 perf report 解析展示。 `perf record # 按 Ctrl+C 终止采样 [ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.452 MB perf.data (6093 samples) ] $ perf report # 展示类似于 perf top 的报告 `在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。 案例下面我们就以 Nginx + PHP 的 Web 服务为例，来看看当你发现 CPU 使用率过高的问题后，要怎么使用 top 等工具找出异常的进程，又要怎么利用 perf 找出引发性能问题的函数。 准备以下案例基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。我使用的案例环境如下所示： 机器配置：2 CPU，8GB 内存 预先安装 docker、sysstat、perf、ab 等工具，如 apt install docker.io sysstat linux-tools-common apache2-utils 我先简单介绍一下这次新使用的工具 ab。ab（apache bench）是一个常用的 HTTP 服务性能测试工具，这里用来模拟 Ngnix 的客户端。由于 Nginx 和 PHP 的配置比较麻烦，我把它们打包成了两个 Docker 镜像https://github.com/feiskyer/linux-perf-examples/tree/master/nginx-high-cpu，这样只需要运行两个容器，就可以得到模拟环境。 注意，这个案例要用到两台虚拟机，如下图所示： 其中一台用作 Web 服务器，来模拟性能问题；另一台用作 Web 服务器的客户端，来给 Web 服务增加压力请求。使用两台虚拟机是为了相互隔离，避免“交叉感染”。 接下来，我们打开两个终端，分别 SSH 登录到两台机器上，并安装上面提到的工具。 还是同样的“配方”。下面的所有命令，都默认假设以 root 用户运行，如果你是普通用户身份登陆系统，一定要先运行 sudo su root 命令切换到 root 用户。到这里，准备工作就完成了。 不过，操作之前，我还想再说一点。这次案例中 PHP 应用的核心逻辑比较简单，大部分人一眼就可以看出问题，但你要知道，实际生产环境中的源码就复杂多了。 所以，我希望你在按照步骤操作之前，先不要查看源码（避免先入为主），而是把它当成一个黑盒来分析。这样，你可以更好地理解整个解决思路，怎么从系统的资源使用问题出发，分析出瓶颈所在的应用、以及瓶颈在应用中的大概位置。 操作和分析接下来，我们正式进入操作环节。 首先，在第一个终端执行下面的命令来运行 Nginx 和 PHP 应用： `docker run --name nginx -p 10000:80 -itd feisky/nginx $ docker run --name phpfpm -itd --network container:nginx feisky/php-fpm `然后，在第二个终端使用 curl 访问 http://[VM1 的 IP]:10000，确认 Nginx 已正常启动。你应该可以看到 It works! 的响应。 `# 192.168.0.10 是第一台虚拟机的 IP 地址 $ curl http://192.168.0.10:10000/ It works! `接着，我们来测试一下这个 Nginx 服务的性能。在第二个终端运行下面的 ab 命令： `# 并发 10 个请求测试 Nginx 性能，总共测试 100 个请求 $ ab -c 10 -n 100 http://192.168.0.10:10000/ This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, ... Requests per second: 11.63 [#/sec] (mean) Time per request: 859.942 [ms] (mean) ... `从 ab 的输出结果我们可以看到，Nginx 能承受的每秒平均请求数只有 11.63。，这也太差了吧。那到底是哪里出了问题呢？我们用 top 和 pidstat 再来观察下。 这次，我们在第二个终端，将测试的请求总数增加到 10000。这样当你在第一个终端使用性能分析工具时， Nginx 的压力还是继续。 继续在第二个终端，运行 ab 命令： `ab -c 10 -n 10000 http://10.240.0.5:10000/ `接着，回到第一个终端运行 top 命令，并按下数字 1 ，切换到每个 CPU 的使用率： `top ... %Cpu0 : 98.7 us, 1.3 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 : 99.3 us, 0.7 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st ... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 21514 daemon 20 0 336696 16384 8712 R 41.9 0.2 0:06.00 php-fpm 21513 daemon 20 0 336696 13244 5572 R 40.2 0.2 0:06.08 php-fpm 21515 daemon 20 0 336696 16384 8712 R 40.2 0.2 0:05.67 php-fpm 21512 daemon 20 0 336696 13244 5572 R 39.9 0.2 0:05.87 php-fpm 21516 daemon 20 0 336696 16384 8712 R 35.9 0.2 0:05.61 php-fpm `这里可以看到，系统中有几个 php-fpm 进程的 CPU 使用率加起来接近 200%；而每个 CPU 的用户使用率（us）也已经超过了 98%，接近饱和。这样，我们就可以确认，正是用户空间的 php-fpm 进程，导致 CPU 使用率骤升。 那再往下走，怎么知道是 php-fpm 的哪个函数导致了 CPU 使用率升高呢？我们来用 perf 分析一下。在第一个终端运行下面的 perf 命令： `# -g 开启调用关系分析，-p 指定 php-fpm 的进程号 21515 $ perf top -g -p 21515 `按方向键切换到 php-fpm，再按下回车键展开 php-fpm 的调用关系，你会发现，调用关系最终到了 sqrt 和 addfunction。看来，我们需要从这两个函数入手了。 我们拷贝出 Nginx 应用的源码，看看是不是调用了这两个函数： `# 从容器 phpfpm 中将 PHP 源码拷贝出来 $ docker cp phpfpm:/app . # 使用 grep 查找函数调用 $ grep sqrt -r app/ # 找到了 sqrt 调用 app/index.php: $x += sqrt($x); $ grep add_function -r app/ # 没找到 add_function 调用，这其实是 PHP 内置函数 `OK，原来只有 sqrt 函数在 app/index.php 文件中调用了。那最后一步，我们就该看看这个文件的源码了： `cat app/index.php &lt;?php // test only. $x = 0.0001; for ($i = 0; $i &lt;= 1000000; $i++) { $x += sqrt($x); } echo &quot;It works!&quot; `呀，有没有发现问题在哪里呢？我想你要笑话我了，居然犯了一个这么傻的错误，测试代码没删就直接发布应用了。为了方便你验证优化后的效果，我把修复后的应用也打包成了一个 Docker 镜像，你可以在第一个终端中执行下面的命令来运行它： `# 停止原来的应用 $ docker rm -f nginx phpfpm # 运行优化后的应用 $ docker run --name nginx -p 10000:80 -itd feisky/nginx:cpu-fix $ docker run --name phpfpm -itd --network container:nginx feisky/php-fpm:cpu-fix `接着，到第二个终端来验证一下修复后的效果。首先 Ctrl+C 停止之前的 ab 命令后，再运行下面的命令： `ab -c 10 -n 10000 http://10.240.0.5:10000/ ... Complete requests: 10000 Failed requests: 0 Total transferred: 1720000 bytes HTML transferred: 90000 bytes Requests per second: 2237.04 [#/sec] (mean) Time per request: 4.470 [ms] (mean) Time per request: 0.447 [ms] (mean, across all concurrent requests) Transfer rate: 375.75 [Kbytes/sec] received ... `从这里你可以发现，现在每秒的平均请求数，已经从原来的 11 变成了 2237。 你看，就是这么很傻的一个小问题，却会极大的影响性能，并且查找起来也并不容易吧。当然，找到问题后，解决方法就简单多了，删除测试代码就可以了。 小结CPU 使用率是最直观和最常用的系统性能指标，更是我们在排查性能问题时，通常会关注的第一个指标。所以我们更要熟悉它的含义，尤其要弄清楚用户（%user）、Nice（%nice）、系统（%system） 、等待 I/O（%iowait） 、中断（%irq）以及软中断（%softirq）这几种不同 CPU 的使用率。比如说： 用户 CPU 和 Nice CPU 高，说明用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题。 系统 CPU 高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。 I/O 等待 CPU 高，说明等待 I/O 的时间比较长，所以应该着重排查系统存储是不是出现了 I/O 问题。 软中断和硬中断高，说明软中断或硬中断的处理程序占用了较多的 CPU，所以应该着重排查内核中的中断服务程序。 碰到 CPU 使用率升高的问题，你可以借助 top、pidstat 等工具，确认引发 CPU 性能问题的来源；再使用 perf 等工具，排查出引起性能问题的具体函数。","categories":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/categories/CPU/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/tags/CPU/"}]},{"title":"传统xml配置方式","slug":"传统xml配置方式","date":"2019-09-02T01:20:45.000Z","updated":"2019-09-03T15:00:41.043Z","comments":true,"path":"2019/09/02/传统xml配置方式/","link":"","permalink":"http://www.ithelei.com/2019/09/02/传统xml配置方式/","excerpt":"","text":"idea传统xml配置方式新建项目 pom.xml `&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.javaboy&lt;/groupId&gt; &lt;artifactId&gt;xmlssm&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; `依赖: applicationContext.xml `&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;org.javaboy&quot; use-default-filters=&quot;true&quot;&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;/context:component-scan&gt; &lt;/beans&gt;`spring-servlet.xml `&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt; &lt;!--springmvc容器 是spring的子容器 springmvc可以访问spring容器的东西。--&gt; &lt;context:component-scan base-package=&quot;org.javaboy&quot; use-default-filters=&quot;false&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;/context:component-scan&gt; &lt;mvc:annotation-driven/&gt; &lt;/beans&gt;`web.xml `&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; `HelloController `package org.javaboy.controller; import org.javaboy.service.HelloService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.Mapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; /** * */ @RestController public class HelloController { @Autowired HelloService helloService ; @RequestMapping(method = RequestMethod.GET) public String hello(){ return helloService.sayhello(); } } `HelloService `package org.javaboy.service; import org.springframework.stereotype.Service; @Service public class HelloService { public String sayhello(){ return &quot;ithelei&quot;; } } `","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.ithelei.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.ithelei.com/tags/SpringBoot/"}]},{"title":"京东云崔牛会","slug":"京东云崔牛会","date":"2019-09-01T01:20:45.000Z","updated":"2019-09-15T13:19:10.187Z","comments":true,"path":"2019/09/01/京东云崔牛会/","link":"","permalink":"http://www.ithelei.com/2019/09/01/京东云崔牛会/","excerpt":"","text":"（北京大兴）亦庄经济技术开发区科创十一街18号院京东集团总部 技术为更好","categories":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/categories/峰会/"}],"tags":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/tags/峰会/"}]},{"title":"方总云市场会议","slug":"方总云市场会议","date":"2019-09-01T01:20:45.000Z","updated":"2019-09-15T14:15:16.161Z","comments":true,"path":"2019/09/01/方总云市场会议/","link":"","permalink":"http://www.ithelei.com/2019/09/01/方总云市场会议/","excerpt":"","text":"科技为更好","categories":[{"name":"会议","slug":"会议","permalink":"http://www.ithelei.com/categories/会议/"}],"tags":[{"name":"会议","slug":"会议","permalink":"http://www.ithelei.com/tags/会议/"}]},{"title":"经常说的-CPU-上下文切换是什么意思？（上）","slug":"经常说的-CPU-上下文切换是什么意思？（上）","date":"2019-09-01T01:20:45.000Z","updated":"2019-09-01T11:47:28.043Z","comments":true,"path":"2019/09/01/经常说的-CPU-上下文切换是什么意思？（上）/","link":"","permalink":"http://www.ithelei.com/2019/09/01/经常说的-CPU-上下文切换是什么意思？（上）/","excerpt":"","text":"理解平均负载（ Load Average），并用三个案例展示了不同场景下平均负载升高的分析方法。这其中，多个进程竞争 CPU 就是一个经常被我们忽视的问题。我想你一定很好奇，进程在竞争 CPU 的时候并没有真正运行，为什么还会导致系统的负载升高呢？看到今天的主题，你应该已经猜到了，CPU 上下文切换就是罪魁祸首。 我们都知道，Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。 而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好CPU 寄存器和程序计数器（Program Counter，PC）。 CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做CPU 上下文。 知道了什么是 CPU 上下文，我想你也很容易理解 CPU 上下文切换。CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。 而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。 我猜肯定会有人说，CPU 上下文切换无非就是更新了 CPU 寄存器的值嘛，但这些寄存器，本身就是为了快速运行任务而设计的，为什么会影响系统的 CPU 性能呢？ 在回答这个问题前，不知道你有没有想过，操作系统管理的这些“任务”到底是什么呢？CPU 寄存器也许你会说，任务就是进程，或者说任务就是线程。是的，进程和线程正是最常见的任务。但是除此之外，还有没有其他的任务呢？ 不要忘了，硬件通过触发信号，会导致中断处理程序的调用，也是一种常见的任务。 所以，根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。 进程上下文切换Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。 内核空间（Ring 0）具有最高权限，可以直接访问所有资源； 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。 换个角度看，也就是说，进程既可以在用户空间运行，又可以在内核空间中运行。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。 从用户态到内核态的转变，需要通过系统调用来完成。比如，当我们查看文件内容时，就需要多次系统调用来完成：首先调用 open() 打开文件，然后调用 read() 读取文件内容，并调用 write() 将内容写到标准输出，最后再调用 close() 关闭文件。 那么，系统调用的过程有没有发生 CPU 上下文的切换呢？答案自然是肯定的。 CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。 而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。 不过，需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的： 进程上下文切换，是指从一个进程切换到另一个进程运行。 而系统调用过程中一直是同一个进程在运行。 所以，系统调用过程通常称为特权模式切换，而不是上下文切换。但实际上，系统调用过程中，CPU 的上下文切换还是无法避免的。 那么，进程上下文切换跟系统调用又有什么区别呢？ 首先，你需要知道，进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。 因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。 如下图所示，保存上下文和恢复上下文的过程并不是“免费”的，需要内核在 CPU 上运行才能完成。 根据 Tsuna 的测试报告，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是上一节中我们所讲的，导致平均负载升高的一个重要因素。 另外，我们知道， Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。 知道了进程上下文切换潜在的性能问题后，我们再来看，究竟什么时候会切换进程上下文。 显然，进程切换时才需要切换上下文，换句话说，只有在进程调度的时候，才需要切换上下文。Linux 为每个 CPU 都维护了一个就绪队列，将活跃进程（即正在运行和正在等待 CPU 的进程）按照优先级和等待 CPU 的时间排序，然后选择最需要 CPU 的进程，也就是优先级最高和等待 CPU 时间最长的进程来运行。 那么，进程在什么时候才会被调度到 CPU 上运行呢？ 最容易想到的一个时机，就是进程执行完终止了，它之前使用的 CPU 会释放出来，这个时候再从就绪队列里，拿一个新的进程过来运行。其实还有很多其他场景，也会触发进程调度，在这里我给你逐个梳理下。 其一，为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。 其二，进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。 其三，当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。 其四，当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。 最后一个，发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。 了解这几个场景是非常有必要的，因为一旦出现上下文切换的性能问题，它们就是幕后凶手。 线程上下文切换说完了进程的上下文切换，我们再来看看线程相关的问题。 线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。所以，对于线程和进程，我们可以这么理解： 当进程只有一个线程时，可以认为进程就等于线程。 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。 这么一来，线程的上下文切换其实就可以分为两种情况： 第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 第二种，前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。 到这里你应该也发现了，虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。 中断上下文切换除了前面两种上下文切换，还有一个场景也会切换 CPU 上下文，那就是中断。 为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。 对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。 另外，跟进程上下文切换一样，中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能。所以，当你发现中断次数过多时，就需要注意去排查它是否会给你的系统带来严重的性能问题。 小结总结一下，不管是哪种场景导致的上下文切换，你都应该知道： CPU 上下文切换，是保证 Linux 系统正常工作的核心功能之一，一般情况下不需要我们特别关注。 但过多的上下文切换，会把 CPU 时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，从而缩短进程真正运行的时间，导致系统的整体性能大幅下降。","categories":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/categories/CPU/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/tags/CPU/"}]},{"title":"系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？","slug":"系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？","date":"2019-09-01T01:20:45.000Z","updated":"2019-09-08T11:22:52.115Z","comments":true,"path":"2019/09/01/系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？/","link":"","permalink":"http://www.ithelei.com/2019/09/01/系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？/","excerpt":"","text":"准备本次案例还是基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。我使用的案例环境如下所示： 机器配置：2 CPU，8GB 内存 预先安装 docker、sysstat、perf、ab 等工具，如 apt install docker.iohttps://www.docker.com/ sysstat linux-tools-common apache2-utils ab（apache bench）是一个常用的 HTTP 服务性能测试工具，这里同样用来模拟 Nginx 的客户端。由于 Nginx 和 PHP 的配置比较麻烦，我把它们打包成了两个 Docker https://github.com/feiskyer/linux-perf-examples/tree/master/nginx-short-process镜像，这样只需要运行两个容器，就可以得到模拟环境。 注意，这个案例要用到两台虚拟机，如下图所示： 其中一台用作 Web 服务器，来模拟性能问题；另一台用作 Web 服务器的客户端，来给 Web 服务增加压力请求。使用两台虚拟机是为了相互隔离，避免“交叉感染”。 接下来，我们打开两个终端，分别 SSH 登录到两台机器上，并安装上述工具。 同样注意，下面所有命令都默认以 root 用户运行，如果你是用普通用户身份登陆系统，请运行 sudo su root 命令切换到 root 用户。 走到这一步，准备工作就完成了。接下来，我们正式进入操作环节。 温馨提示：案例中 PHP 应用的核心逻辑比较简单，你可能一眼就能看出问题，但实际生产环境中的源码就复杂多了。所以，我依旧建议，操作之前别看源码，避免先入为主，而要把它当成一个黑盒来分析。这样，你可以更好把握，怎么从系统的资源使用问题出发，分析出瓶颈所在的应用，以及瓶颈在应用中大概的位置。 操作和分析首先，我们在第一个终端，执行下面的命令运行 Nginx 和 PHP 应用： `docker run --name nginx -p 10000:80 -itd feisky/nginx:sp $ docker run --name phpfpm -itd --network container:nginx feisky/php-fpm:sp `然后，在第二个终端，使用 curl 访问 http://[VM1 的 IP]:10000，确认 Nginx 已正常启动。你应该可以看到 It works! 的响应。 `# 192.168.0.10 是第一台虚拟机的 IP 地址 $ curl http://192.168.0.10:10000/ It works! `接着，我们来测试一下这个 Nginx 服务的性能。在第二个终端运行下面的 ab 命令。要注意，与上次操作不同的是，这次我们需要并发 100 个请求测试 Nginx 性能，总共测试 1000 个请求。 `# 并发 100 个请求测试 Nginx 性能，总共测试 1000 个请求 $ ab -c 100 -n 1000 http://192.168.0.10:10000/ This is ApacheBench, Version 2.3 &lt;$Revision: 1706008 $&gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, ... Requests per second: 87.86 [#/sec] (mean) Time per request: 1138.229 [ms] (mean) ... `从 ab 的输出结果我们可以看到，Nginx 能承受的每秒平均请求数，只有 87 多一点，是不是感觉它的性能有点差呀。那么，到底是哪里出了问题呢？我们再用 top 和 pidstat 来观察一下。 这次，我们在第二个终端，将测试的并发请求数改成 5，同时把请求时长设置为 10 分钟（-t 600）。这样，当你在第一个终端使用性能分析工具时， Nginx 的压力还是继续的。 继续在第二个终端运行 ab 命令： `ab -c 5 -t 600 http://192.168.0.10:10000/`然后，我们在第一个终端运行 top 命令，观察系统的 CPU 使用情况： `top ... %Cpu(s): 80.8 us, 15.1 sy, 0.0 ni, 2.8 id, 0.0 wa, 0.0 hi, 1.3 si, 0.0 st ... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 6882 root 20 0 8456 5052 3884 S 2.7 0.1 0:04.78 docker-containe 6947 systemd+ 20 0 33104 3716 2340 S 2.7 0.0 0:04.92 nginx 7494 daemon 20 0 336696 15012 7332 S 2.0 0.2 0:03.55 php-fpm 7495 daemon 20 0 336696 15160 7480 S 2.0 0.2 0:03.55 php-fpm 10547 daemon 20 0 336696 16200 8520 S 2.0 0.2 0:03.13 php-fpm 10155 daemon 20 0 336696 16200 8520 S 1.7 0.2 0:03.12 php-fpm 10552 daemon 20 0 336696 16200 8520 S 1.7 0.2 0:03.12 php-fpm 15006 root 20 0 1168608 66264 37536 S 1.0 0.8 9:39.51 dockerd 4323 root 20 0 0 0 0 I 0.3 0.0 0:00.87 kworker/u4:1 ... `观察 top 输出的进程列表可以发现，CPU 使用率最高的进程也只不过才 2.7%，看起来并不高。 然而，再看系统 CPU 使用率（ %Cpu ）这一行，你会发现，系统的整体 CPU 使用率是比较高的：用户 CPU 使用率（us）已经到了 80%，系统 CPU 为 15.1%，而空闲 CPU （id）则只有 2.8%。 为什么用户 CPU 使用率这么高呢？我们再重新分析一下进程列表，看看有没有可疑进程： docker-containerd 进程是用来运行容器的，2.7% 的 CPU 使用率看起来正常； Nginx 和 php-fpm 是运行 Web 服务的，它们会占用一些 CPU 也不意外，并且 2% 的 CPU 使用率也不算高； 再往下看，后面的进程呢，只有 0.3% 的 CPU 使用率，看起来不太像会导致用户 CPU 使用率达到 80%。 那就奇怪了，明明用户 CPU 使用率都 80% 了，可我们挨个分析了一遍进程列表，还是找不到高 CPU 使用率的进程。看来 top 是不管用了，那还有其他工具可以查看进程 CPU 使用情况吗？不知道你记不记得我们的老朋友 pidstat，它可以用来分析进程的 CPU 使用情况。 接下来，我们还是在第一个终端，运行 pidstat 命令： `# 间隔 1 秒输出一组数据（按 Ctrl+C 结束） $ pidstat 1 ... 04:36:24 UID PID %usr %system %guest %wait %CPU CPU Command 04:36:25 0 6882 1.00 3.00 0.00 0.00 4.00 0 docker-containe 04:36:25 101 6947 1.00 2.00 0.00 1.00 3.00 1 nginx 04:36:25 1 14834 1.00 1.00 0.00 1.00 2.00 0 php-fpm 04:36:25 1 14835 1.00 1.00 0.00 1.00 2.00 0 php-fpm 04:36:25 1 14845 0.00 2.00 0.00 2.00 2.00 1 php-fpm 04:36:25 1 14855 0.00 1.00 0.00 1.00 1.00 1 php-fpm 04:36:25 1 14857 1.00 2.00 0.00 1.00 3.00 0 php-fpm 04:36:25 0 15006 0.00 1.00 0.00 0.00 1.00 0 dockerd 04:36:25 0 15801 0.00 1.00 0.00 0.00 1.00 1 pidstat 04:36:25 1 17084 1.00 0.00 0.00 2.00 1.00 0 stress 04:36:25 0 31116 0.00 1.00 0.00 0.00 1.00 0 atopacctd ... `观察一会儿，你是不是发现，所有进程的 CPU 使用率也都不高啊，最高的 Docker 和 Nginx 也只有 4% 和 3%，即使所有进程的 CPU 使用率都加起来，也不过是 21%，离 80% 还差得远呢！ 最早的时候，我碰到这种问题就完全懵了：明明用户 CPU 使用率已经高达 80%，但我却怎么都找不到是哪个进程的问题。到这里，你也可以想想，你是不是也遇到过这种情况？还能不能再做进一步的分析呢？ 后来我发现，会出现这种情况，很可能是因为前面的分析漏了一些关键信息。你可以先暂停一下，自己往上翻，重新操作检查一遍。或者，我们一起返回去分析 top 的输出，看看能不能有新发现。 现在，我们回到第一个终端，重新运行 top 命令，并观察一会儿： `top top - 04:58:24 up 14 days, 15:47, 1 user, load average: 3.39, 3.82, 2.74 Tasks: 149 total, 6 running, 93 sleeping, 0 stopped, 0 zombie %Cpu(s): 77.7 us, 19.3 sy, 0.0 ni, 2.0 id, 0.0 wa, 0.0 hi, 1.0 si, 0.0 st KiB Mem : 8169348 total, 2543916 free, 457976 used, 5167456 buff/cache KiB Swap: 0 total, 0 free, 0 used. 7363908 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 6947 systemd+ 20 0 33104 3764 2340 S 4.0 0.0 0:32.69 nginx 6882 root 20 0 12108 8360 3884 S 2.0 0.1 0:31.40 docker-containe 15465 daemon 20 0 336696 15256 7576 S 2.0 0.2 0:00.62 php-fpm 15466 daemon 20 0 336696 15196 7516 S 2.0 0.2 0:00.62 php-fpm 15489 daemon 20 0 336696 16200 8520 S 2.0 0.2 0:00.62 php-fpm 6948 systemd+ 20 0 33104 3764 2340 S 1.0 0.0 0:00.95 nginx 15006 root 20 0 1168608 65632 37536 S 1.0 0.8 9:51.09 dockerd 15476 daemon 20 0 336696 16200 8520 S 1.0 0.2 0:00.61 php-fpm 15477 daemon 20 0 336696 16200 8520 S 1.0 0.2 0:00.61 php-fpm 24340 daemon 20 0 8184 1616 536 R 1.0 0.0 0:00.01 stress 24342 daemon 20 0 8196 1580 492 R 1.0 0.0 0:00.01 stress 24344 daemon 20 0 8188 1056 492 R 1.0 0.0 0:00.01 stress 24347 daemon 20 0 8184 1356 540 R 1.0 0.0 0:00.01 stress ... `这次从头开始看 top 的每行输出，咦？Tasks 这一行看起来有点奇怪，就绪队列中居然有 6 个 Running 状态的进程（6 running），是不是有点多呢？ 回想一下 ab 测试的参数，并发请求数是 5。再看进程列表里， php-fpm 的数量也是 5，再加上 Nginx，好像同时有 6 个进程也并不奇怪。但真的是这样吗？ 再仔细看进程列表，这次主要看 Running（R） 状态的进程。你有没有发现， Nginx 和所有的 php-fpm 都处于 Sleep（S）状态，而真正处于 Running（R）状态的，却是几个 stress 进程。这几个 stress 进程就比较奇怪了，需要我们做进一步的分析。 我们还是使用 pidstat 来分析这几个进程，并且使用 -p 选项指定进程的 PID。首先，从上面 top 的结果中，找到这几个进程的 PID。比如，先随便找一个 24344，然后用 pidstat 命令看一下它的 CPU 使用情况： `pidstat -p 24344 16:14:55 UID PID %usr %system %guest %wait %CPU CPU Command `奇怪，居然没有任何输出。难道是 pidstat 命令出问题了吗？之前我说过，在怀疑性能工具出问题前，最好还是先用其他工具交叉确认一下。那用什么工具呢？ ps 应该是最简单易用的。我们在终端里运行下面的命令，看看 24344 进程的状态： `# 从所有进程中查找 PID 是 24344 的进程 $ ps aux | grep 24344 root 9628 0.0 0.0 14856 1096 pts/0 S+ 16:15 0:00 grep --color=auto 24344 `还是没有输出。现在终于发现问题，原来这个进程已经不存在了，所以 pidstat 就没有任何输出。既然进程都没了，那性能问题应该也跟着没了吧。我们再用 top 命令确认一下： `top ... %Cpu(s): 80.9 us, 14.9 sy, 0.0 ni, 2.8 id, 0.0 wa, 0.0 hi, 1.3 si, 0.0 st ... PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 6882 root 20 0 12108 8360 3884 S 2.7 0.1 0:45.63 docker-containe 6947 systemd+ 20 0 33104 3764 2340 R 2.7 0.0 0:47.79 nginx 3865 daemon 20 0 336696 15056 7376 S 2.0 0.2 0:00.15 php-fpm 6779 daemon 20 0 8184 1112 556 R 0.3 0.0 0:00.01 stress ... `好像又错了。结果还跟原来一样，用户 CPU 使用率还是高达 80.9%，系统 CPU 接近 15%，而空闲 CPU 只有 2.8%，Running 状态的进程有 Nginx、stress 等。 可是，刚刚我们看到 stress 进程不存在了，怎么现在还在运行呢？再细看一下 top 的输出，原来，这次 stress 进程的 PID 跟前面不一样了，原来的 PID 24344 不见了，现在的是 6779。 进程的 PID 在变，这说明什么呢？在我看来，要么是这些进程在不停地重启，要么就是全新的进程，这无非也就两个原因： 第一个原因，进程在不停地崩溃重启，比如因为段错误、配置错误等等，这时，进程在退出后可能又被监控系统自动重启了。 第二个原因，这些进程都是短时进程，也就是在其他应用内部通过 exec 调用的外面命令。这些命令一般都只运行很短的时间就会结束，你很难用 top 这种间隔时间比较长的工具发现（上面的案例，我们碰巧发现了）。 至于 stress，我们前面提到过，它是一个常用的压力测试工具。它的 PID 在不断变化中，看起来像是被其他进程调用的短时进程。要想继续分析下去，还得找到它们的父进程。 要怎么查找一个进程的父进程呢？没错，用 pstree 就可以用树状形式显示所有进程之间的关系： `pstree | grep stress |-docker-containe-+-php-fpm-+-php-fpm---sh---stress | |-3*[php-fpm---sh---stress---stress] `从这里可以看到，stress 是被 php-fpm 调用的子进程，并且进程数量不止一个（这里是 3 个）。找到父进程后，我们能进入 app 的内部分析了。 首先，当然应该去看看它的源码。运行下面的命令，把案例应用的源码拷贝到 app 目录，然后再执行 grep 查找是不是有代码再调用 stress 命令： `# 拷贝源码到本地 $ docker cp phpfpm:/app . # grep 查找看看是不是有代码在调用 stress 命令 $ grep stress -r app app/index.php:// fake I/O with stress (via write()/unlink()). app/index.php:$result = exec(&quot;/usr/local/bin/stress -t 1 -d 1 2&gt;&amp;1&quot;, $output, $status); `找到了，果然是 app/index.php 文件中直接调用了 stress 命令。 再来看看 app/index.php 的源代码： `cat app/index.php &lt;?php // fake I/O with stress (via write()/unlink()). $result = exec(&quot;/usr/local/bin/stress -t 1 -d 1 2&gt;&amp;1&quot;, $output, $status); if (isset($_GET[&quot;verbose&quot;]) &amp;&amp; $_GET[&quot;verbose&quot;]==1 &amp;&amp; $status != 0) { echo &quot;Server internal error: &quot;; print_r($output); } else { echo &quot;It works!&quot;; } ?&gt; `可以看到，源码里对每个请求都会调用一个 stress 命令，模拟 I/O 压力。从注释上看，stress 会通过 write() 和 unlink() 对 I/O 进程进行压测，看来，这应该就是系统 CPU 使用率升高的根源了。 不过，stress 模拟的是 I/O 压力，而之前在 top 的输出中看到的，却一直是用户 CPU 和系统 CPU 升高，并没见到 iowait 升高。这又是怎么回事呢？stress 到底是不是 CPU 使用率升高的原因呢？ 我们还得继续往下走。从代码中可以看到，给请求加入 verbose=1 参数后，就可以查看 stress 的输出。你先试试看，在第二个终端运行： `curl http://192.168.0.10:10000?verbose=1 Server internal error: Array ( [0] =&gt; stress: info: [19607] dispatching hogs: 0 cpu, 0 io, 0 vm, 1 hdd [1] =&gt; stress: FAIL: [19608] (563) mkstemp failed: Permission denied [2] =&gt; stress: FAIL: [19607] (394) &lt;-- worker 19608 returned error 1 [3] =&gt; stress: WARN: [19607] (396) now reaping child worker processes [4] =&gt; stress: FAIL: [19607] (400) kill error: No such process [5] =&gt; stress: FAIL: [19607] (451) failed run completed in 0s ) `看错误消息 mkstemp failed: Permission denied ，以及 failed run completed in 0s。原来 stress 命令并没有成功，它因为权限问题失败退出了。看来，我们发现了一个 PHP 调用外部 stress 命令的 bug：没有权限创建临时文件。 从这里我们可以猜测，正是由于权限错误，大量的 stress 进程在启动时初始化失败，进而导致用户 CPU 使用率的升高。 分析出问题来源，下一步是不是就要开始优化了呢？当然不是！既然只是猜测，那就需要再确认一下，这个猜测到底对不对，是不是真的有大量的 stress 进程。该用什么工具或指标呢？ 我们前面已经用了 top、pidstat、pstree 等工具，没有发现大量的 stress 进程。那么，还有什么其他的工具可以用吗？ 还记得上一期提到的 perf 吗？它可以用来分析 CPU 性能事件，用在这里就很合适。依旧在第一个终端中运行 perf record -g 命令 ，并等待一会儿（比如 15 秒）后按 Ctrl+C 退出。然后再运行 perf report 查看报告： `# 记录性能事件，等待大约 15 秒后按 Ctrl+C 退出 $ perf record -g # 查看报告 $ perf report `这样，你就可以看到下图这个性能报告： 看，stress 占了所有 CPU 时钟事件的 77%，而 stress 调用调用栈中比例最高的，是随机数生成函数 random()，看来它的确就是 CPU 使用率升高的元凶了。随后的优化就很简单了，只要修复权限问题，并减少或删除 stress 的调用，就可以减轻系统的 CPU 压力。 当然，实际生产环境中的问题一般都要比这个案例复杂，在你找到触发瓶颈的命令行后，却可能发现，这个外部命令的调用过程是应用核心逻辑的一部分，并不能轻易减少或者删除。 这时，你就得继续排查，为什么被调用的命令，会导致 CPU 使用率升高或 I/O 升高等问题。这些复杂场景的案例，我会在后面的综合实战里详细分析。 最后，在案例结束时，不要忘了清理环境，执行下面的 Docker 命令，停止案例中用到的 Nginx 进程： `docker rm -f nginx phpfpm`execsnoop在这个案例中，我们使用了 top、pidstat、pstree 等工具分析了系统 CPU 使用率高的问题，并发现 CPU 升高是短时进程 stress 导致的，但是整个分析过程还是比较复杂的。对于这类问题，有没有更好的方法监控呢？ execsnoop https://github.com/brendangregg/perf-tools/blob/master/execsnoop就是一个专为短时进程设计的工具。它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息，包括进程 PID、父进程 PID、命令行参数以及执行的结果。 比如，用 execsnoop 监控上述案例，就可以直接得到 stress 进程的父进程 PID 以及它的命令行参数，并可以发现大量的 stress 进程在不停启动： `# 按 Ctrl+C 结束 $ execsnoop PCOMM PID PPID RET ARGS sh 30394 30393 0 stress 30396 30394 0 /usr/local/bin/stress -t 1 -d 1 sh 30398 30393 0 stress 30399 30398 0 /usr/local/bin/stress -t 1 -d 1 sh 30402 30400 0 stress 30403 30402 0 /usr/local/bin/stress -t 1 -d 1 sh 30405 30393 0 stress 30407 30405 0 /usr/local/bin/stress -t 1 -d 1 ... `execsnoop 所用的 ftrace 是一种常用的动态追踪技术，一般用于分析 Linux 内核的运行时行为，后面课程我也会详细介绍并带你使用。 小结碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况。 第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。 用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU。 对于这类进程，我们可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。对于这类进程，我们可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。","categories":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/categories/CPU/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/tags/CPU/"}]},{"title":"能力图谱","slug":"能力图谱","date":"2019-09-01T01:20:45.000Z","updated":"2019-09-01T01:24:41.711Z","comments":true,"path":"2019/09/01/能力图谱/","link":"","permalink":"http://www.ithelei.com/2019/09/01/能力图谱/","excerpt":"","text":"工程师能力图谱： 技术经理能力图谱 技术总监能力图谱 CTO能力图谱","categories":[{"name":"能力图谱","slug":"能力图谱","permalink":"http://www.ithelei.com/categories/能力图谱/"}],"tags":[{"name":"能力图谱","slug":"能力图谱","permalink":"http://www.ithelei.com/tags/能力图谱/"}]},{"title":"经常说的-CPU-上下文切换是什么意思？（下）","slug":"经常说的-CPU-上下文切换是什么意思？（下）","date":"2019-09-01T01:20:45.000Z","updated":"2019-09-01T11:48:34.973Z","comments":true,"path":"2019/09/01/经常说的-CPU-上下文切换是什么意思？（下）/","link":"","permalink":"http://www.ithelei.com/2019/09/01/经常说的-CPU-上下文切换是什么意思？（下）/","excerpt":"","text":"CPU 上下文切换的工作原理。简单回顾一下，CPU 上下文切换是保证 Linux 系统正常工作的一个核心功能，按照不同场景，可以分为进程上下文切换、线程上下文切换和中断上下文切换。具体的概念和区别，你也要在脑海中过一遍，忘了的话及时查看上一篇。 怎么查看系统的上下文切换情况过多的上下文切换，会把 CPU 时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成了系统性能大幅下降的一个元凶。 既然上下文切换对系统性能影响那么大，你肯定迫不及待想知道，到底要怎么查看上下文切换呢？在这里，我们可以使用 vmstat 这个工具，来查询系统的上下文切换情况。 vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。 比如，下面就是一个 vmstat 的使用示例： # 每隔 5 秒输出 1 组数据 我们一起来看这个结果，你可以先试着自己解读每列的含义。在这里，我重点强调下，需要特别关注的四列内容： cs（context switch）是每秒上下文切换的次数。 in（interrupt）则是每秒中断的次数。 r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。 b（Blocked）则是处于不可中断睡眠状态的进程数。 可以看到，这个例子中的上下文切换次数 cs 是 2 次，而系统中断次数 in 则是 3 次，而就绪队列长度 r 和不可中断状态进程数 b 都是 0。 vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用我们前面提到过的 pidstat 了。给它加上 -w 选项，你就可以查看每个进程上下文切换的情况了。 比如说：pidstat -w 5 这个结果中有两列内容是我们的重点关注对象。一个是 cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数，另一个则是 nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。 这两个概念你一定要牢牢记住，因为它们意味着不同的性能问题： 所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。 而非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。 案例分析知道了怎么查看这些指标，另一个问题又来了，上下文切换频率是多少次才算正常呢？别急着要答案，同样的，我们先来看一个上下文切换的案例。通过案例实战演练，你自己就可以分析并找出这个标准了。 准备我们将使用 sysbench 来模拟系统多线程调度切换的情况。 sysbench 是一个多线程的基准测试工具，一般用来评估不同系统参数下的数据库负载情况。当然，在这次案例中，我们只把它当成一个异常进程来看，作用是模拟上下文切换过多的问题。 下面的案例基于 Ubuntu 18.04，当然，其他的 Linux 系统同样适用。我使用的案例环境如下所示： 机器配置：2 CPU，8GB 内存 预先安装 sysbench 和 sysstat 包，如 apt install sysbench sysstat 正式操作开始前，你需要打开三个终端，登录到同一台 Linux 机器中，并安装好上面提到的两个软件包。包的安装，可以先 Google 一下自行解决，如果仍然有问题的，在留言区写下你的情况。 另外注意，下面所有命令，都默认以 root 用户运行。所以，如果你是用普通用户登陆的系统，记住先运行 sudo su root 命令切换到 root 用户。 安装完成后，你可以先用 vmstat 看一下空闲系统的上下文切换次数：vmstat 1 1 这里你可以看到，现在的上下文切换次数 cs 是 0，而中断次数 in 是 0，r 和 b 都是 0。因为这会儿我并没有运行其他任务，所以它们就是空闲系统的上下文切换次数。 操作和分析接下来，我们正式进入实战操作。 首先，在第一个终端里运行 sysbench ，模拟系统多线程调度的瓶颈： # 以 10 个线程运行 5 分钟的基准测试，模拟多线程切换的问题$ sysbench –threads=10 –max-time=300 threads run 接着，在第二个终端运行 vmstat ，观察上下文切换情况： vmstat 1 你应该可以发现，cs 列的上下文切换次数从之前的 35 骤然上升到了 139 万。同时，注意观察其他几个指标： r 列：就绪队列的长度已经到了 8，远远超过了系统 CPU 的个数 2，所以肯定会有大量的 CPU 竞争。 us（user）和 sy（system）列：这两列的 CPU 使用率加起来上升到了 100%，其中系统 CPU 使用率，也就是 sy 列高达 84%，说明 CPU 主要是被内核占用了。 in 列：中断次数也上升到了 1 万左右，说明中断处理也是个潜在的问题。 综合这几个指标，我们可以知道，系统的就绪队列过长，也就是正在运行和等待 CPU 的进程数过多，导致了大量的上下文切换，而上下文切换又导致了系统 CPU 的占用率升高。 那么到底是什么进程导致了这些问题呢？ 我们继续分析，在第三个终端再用 pidstat 来看一下， CPU 和进程上下文切换的情况： `# 每隔 1 秒输出 1 组数据（需要 Ctrl+C 才结束） # -w 参数表示输出进程切换指标，而 -u 参数则表示输出 CPU 使用指标 $ pidstat -w -u 1 08:06:33 UID PID %usr %system %guest %wait %CPU CPU Command 08:06:34 0 10488 30.00 100.00 0.00 0.00 100.00 0 sysbench 08:06:34 0 26326 0.00 1.00 0.00 0.00 1.00 0 kworker/u4:2 08:06:33 UID PID cswch/s nvcswch/s Command 08:06:34 0 8 11.00 0.00 rcu_sched 08:06:34 0 16 1.00 0.00 ksoftirqd/1 08:06:34 0 471 1.00 0.00 hv_balloon 08:06:34 0 1230 1.00 0.00 iscsid 08:06:34 0 4089 1.00 0.00 kworker/1:5 08:06:34 0 4333 1.00 0.00 kworker/0:3 08:06:34 0 10499 1.00 224.00 pidstat 08:06:34 0 26326 236.00 0.00 kworker/u4:2 08:06:34 1000 26784 223.00 0.00 sshd `从 pidstat 的输出你可以发现，CPU 使用率的升高果然是 sysbench 导致的，它的 CPU 使用率已经达到了 100%。但上下文切换则是来自其他进程，包括非自愿上下文切换频率最高的 pidstat ，以及自愿上下文切换频率最高的内核线程 kworker 和 sshd。 不过，细心的你肯定也发现了一个怪异的事儿：pidstat 输出的上下文切换次数，加起来也就几百，比 vmstat 的 139 万明显小了太多。这是怎么回事呢？难道是工具本身出了错吗？ 别着急，在怀疑工具之前，我们再来回想一下，前面讲到的几种上下文切换场景。其中有一点提到， Linux 调度的基本单位实际上是线程，而我们的场景 sysbench 模拟的也是线程的调度问题，那么，是不是 pidstat 忽略了线程的数据呢？ 通过运行 man pidstat ，你会发现，pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标。 所以，我们可以在第三个终端里， Ctrl+C 停止刚才的 pidstat 命令，再加上 -t 参数，重试一下看看： `# 每隔 1 秒输出一组数据（需要 Ctrl+C 才结束） # -wt 参数表示输出线程的上下文切换指标 $ pidstat -wt 1 08:14:05 UID TGID TID cswch/s nvcswch/s Command ... 08:14:05 0 10551 - 6.00 0.00 sysbench 08:14:05 0 - 10551 6.00 0.00 |__sysbench 08:14:05 0 - 10552 18911.00 103740.00 |__sysbench 08:14:05 0 - 10553 18915.00 100955.00 |__sysbench 08:14:05 0 - 10554 18827.00 103954.00 |__sysbench ... `现在你就能看到了，虽然 sysbench 进程（也就是主线程）的上下文切换次数看起来并不多，但它的子线程的上下文切换次数却有很多。看来，上下文切换罪魁祸首，还是过多的 sysbench 线程。 我们已经找到了上下文切换次数增多的根源，那是不是到这儿就可以结束了呢？ 当然不是。不知道你还记不记得，前面在观察系统指标时，除了上下文切换频率骤然升高，还有一个指标也有很大的变化。是的，正是中断次数。中断次数也上升到了 1 万，但到底是什么类型的中断上升了，现在还不清楚。我们接下来继续抽丝剥茧找源头。 既然是中断，我们都知道，它只发生在内核态，而 pidstat 只是一个进程的性能分析工具，并不提供任何关于中断的详细信息，怎样才能知道中断发生的类型呢？ 没错，那就是从 /proc/interrupts 这个只读文件中读取。/proc 实际上是 Linux 的一个虚拟文件系统，用于内核空间与用户空间之间的通信。/proc/interrupts 就是这种通信机制的一部分，提供了一个只读的中断使用情况。 我们还是在第三个终端里， Ctrl+C 停止刚才的 pidstat 命令，然后运行下面的命令，观察中断的变化情况： `# -d 参数表示高亮显示变化的区域 $ watch -d cat /proc/interrupts CPU0 CPU1 ... RES: 2450431 5279697 Rescheduling interrupts ... `观察一段时间，你可以发现，变化速度最快的是重调度中断（RES），这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断（Inter-Processor Interrupts，IPI）。 所以，这里的中断升高还是因为过多任务的调度问题，跟前面上下文切换次数的分析结果是一致的。 通过这个案例，你应该也发现了多工具、多方面指标对比观测的好处。如果最开始时，我们只用了 pidstat 观测，这些很严重的上下文切换线程，压根儿就发现不了了。 现在再回到最初的问题，每秒上下文切换多少次才算正常呢？ 这个数值其实取决于系统本身的 CPU 性能。在我看来，如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。 这时，你还需要根据上下文切换的类型，再做具体分析。比方说： 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题； 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈； 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。 小结今天，我通过一个 sysbench 的案例，给你讲了上下文切换问题的分析思路。碰到上下文切换次数过多的问题时，我们可以借助 vmstat 、 pidstat 和 /proc/interrupts 等工具，来辅助排查性能问题的根源。","categories":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/categories/CPU/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"http://www.ithelei.com/tags/CPU/"}]},{"title":"ECS上搭建Docker（CentOS7）","slug":"ECS上搭建Docker（CentOS7）","date":"2019-08-31T13:27:24.000Z","updated":"2019-08-31T15:02:39.023Z","comments":true,"path":"2019/08/31/ECS上搭建Docker（CentOS7）/","link":"","permalink":"http://www.ithelei.com/2019/08/31/ECS上搭建Docker（CentOS7）/","excerpt":"","text":"本文介绍在CentOS系统上部署Docker的过程。 背景信息本教程适用于熟悉Linux操作系统。 本教程示例步骤中使用的操作系统版本为CentOS 7.2 64 3.10.0-514.6.2.el7.x86_64 说明 Docker要求64位的系统且内核版本至少为3.10。部署Docker完成以下操作，部署Docker： 添加yum源。 yum install epel-release –y yum clean all yum list 安装并运行Docker。 yum install docker-io –y systemctl start docker 检查安装结果。 docker info 出现以下说明信息则表明安装成功。 使用DockerDocker有以下基本用法： 管理Docker守护进程。 systemctl start docker 运行Docker守护进程 systemctl stop docker 停止Docker守护进程 systemctl restart docker 重启Docker守护进程 管理镜像。本文使用的是来自阿里云仓库的Apache镜像。 docker pull registry.cn-hangzhou.aliyuncs.com/lxepoo/apache-php5 修改标签。由于阿里云仓库镜像的镜像名称很长，可以修改镜像标签以便记忆区分。 docker tag registry.cn-hangzhou.aliyuncs.com/lxepoo/apache-php5:latest aliweb:v1 查看已有镜像。 docker images 强制删除镜像。 docker rmi –f registry.cn-hangzhou.aliyuncs.com/lxepoo/apache-php5 管理容器。 进入容器。e1xxxxxxxxxe是执行docker images命令查询到的ImageId，使用docker run命令进入容器。 docker run –ti e1xxxxxxxxxe /bin/bash 退出容器。使用exit命令退出当前容器。 run命令加上–d参数可以在后台运行容器，–name指定容器命名为apache。 docker run -d –name apache e1xxxxxxxxxe 进入后台运行的容器。 docker exec -ti apache /bin/bash 将容器做成镜像。 docker commit containerID/containerName newImageName:tag 为了方便测试和恢复，将源镜像运行起来后，再做一个命名简单的镜像做测试。 docker commit 4c8066cd8c01 apachephp:v1 运行容器并将宿主机的8080端口映射到容器里去。 docker run -d -p 8080:80 apachephp:v1 在浏览器输入宿主机IP加8080端口访问测试，出现以下内容则说明运行成功。 制作镜像完成以下操作，制作镜像： 准备Dockerfile内容。 ` # vim Dockerfile FROM apachephp:v1 #声明基础镜像来源 MAINTAINER DTSTACK #声明镜像拥有者 RUN mkdir /dtstact #RUN后面接容器运行前需要执行的命令，由于Dockerfile文件不能超过127行，因此当命令较多时建议写到脚本中执行 ENTRYPOINT ping www.aliyun.com #开机启动命令，此处最后一个命令需要是可在前台持续执行的命令，否则容器后台运行时会因为命令执行完而退出。 ` 构建镜像。 ` docker build -t webcentos:v1 . # . 是Dockerfile文件的路径，不能忽略 docker images #查看是否创建成功 docker run –d webcentos:v1 #后台运行容器 docker ps #查看当前运行中的容器 docker ps –a #查看所有容器，包括未运行中的 docker logs CONTAINER ID/IMAGE #如未查看到刚才运行的容器，则用容器id或者名字查看启动日志排错 docker commit fb2844b6c070 dtstackweb:v1 #commit 后接容器id 和构建新镜像的名称和版本号。 docker images #列出本地（已下载的和本地创建的）镜像 docker push #将镜像推送至远程仓库，默认为 Docker Hub ` 将镜像推送到registry。 其中ImageId和镜像版本号请您根据自己的镜像信息进行填写。 ` docker login --username=dtstack_plus registry.cn-shanghai.aliyuncs.com #执行后输入镜像仓库密码 docker tag [ImageId] registry.cn-shanghai.aliyuncs.com/dtstack123/test:[镜像版本号] docker push registry.cn-shanghai.aliyuncs.com/dtstack123/test:[镜像版本号] `在镜像仓库能查看到镜像版本信息则说明推送成功。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://www.ithelei.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.ithelei.com/tags/Docker/"}]},{"title":"Tomcat服务启动非常缓慢","slug":"Tomcat服务启动非常缓慢","date":"2019-08-31T11:36:42.000Z","updated":"2019-08-31T12:16:45.879Z","comments":true,"path":"2019/08/31/Tomcat服务启动非常缓慢/","link":"","permalink":"http://www.ithelei.com/2019/08/31/Tomcat服务启动非常缓慢/","excerpt":"","text":"概述：本文主要介绍Tomcat服务启动非常缓慢的解决方法。 问题症状 Tomcat启动非常缓慢，查看日志如下。 问题原因 SecureRandom这个jre的工具类的问题。 解决方案：在Tomcat环境中解决。 可以通过配置JRE使用非阻塞的Entropy Source。 在catalina.sh文件中加入如下内容 -Djava.security.egd=file:/dev/./urandom 加入后重启Tomcat，查看Tomcat服务启动日志，启动耗时下降。 在JVM环境中解决 打开 $JAVA_PATH/jre/lib/security/java.security这个文件。 在文件中找到如下内容。 securerandom.source=file:/dev/urandom 将内容替换成如下内容 securerandom.source=file:/dev/./urandom","categories":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://www.ithelei.com/categories/Tomcat/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://www.ithelei.com/tags/Tomcat/"}]},{"title":"Linux性能优化实战","slug":"Linux性能优化实战","date":"2019-08-31T11:33:45.000Z","updated":"2019-08-31T13:35:58.695Z","comments":true,"path":"2019/08/31/Linux性能优化实战/","link":"","permalink":"http://www.ithelei.com/2019/08/31/Linux性能优化实战/","excerpt":"","text":"如图：","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"},{"name":"性能","slug":"Linux/性能","permalink":"http://www.ithelei.com/categories/Linux/性能/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"},{"name":"性能","slug":"性能","permalink":"http://www.ithelei.com/tags/性能/"}]},{"title":"Linux清除日志脚本","slug":"Linux清除日志脚本","date":"2019-08-31T11:33:45.000Z","updated":"2020-06-14T11:13:09.052Z","comments":true,"path":"2019/08/31/Linux清除日志脚本/","link":"","permalink":"http://www.ithelei.com/2019/08/31/Linux清除日志脚本/","excerpt":"","text":"`#!/bin/sh #by ithelei #清除日志脚本，版本2 LOG_DIR=/var/log ROOT_UID=0 # &lt;==$UID为0的用户，即root用户 #脚本需要使用root用户来执行，因此对当前用户进行判断，对不合格要求的用户给出提示，并终止程序运行。 if [ &quot;$UID&quot; -ne &quot;$ROOT_UID&quot; ] #&lt;==如果当前不是root,不允许执行脚本 then echo &quot;Must be root to run this script.&quot; #&lt;--给出提示后退出 exit 1 #&lt;--退出脚本 fi #如果切换到指定目录不成功，则给出提示，并终止运行。 cd $LOG_DIR || { echo &quot;Cannot change to necessary directory.&quot; exit 1 } #经过上述两个判断后，此处的用户权限和路径就是对的了，只有清空成功，才打印成功提示 cat /dev/null &gt;messages &amp;&amp; { echo &quot;Logs cleaned up.&quot; exit 0 #退出之前，返回0表示成功，返回1表示失败。 } echo &quot;logs cleaned up fail&quot; exit 1 `","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"}]},{"title":"Linux监控思路图","slug":"Linux监控思路图","date":"2019-08-31T11:33:45.000Z","updated":"2020-08-23T15:12:33.002Z","comments":true,"path":"2019/08/31/Linux监控思路图/","link":"","permalink":"http://www.ithelei.com/2019/08/31/Linux监控思路图/","excerpt":"","text":"","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"},{"name":"监控","slug":"Linux/监控","permalink":"http://www.ithelei.com/categories/Linux/监控/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"},{"name":"监控","slug":"监控","permalink":"http://www.ithelei.com/tags/监控/"}]},{"title":"到底应该怎么理解（平均负载）？","slug":"到底应该怎么理解（平均负载）","date":"2019-08-30T13:27:24.000Z","updated":"2019-08-31T14:08:59.255Z","comments":true,"path":"2019/08/30/到底应该怎么理解（平均负载）/","link":"","permalink":"http://www.ithelei.com/2019/08/30/到底应该怎么理解（平均负载）/","excerpt":"","text":"每次发现系统变慢时，我们通常做的第一件事，就是执行 top 或者 uptime 命令，来了解系统的负载情况。比如像下面这样，我在命令行里输入了 uptime 命令，系统也随即给出了结果。 ` $uptime 02:34:03 up 2 days, 20:14, 1 user, load average: 0.63, 0.83, 0.88 `但我想问的是，你真的知道这里每列输出的含义吗？ 我相信你对前面的几列比较熟悉，它们分别是当前时间、系统运行时间以及正在登录用户数。 ` 02:34:03 // 当前时间 up 2 days, 20:14 // 系统运行时间 1 user // 正在登录用户数 `而最后三个数字呢，依次则是过去 1 分钟、5 分钟、15 分钟的平均负载（Load Average）。 平均负载？这个词对很多人来说，可能既熟悉又陌生，我们每天的工作中，也都会提到这个词，但你真正理解它背后的含义吗？ 如何观测和理解这个最常见、也是最重要的系统指标。 平均负载不就是单位时间内的 CPU 使用率吗？上面的 0.63，就代表 CPU 使用率是 63%。其实并不是这样，如果你方便的话，可以通过执行 man uptime 命令，来了解平均负载的详细解释。 简单来说，平均负载是指单位时间内，系统处于可运行状态 和不可中断状态的平均进程数，也就是平均活跃进程数 ，它和 CPU 使用率并没有直接关系。这里我先解释下，可运行状态和不可中断状态这俩词儿。 所谓可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。 比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。 所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制 因此，你可以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。这个“指数衰减平均”的详细含义你不用计较，这只是系统的一种更快速的计算方式，你把它直接当成活跃进程数的平均值也没问题。 既然平均的是活跃进程数，那么最理想的，就是每个 CPU 上都刚好运行着一个进程，这样每个 CPU 都得到了充分利用。比如当平均负载为 2 时，意味着什么呢？ 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用。 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲。 而在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU。 平均负载为多少时合理说完了什么是平均负载，现在我们再回到最开始的例子，在 uptime 命令的结果里，那三个时间段的平均负载数，多大的时候能说明系统负载高？或是多小的时候就能说明系统负载很低呢？ 我们知道，平均负载最理想的情况是等于 CPU 个数。所以在评判平均负载时，首先你要知道系统有几个 CPU ，这可以通过 top 命令或者从文件 /proc/cpuinfo 中读取，比如： ` # 关于 grep 和 wc 的用法请查询它们的手册或者网络搜索 $ grep &apos;model name&apos; /proc/cpuinfo | wc -l 2 `有了 CPU 个数，我们就可以判断出，当平均负载比 CPU 个数还大的时候，系统已经出现了过载。 不过，且慢，新的问题又来了。我们在例子中可以看到，平均负载有三个数值，到底该参考哪一个呢？ 实际上，都要看。三个不同时间间隔的平均值，其实给我们提供了，分析系统负载趋势的数据来源，让我们能更全面、更立体地理解目前的负载状况。 打个比方，就像初秋时北京的天气，如果只看中午的温度，你可能以为还在 7 月份的大夏天呢。但如果你结合了早上、中午、晚上三个时间点的温度来看，基本就可以全方位了解这一天的天气情况了。 同样的，前面说到的 CPU 的三个负载时间段也是这个道理。 如果 1 分钟、5 分钟、15 分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。 但如果 1 分钟的值远小于 15 分钟的值，就说明系统最近 1 分钟的负载在减少，而过去 15 分钟内却有很大的负载。 反过来，如果 1 分钟的值远大于 15 分钟的值，就说明最近 1 分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦 1 分钟的平均负载接近或超过了 CPU 的个数，就意味着系统正在发生过载的问题，这时就得分析调查是哪里导致的问题，并要想办法优化了。 这里我再举个例子，假设我们在一个单 CPU 系统上看到平均负载为 1.73，0.60，7.98，那么说明在过去 1 分钟内，系统有 73% 的超载，而在 15 分钟内，有 698% 的超载，从整体趋势来看，系统的负载在降低。 那么，在实际生产环境中，平均负载多高时，需要我们重点关注呢？ 在我看来，当平均负载高于 CPU 数量 70% 的时候 ，你就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。 但 70% 这个数字并不是绝对的，最推荐的方法，还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。当发现负载有明显升高趋势时，比如说负载翻倍了，你再去做分析和调查。 平均负载与 CPU 使用率现实工作中，我们经常容易把平均负载和 CPU 使用率混淆，所以在这里，我也做一个区分。 可能你会疑惑，既然平均负载代表的是活跃进程数，那平均负载高了，不就意味着 CPU 使用率高吗？ 我们还是要回到平均负载的含义上来，平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了 而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如： 而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如： I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高； 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。 平均负载案例分析下面，我们以三个示例分别来看这三种情况，并用 iostat、mpstat、pidstat 等工具，找出平均负载升高的根源。 因为案例分析都是基于机器上的操作，所以不要只是听听、看看就够了，最好还是跟着我实际操作一下。 你的准备下面的案例都是基于 Ubuntu 18.04，当然，同样适用于其他 Linux 系统。我使用的案例环境如下所示。 机器配置：2 CPU，8GB 内存。 预先安装 stress 和 sysstat 包，如 apt install stress sysstat。 在这里，我先简单介绍一下 stress 和 sysstat。 stress 是一个 Linux 系统压力测试工具，这里我们用作异常进程模拟平均负载升高的场景。 而 sysstat 包含了常用的 Linux 性能工具，用来监控和分析系统的性能。我们的案例会用到这个包的两个命令 mpstat 和 pidstat。 mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标。 pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。 此外，每个场景都需要你开三个终端，登录到同一台 Linux 机器中。 实验之前，你先做好上面的准备。如果包的安装有问题，可以先在 Google 一下自行解决，如果还是解决不了，再来留言区找我，这事儿应该不难。 另外要注意，下面的所有命令，我们都是默认以 root 用户运行。所以，如果你是用普通用户登陆的系统，一定要先运行 sudo su root 命令切换到 root 用户。 如果上面的要求都已经完成了，你可以先用 uptime 命令，看一下测试前的平均负载情况： `$uptame ..., load average: 0.11, 0.15, 0.09 `场景一：CPU 密集型进程首先，我们在第一个终端运行 stress 命令，模拟一个 CPU 使用率 100% 的场景： ` $ stress --cpu 1 --timeout 600 `接着，在第二个终端运行 uptime 查看平均负载的变化情况： ` # -d 参数表示高亮显示变化的区域 $ watch -d uptime ..., load average: 1.00, 0.75, 0.39 `最后，在第三个终端运行 mpstat 查看 CPU 使用率的变化情况： `# -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据 $ mpstat -P ALL 5 Linux 4.15.0 (ubuntu) 09/22/18 _x86_64_ (2 CPU) 13:30:06 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 13:30:11 all 50.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 49.95 13:30:11 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 13:30:11 1 100.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 `从终端二中可以看到，1 分钟的平均负载会慢慢增加到 1.00，而从终端三中还可以看到，正好有一个 CPU 的使用率为 100%，但它的 iowait 只有 0。这说明，平均负载的升高正是由于 CPU 使用率为 100% 。 那么，到底是哪个进程导致了 CPU 使用率为 100% 呢？你可以使用 pidstat 来查询： ` # 间隔 5 秒后输出一组数据 $ pidstat -u 5 1 13:37:07 UID PID %usr %system %guest %wait %CPU CPU Command 13:37:12 0 2962 100.00 0.00 0.00 0.00 100.00 1 stress `从这里可以明显看到，stress 进程的 CPU 使用率为 100%。 场景二：I/O 密集型进程首先还是运行 stress 命令，但这次模拟 I/O 压力，即不停地执行 sync： `$stress -i 1 --timeout 600 `还是在第二个终端运行 uptime 查看平均负载的变化情况： `$watch -d uptime ..., load average: 1.06, 0.58, 0.37 `然后，第三个终端运行 mpstat 查看 CPU 使用率的变化情况： `# 显示所有 CPU 的指标，并在间隔 5 秒输出一组数据 $ mpstat -P ALL 5 1 Linux 4.15.0 (ubuntu) 09/22/18 _x86_64_ (2 CPU) 13:41:28 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 13:41:33 all 0.21 0.00 12.07 32.67 0.00 0.21 0.00 0.00 0.00 54.84 13:41:33 0 0.43 0.00 23.87 67.53 0.00 0.43 0.00 0.00 0.00 7.74 13:41:33 1 0.00 0.00 0.81 0.20 0.00 0.00 0.00 0.00 0.00 98.99 `从这里可以看到，1 分钟的平均负载会慢慢增加到 1.06，其中一个 CPU 的系统 CPU 使用率升高到了 23.87，而 iowait 高达 67.53%。这说明，平均负载的升高是由于 iowait 的升高。 那么到底是哪个进程，导致 iowait 这么高呢？我们还是用 pidstat 来查询： `# 间隔 5 秒后输出一组数据，-u 表示 CPU 指标 $ pidstat -u 5 1 Linux 4.15.0 (ubuntu) 09/22/18 _x86_64_ (2 CPU) 13:42:08 UID PID %usr %system %guest %wait %CPU CPU Command 13:42:13 0 104 0.00 3.39 0.00 0.00 3.39 1 kworker/1:1H 13:42:13 0 109 0.00 0.40 0.00 0.00 0.40 0 kworker/0:1H 13:42:13 0 2997 2.00 35.53 0.00 3.99 37.52 1 stress 13:42:13 0 3057 0.00 0.40 0.00 0.00 0.40 0 pidstat `可以发现，还是 stress 进程导致的。 场景三：大量进程的场景当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程。 比如，我们还是使用 stress，但这次模拟的是 8 个进程： `$stress -c 8 --timeout 600 `由于系统只有 2 个 CPU，明显比 8 个进程要少得多，因而，系统的 CPU 处于严重过载状态，平均负载高达 7.97： `$uptime ..., load average: 7.97, 5.93, 3.02 `接着再运行 pidstat 来看一下进程的情况： `# 间隔 5 秒后输出一组数据 $ pidstat -u 5 1 14:23:25 UID PID %usr %system %guest %wait %CPU CPU Command 14:23:30 0 3190 25.00 0.00 0.00 74.80 25.00 0 stress 14:23:30 0 3191 25.00 0.00 0.00 75.20 25.00 0 stress 14:23:30 0 3192 25.00 0.00 0.00 74.80 25.00 1 stress 14:23:30 0 3193 25.00 0.00 0.00 75.00 25.00 1 stress 14:23:30 0 3194 24.80 0.00 0.00 74.60 24.80 0 stress 14:23:30 0 3195 24.80 0.00 0.00 75.00 24.80 0 stress 14:23:30 0 3196 24.80 0.00 0.00 74.60 24.80 1 stress 14:23:30 0 3197 24.80 0.00 0.00 74.80 24.80 1 stress 14:23:30 0 3200 0.00 0.20 0.00 0.20 0.20 0 pidstat `可以看出，8 个进程在争抢 2 个 CPU，每个进程等待 CPU 的时间（也就是代码块中的 %wait 列）高达 75%。这些超出 CPU 计算能力的进程，最终导致 CPU 过载。 小结分析完这三个案例，我再来归纳一下平均负载的理解 平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意： 平均负载高有可能是 CPU 密集型进程导致的； 平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了； 当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"}]},{"title":"Nginx百度峰会上机","slug":"Nginx百度峰会上机","date":"2019-08-29T11:33:45.000Z","updated":"2020-03-01T13:07:00.414Z","comments":true,"path":"2019/08/29/Nginx百度峰会上机/","link":"","permalink":"http://www.ithelei.com/2019/08/29/Nginx百度峰会上机/","excerpt":"","text":"如下","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.ithelei.com/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.ithelei.com/tags/Nginx/"}]},{"title":"百度云智峰会（实战环节）","slug":"百度云智峰会 （实战）本","date":"2019-08-29T01:20:45.000Z","updated":"2019-09-01T12:50:52.310Z","comments":true,"path":"2019/08/29/百度云智峰会 （实战）本/","link":"","permalink":"http://www.ithelei.com/2019/08/29/百度云智峰会 （实战）本/","excerpt":"","text":"百度云智峰会，上机实战环节。在这里由于表现突出，得了一个自己特别喜欢小奖品。","categories":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/categories/峰会/"}],"tags":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/tags/峰会/"}]},{"title":"百度云智峰会","slug":"百度云智峰会","date":"2019-08-29T01:20:45.000Z","updated":"2019-09-01T12:36:57.939Z","comments":true,"path":"2019/08/29/百度云智峰会/","link":"","permalink":"http://www.ithelei.com/2019/08/29/百度云智峰会/","excerpt":"","text":"百度云智峰会，科技为更好。","categories":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/categories/峰会/"}],"tags":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/tags/峰会/"}]},{"title":"MySQL优化(1)","slug":"MySQL优化(1)","date":"2019-08-28T14:39:45.000Z","updated":"2019-08-28T13:21:45.209Z","comments":true,"path":"2019/08/28/MySQL优化(1)/","link":"","permalink":"http://www.ithelei.com/2019/08/28/MySQL优化(1)/","excerpt":"","text":"MySQL查询优化应注意的问题 对查询进行优化，应尽量避免全表扫描，首先应考虑在where及order by 涉及的列上建立索引。 应尽量避免在where子句中使用！=或 &lt;&gt; 操作符，否则引擎将放弃索引而进行全表扫描。 应尽量避免在where字句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描，如select id from t where num is null 可以在num上设置默认值为0，确保表中num列没有null值，如select id from t where num = 0。 应尽量避免在where子句中使用or来连接条件，否则将导致引擎放弃使用索引而进行全表扫描。如下面的语句：select id from t where num =10 or num =20,可以改成下面的语句：select id from t where num =10 union all select id from t where num =20 下面的查询也将导致全表扫描： select id from t where name like &#39;%abc%&#39; in 和 not in也要慎用，否则会导致全表扫描。如下面的语句： select id from t where num in (1,2,3) 对于连续的数值，能用between 就不要用 in 了。 select id from t where num between 1 and 3 如果在where子句中使用参数，也会导致全表扫描。因为sql只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择选择推迟到运行时；他必须在编译时进行选择。然而。如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择输入项。如下面的语句将进行全表扫描。 select id from t where num=@num 可以改为强制查询使用索引，如下语句： select id from t with (index(索引名)) where num =@num 应尽量避免在where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描，如下面的语句： select id from t where num/2=100应改为 select id from t where num=100*2 应尽量避免在where子句中 对字段进行函数操作，这将导致殷勤放弃使用索引而进行全表扫描，如下面的语句： select id from t where SUBSTRING(name,1,3)=&#39;abc&#39; –name以abc开头的id select id from t where DATEDIFF(day,createdate,&#39;2019-08-28&#39;)=0 –2019-08-28生成的id 。 应改为如下面的语句： `select id from ｔ where nane like &apos;abc%&apos;` `select id from t where createdate &gt; = &apos;2019-08-28&apos; and createdate &lt; &apos;2019-08-29&apos;` 不要在where 子句中的 “=” 左边进行函数、算数运算或其他表达式运算。否则系统将可能无法正确使用索引。 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 很多时候用exists代替in是一个好的选择。 select num from a where num in （select num from b） 用下面的语句替换。 `select num from a where exists （select 1 from b where num=a.num）`","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MySQL优化(2)","slug":"MySQL优化(2)","date":"2019-08-28T13:36:45.000Z","updated":"2019-08-28T14:03:47.468Z","comments":true,"path":"2019/08/28/MySQL优化(2)/","link":"","permalink":"http://www.ithelei.com/2019/08/28/MySQL优化(2)/","excerpt":"","text":"继MySQL优化(1) 并不是所有索引对查询都有效，sql语句是根军表中数据来进行优化的，当索引列有大量数据重复时，sql查询可能不会去利用索引，如某表中有字段sex,male,female几乎各一半，那么及时在sex上建了索引也对查询效率起不了作用。 索引并不是越多越好，索引固然可以提高相应的select的效率，但同时也降低了insert和update的效率，因为insert和update时有可能会重建索引，所以怎样建索引需要慎重考虑，是具体情况而定。一个表的索引不要超过5个。若太多则时，考虑那些不常使用列上的索引是否有必要。 应尽可能地避免更新 lustered素引数据列，因为 clustered索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要烦繁更新 clustered索引数据列，那么需要考虑是否将该索引建为 clustered索引。 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每个字符，而对于数字型而言只需要比较一次就够了。 尽可能地使用 VARCHAR/NVARCHAR代替 CHAR/NCHAR，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 任何地方都不要使用 SELECT＊ FROM t，用具体的字段列表代替“＊”，不要返回用不到的任何字段。 尽量使用表变量来代替临时表。如果表变量包含大量数据，应注意索引非常有限(只有主键索引)。 避免频繁创建和删除临时表，以减少系统表资源的消耗 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用,大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 在新建临时表时，如果一次性插入数据量很大，那么可以使用 SELECT into代替 CREATEtable，避免造成大量log，以提高速度:如果数据量不大，为了缓和系统表的资源，应先CREATE table，然后 INSERT 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式刷除，先 truncate tabl然后 DROP table，这样可以避免系统表的较长时间锁定。 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应考虑改写 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效 与临时表一样，游标并不是不可使用。对小型数据集使用FAST_ FORWARD游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的历程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好 在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON，在结束时设置SETNOCOUNT OFF。无须在执行存储过程和触发器的每个语句后向客户端发送 DONE INPROC消息。 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理 尽量避免大事务操作，提高系统并发能力","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"MySQL规范","slug":"MySQL规范","date":"2019-08-27T13:45:00.000Z","updated":"2019-08-27T14:16:51.451Z","comments":true,"path":"2019/08/27/MySQL规范/","link":"","permalink":"http://www.ithelei.com/2019/08/27/MySQL规范/","excerpt":"","text":"一、基础规范 表存储引擎必须使用InnoDB 表字符集默认使用utf8，必要时候使用utf8mb4 解读： （1）通用，无乱码风险，汉字3字节，英文1字节。 （2）utf8mb4是utf8的超集，有存储4字节例如表情符号时，使用它。 禁止使用存储过程，视图，触发器，Event。 解读： （1）对数据库性能影响较大，互联网业务，能让站点层和服务层干的事情，不要交到数据库层。 （2）调试，排错，迁移都比较困难，扩展性较差。 禁止在数据库中存储大文件，例如照片，可以将大文件存储在对象存储系统，数据库中存储路径。 禁止在线上环境做数据库压力测试。 测试，开发，线上数据库环境必须隔离。 二、命名规范 库名，表名，列名必须用小写，采用下划线分隔。 解读：abc，Abc，ABC都是不允许的。 库名，表名，列名必须见名知义，长度不要超过32字符。 解读：tmp，wujun谁TM知道这些库是干嘛的。 库备份必须以bak为前缀，以日期为后缀。 从库必须以-s为后缀。 备库必须以-ss为后缀。 三、表设计规范 单实例表个数必须控制在2000个以内。 单表分表个数必须控制在1024个以内。 必须有主键，推荐使用UNSIGNED整数为主键。 潜在坑：删除无主键的表，如果是row模式的主从架构，从库会挂住 禁止使用外键，如果要保证完整性，应由应用程式实现。 解读：外键使得表之间相互耦合，影响update/delete等SQL性能，有可能造成死锁，高并发情况下容易成为数据库瓶颈 建议将大字段，访问频度低的字段拆分到单独的表中存储，分离冷热数据。 四、列设计规范 根据业务区分使用tinyint/int/bigint，分别会占用1/4/8字节。 根据业务区分使用char/varchar。 解读： （1）字段长度固定，或者长度近似的业务场景，适合使用char，能够减少碎片，查询性能高 （2）字段长度相差较大，或者更新较少的业务场景，适合使用varchar，能够减少空间。 根据业务区分使用datetime/timestamp。 解读：前者占用5个字节，后者占用4个字节，存储年使用YEAR，存储日期使用DATE，存储时间使用datetime。 必须把字段定义为NOT NULL并设默认值。 解读： （1）NULL的列使用索引，索引统计，值都更加复杂，MySQL更难优化 （2）NULL需要更多的存储空间 （3）NULL只能采用IS NULL或者IS NOT NULL，而在=/!=/in/not in时有大坑 使用INT UNSIGNED存储IPv4，不要用char(15)。 使用varchar(20)存储手机号，不要使用整数。 解读： （1）牵扯到国家代号，可能出现+/-/()等字符，例如+86 （2）手机号不会用来做数学运算 （3）varchar可以模糊查询，例如like ‘138%’ 使用TINYINT来代替ENUM。 解读：ENUM增加新值要进行DDL操作。 五、索引规范 唯一索引使用uniq_[字段名]来命名。 非唯一索引使用idx_[字段名]来命名。 单张表索引数量建议控制在5个以内。 解读： （1）互联网高并发业务，太多索引会影响写性能。 （2）生成执行计划时，如果索引太多，会降低性能，并可能导致MySQL选择不到最优索引。 （3）异常复杂的查询需求，可以选择ES等更为适合的方式存储。 组合索引字段数不建议超过5个。 解读：如果5个字段还不能极大缩小row范围，八成是设计有问题 不建议在频繁更新的字段上建立索引。 非必要不要进行JOIN查询，如果要进行JOIN查询，被JOIN的字段必须类型相同，并建立索引。 解读：因为JOIN字段类型不一致，而导致全表扫描。 理解组合索引最左前缀原则，避免重复建设索引，如果建立了(a,b,c)，相当于建立了(a), (a,b), (a,b,c)。 六、SQL规范 禁止使用select *，只获取必要字段。 解读： （1）select *会增加cpu/io/内存/带宽的消耗。 （2）指定字段能有效利用索引覆盖。 （3）指定字段查询，在表结构变更时，能保证对应用程序无影响。 insert必须指定字段，禁止使用insert into T values()。 解读：指定字段插入，在表结构变更时，能保证对应用程序无影响。 隐式类型转换会使索引失效，导致全表扫描。 禁止在where条件列使用函数或者表达式。 解读：导致不能命中索引，全表扫描 禁止负向查询以及%开头的模糊查询。 解读：导致不能命中索引，全表扫描。 禁止大表JOIN和子查询。 同一个字段上的OR必须改写问IN，IN的值必须少于50个。 应用程序必须捕获SQL异常。 解读：方便定位线上问题","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ithelei.com/tags/MySQL/"}]},{"title":"阿里云标准-Apache Tomcat 安全基线检查","slug":"阿里云标准-Apache Tomcat 安全基线检查","date":"2019-08-27T13:27:24.000Z","updated":"2019-08-27T13:36:34.131Z","comments":true,"path":"2019/08/27/阿里云标准-Apache Tomcat 安全基线检查/","link":"","permalink":"http://www.ithelei.com/2019/08/27/阿里云标准-Apache Tomcat 安全基线检查/","excerpt":"","text":"Tomcat进程运行权限检测 | 访问控制描述 在运行Internet服务时，最好尽可能避免使用root用户运行，降低攻击者拿到服务器控制权限的机会。 加固建议 创建低权限的账号运行Tomcat 操作时建议做好记录或备份 Tomcat目录权限检测 | 访问控制描述 在运行Tomcat服务时，避免使用root用户运行，tomcat目录(catalina.home、 catalina.base目录)所有者应改为非root的运行用户 加固建议 使用chown -R &lt;Tomcat启动用户所属组&gt;:&lt;Tomcat启动用户&gt; &lt;Tomcat目录&gt;修改tomcat目录文件所有者，如chown -R tomcat:tomcat /usr/local/tomcat 操作时建议做好记录或备份 限制服务器平台信息泄漏 | 服务配置描述 限制服务器平台信息泄漏会使攻击者更难确定哪些漏洞会影响服务器平台。 加固建议 1、进入Tomcat安装主目录的lib目录下，比如 cd /usr/local/tomcat7/lib 2、执行：jar xf catalina.jar org/apache/catalina/util/ServerInfo.properties，修改文件ServerInfo.properties中的server.info和server.number的值，如分别改为：Apache/11.0.92、11.0.92.0 3、执行：jar uf catalina.jar org/apache/catalina/util/ServerInfo.properties 4、重启Tomcat服务 操作时建议做好记录或备份 禁止自动部署 | 服务配置描述 配置自动部署，容易被部署恶意或未经测试的应用程序，应将其禁用 加固建议 修改Tomcat 跟目录下的配置文件conf/server.xml，将host节点的autoDeploy属性设置为“false”，如果host的deployOnStartup属性(如没有deployOnStartup配置可以忽略)为“true”，则也将其更改为“false” 操作时建议做好记录或备份 禁止显示异常调试信息 | 服务配置描述 当请求处理期间发生运行时错误时，ApacheTomcat将向请求者显示调试信息。建议不要向请求者提供此类调试信息。 加固建议 在Tomcat根目录下的conf/web.xml文件里面的web-app添加子节点：java.lang.Throwable/error.jsp，在webapps目录下创建error.jsp，定义自定义错误信息 操作时建议做好记录或备份 开启日志记录 | 安全审计描述 Tomcat需要保存输出日志，以便于排除错误和发生安全事件时，进行分析和定位 加固建议 1、修改Tomcat根目录下的conf/server.xml文件。 2、取消Host节点下Valve节点的注释(如没有则添加)。 3、重新启动Tomcat 操作时建议做好记录或备份 禁止Tomcat显示目录文件列表 | 服务配置描述 Tomcat允许显示目录文件列表会引发目录遍历漏洞 加固建议 修改Tomcat 跟目录下的配置文件conf/web.xml，将listings的值设置为false。 listings false 操作时建议做好记录或备份 删除项目无关文件和目录 | 访问控制描述 Tomcat安装提供了示例应用程序、文档和其他可能不用于生产程序及目录，存在极大安全风险，建议移除 加固建议 请删除Tomcat示例程序和目录、管理控制台等，即从Tomcat根目录的webapps目录，移出或删除docs、examples、host-manager、manager目录。 操作时建议做好记录或备份 避免为tomcat配置manager-gui弱口令 | 访问控制描述 tomcat-manger是Tomcat提供的web应用热部署功能，该功能具有较高权限，会直接控制Tomcat应用，应尽量避免使用此功能。如有特殊需求，请务必确保为该功能配置了强口令 加固建议 编辑Tomcat根目录下的配置文件conf/tomcat-user.xml，修改user节点的password属性值为复杂密码, 密码应符合复杂性要求： 1、长度8位以上 2、包含以下四类字符中的三类字符:英文大写字母(A 到 Z)英文小写字母(a 到 z)10 个基本数字(0 到 9)非字母字符(例如 !、$、#、%、@、^、&amp;) 3、避免使用已公开的弱密码，如：abcd.1234 、admin@123等操作时建议做好记录或备份","categories":[{"name":"安全","slug":"安全","permalink":"http://www.ithelei.com/categories/安全/"}],"tags":[{"name":"基线","slug":"基线","permalink":"http://www.ithelei.com/tags/基线/"},{"name":"Apache Tomcat","slug":"Apache-Tomcat","permalink":"http://www.ithelei.com/tags/Apache-Tomcat/"}]},{"title":"CentOS Linux 7安全基线检查","slug":"CentOS Linux 7安全基线检查","date":"2019-08-26T14:25:24.000Z","updated":"2019-08-27T13:20:42.155Z","comments":true,"path":"2019/08/26/CentOS Linux 7安全基线检查/","link":"","permalink":"http://www.ithelei.com/2019/08/26/CentOS Linux 7安全基线检查/","excerpt":"","text":"设置用户权限配置文件的权限 | 文件权限描述 设置用户权限配置文件的权限 加固建议 执行以下5条命令 chown root:root /etc/passwd /etc/shadow /etc/group /etc/gshadow chmod 0644 /etc/group chmod 0644 /etc/passwd chmod 0400 /etc/shadow chmod 0400 /etc/gshadow 操作时建议做好记录或备份 确保SSH LogLevel设置为INFO | 服务配置描述 确保SSH LogLevel设置为INFO,记录登录和注销活动 加固建议 编辑 /etc/ssh/sshd_config 文件以按如下方式设置参数(取消注释): LogLevel INFO 操作时建议做好记录或备份 设置SSH空闲超时退出时间 | 服务配置描述 设置SSH空闲超时退出时间,可降低未授权用户访问其他用户ssh会话的风险 加固建议 编辑/etc/ssh/sshd_config，将ClientAliveInterval 设置为300到900，即5-15分钟，将ClientAliveCountMax设置为0。 ClientAliveInterval 900 ClientAliveCountMax 0 操作时建议做好记录或备份 SSHD强制使用V2安全协议 | 服务配置描述 SSHD强制使用V2安全协议 加固建议 编辑 /etc/ssh/sshd_config 文件以按如下方式设置参数： Protocol 2 操作时建议做好记录或备份 确保SSH MaxAuthTries设置为3到6之间 | 服务配置描述 设置较低的Max AuthTrimes参数将降低SSH服务器被暴力攻击成功的风险。 加固建议 在/etc/ssh/sshd_config中取消MaxAuthTries注释符号#，设置最大密码尝试失败次数3-6，建议为4： MaxAuthTries 4 操作时建议做好记录或备份 设置密码修改最小间隔时间 | 身份鉴别描述 设置密码修改最小间隔时间，限制密码更改过于频繁 加固建议 在 /etc/login.defs 中将 PASS_MIN_DAYS 参数设置为7-14之间,建议为7： PASS_MIN_DAYS 7 需同时执行命令为root用户设置： chage –mindays 7 root 操作时建议做好记录或备份 设置密码失效时间 | 身份鉴别描述 设置密码失效时间，强制定期修改密码，减少密码被泄漏和猜测风险，使用非密码登陆方式(如密钥对)请忽略此项。 加固建议 使用非密码登陆方式如密钥对，请忽略此项。在 /etc/login.defs 中将 PASS_MAX_DAYS 参数设置为 60-180之间，如 PASS_MAX_DAYS 90。需同时执行命令设置root密码失效时间： chage –maxdays 90 root。 操作时建议做好记录或备份 禁止SSH空密码用户登录 | 服务配置描述 禁止SSH空密码用户登录 加固建议 在/etc/ssh/sshd_config中取消PermitEmptyPasswords no注释符号# 操作时建议做好记录或备份 确保root是唯一的UID为0的帐户 | 身份鉴别描述 除root以外其他UID为0的用户都应该删除，或者为其分配新的UID 加固建议 除root以外其他UID为0的用户(查看命令cat /etc/passwd | awk -F: ‘($3 == 0) { print $1 }’|grep -v ‘^root$’ )都应该删除，或者为其分配新的UID 操作时建议做好记录或备份","categories":[{"name":"安全","slug":"安全","permalink":"http://www.ithelei.com/categories/安全/"}],"tags":[{"name":"CentOS Linux 7","slug":"CentOS-Linux-7","permalink":"http://www.ithelei.com/tags/CentOS-Linux-7/"},{"name":"基线","slug":"基线","permalink":"http://www.ithelei.com/tags/基线/"}]},{"title":"QingCloud峰会","slug":"青云峰会","date":"2019-06-03T01:20:45.000Z","updated":"2019-09-01T12:19:03.426Z","comments":true,"path":"2019/06/03/青云峰会/","link":"","permalink":"http://www.ithelei.com/2019/06/03/青云峰会/","excerpt":"","text":"参加QingCloud峰会，了解互联网最前沿技术科技为更好","categories":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/categories/峰会/"}],"tags":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/tags/峰会/"}]},{"title":"Tomcat服务安全加固","slug":"Tomcat服务安全加固","date":"2019-03-01T01:20:45.000Z","updated":"2020-02-29T13:59:38.370Z","comments":true,"path":"2019/03/01/Tomcat服务安全加固/","link":"","permalink":"http://www.ithelei.com/2019/03/01/Tomcat服务安全加固/","excerpt":"","text":"安全加固方案Tomcat服务默认启用了管理后台功能，使用该后台可直接上传 war 文件包对站点进行部署和管理。由于运维人员的疏忽，可能导致管理后台存在空口令或者弱口令的漏洞，使得黑客或者不法分子可以利用该漏洞直接上传 Webshell 脚本导致服务器沦陷。 通常 Tomcat 后台管理的 URL 地址为 http://iP:8080/manager/html/, 如下图所示： 黑客通过猜解到的口令登录 Tomcat 管理后台后，可以上传 Webshell 脚本导致服务器被入侵。 ##安全加固方案 由于此类型漏洞可能对业务系统造成比较严重的危害，建议您针对 Tomcat 管理后台进行以下安全加固配置。 (1) 网络访问控制如果您的业务不需要使用 Tomcat 管理后台管理业务代码，建议您使用安全组防火墙https://help.aliyun.com/document_detail/25475.html?spm=a2c4g.11186623.2.13.156e3e2dMa9xd2功能对管理后台 URL 地址进行拦截，或直接将 Tomcat 部署目录中 webapps 文件夹中的 manager、host-manager 文件夹全部删除，并注释 Tomcat 目录中 conf 文件夹中的 tomcat-users.xml 文件中的所有代码。 如果您的业务系统确实需要使用 Tomcat 管理后台进行业务代码的发布和管理，建议为 Tomcat 管理后台配置强口令，并修改默认 admin 用户，且密码长度不低于10位，必须包含大写字母、特殊符号、数字组合。 （2）开启 Tomcat 的访问日志 修改 conf/server.xml 文件，将下列代码取消注释： `&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;common&quot; resolveHosts=&quot;false&quot;/&gt;`启用访问日志功能，重启 Tomcat 服务后，在 tomcat_home/logs 文件夹中就可以看到访问日志。 （3） Tomcat 默认帐号安全 修改 Tomcat 安装目录 conf 下的 tomcat-user.xml 文件，重新设置复杂口令并保存文件。重启 Tomcat 服务后，新口令即生效。 （4）修改默认访问端口修改 conf/server.xml 文件把默认的 8080 访问端口改成其它端口。 （5）重定向错误页面修改访问 Tomcat 错误页面的返回信息，在 webapps\\manger 目录中创建相应的401.html、404.htm、500.htm 文件，然后在 conf/web.xml 文件的最后一行之前添加下列代码： ` &lt;error-page&gt; &lt;error-code&gt;401&lt;/error-code&gt; &lt;location&gt;/401.htm&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;location&gt;/404.htm&lt;/location&gt; &lt;/error-page&gt; &lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;location&gt;/500.htm&lt;/location&gt; &lt;/error-page&gt;`（6）防止直接访问目录时由于找不到默认页面，而列出目录下的文件的情况。 在 web.xml 文件中，将listings改成false。 （7） 删除文档和示例程序 删除 webapps 目录下的 docs、examples、manager、ROOT、host-manager 文件夹。","categories":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://www.ithelei.com/categories/Tomcat/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://www.ithelei.com/tags/Tomcat/"}]},{"title":"参加阿里云峰会","slug":"阿里云峰会","date":"2019-03-01T01:20:45.000Z","updated":"2019-09-01T12:14:15.602Z","comments":true,"path":"2019/03/01/阿里云峰会/","link":"","permalink":"http://www.ithelei.com/2019/03/01/阿里云峰会/","excerpt":"","text":"参加阿里云峰会，了解互联网最前沿技术十年再出发 科技为更好","categories":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/categories/峰会/"}],"tags":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/tags/峰会/"}]},{"title":"生意帮","slug":"生意帮","date":"2019-02-17T01:20:45.000Z","updated":"2019-09-15T13:40:31.049Z","comments":true,"path":"2019/02/17/生意帮/","link":"","permalink":"http://www.ithelei.com/2019/02/17/生意帮/","excerpt":"","text":"数字化","categories":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/categories/峰会/"}],"tags":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/tags/峰会/"}]},{"title":"2019企业微信","slug":"2019企业微信","date":"2019-01-17T01:20:45.000Z","updated":"2019-09-15T13:34:19.788Z","comments":true,"path":"2019/01/17/2019企业微信/","link":"","permalink":"http://www.ithelei.com/2019/01/17/2019企业微信/","excerpt":"","text":"技术为更好","categories":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/categories/峰会/"}],"tags":[{"name":"峰会","slug":"峰会","permalink":"http://www.ithelei.com/tags/峰会/"}]},{"title":"Openresty","slug":"openresty","date":"2019-01-17T01:20:45.000Z","updated":"2020-03-29T08:35:37.392Z","comments":true,"path":"2019/01/17/openresty/","link":"","permalink":"http://www.ithelei.com/2019/01/17/openresty/","excerpt":"","text":"Openresty源码安装https://openresty.org/cn/installation.html apt-get install gcc libpcre3-dev libssl-dev perl make build-essential yum -y install pcre-devel openssl-devel gcc curl yum -y install readline-devel pcre-devel openssl-devel gcc wget https://openresty.org/download/openresty-1.13.6.2.tar.gz tar xvfz openresty-1.13.6.2.tar.gz cd openresty-1.13.6.2 ./configure make make install export PATH=/usr/local/openresty/bin:$PATH 环境变量 OpenResty官网 `https://openresty.org/`","categories":[{"name":"Openresty","slug":"Openresty","permalink":"http://www.ithelei.com/categories/Openresty/"}],"tags":[{"name":"Openresty","slug":"Openresty","permalink":"http://www.ithelei.com/tags/Openresty/"}]},{"title":"部门开会","slug":"部门开会","date":"2018-12-08T01:20:45.000Z","updated":"2019-09-15T13:59:59.123Z","comments":true,"path":"2018/12/08/部门开会/","link":"","permalink":"http://www.ithelei.com/2018/12/08/部门开会/","excerpt":"","text":"方总CTO","categories":[{"name":"会议","slug":"会议","permalink":"http://www.ithelei.com/categories/会议/"}],"tags":[{"name":"会议","slug":"会议","permalink":"http://www.ithelei.com/tags/会议/"}]},{"title":"LinuxShell脚本的开发环境的配置和优化","slug":"LinuxShell脚本的开发环境的配置和优化","date":"2017-01-17T01:20:45.000Z","updated":"2020-06-14T11:10:50.224Z","comments":true,"path":"2017/01/17/LinuxShell脚本的开发环境的配置和优化/","link":"","permalink":"http://www.ithelei.com/2017/01/17/LinuxShell脚本的开发环境的配置和优化/","excerpt":"","text":"使用vim而不是vi编辑器 vim /etc/profile alias vi=vim source /etc/profile linux 环境下的vim编辑器默认不够强大，如果进行脚本开发还要进行适当的设置。 vim编辑器有一个可以用来调整配置的配置文件，默认放在用户家目录下，全路径以及名字组合为~/.vimrc(全局路径为/etc/vimrc),这是一个隐藏文件。然后退出SSH客户端重新登录，即可应用.vimrc里对应的设置。 设置： `set nocompatible set history=100 filetype on filetype plugin on filetype indent on set autoread set mouse=a syntax enable set cursorline hi cursorline guibg=#00ff00 hi CursorColumn guibg=#00ff00 set nofen set fdl=0 set expandtab set tabstop=4 set shiftwidth=4 set softtabstop=4 set smarttab set ai set si set wrap set sw=4 set wildmenu set ruler set cmdheight=1 set lz set backspace=eol,start,indent set whichwrap+=&lt;,&gt;,h,l set magic set noerrorbells set novisualbell set showmatch set mat=2 set hlsearch set ignorecase set encoding=utf-8 set fileencodings=utf-8 set termencoding=utf-8 set smartindent set cin set showmatch set guioptions-=T set guioptions-=m set vb t_vb= set laststatus=2 set pastetoggle=&lt;F9&gt; set background=dark highlight Search ctermbg=black ctermfg=white guifg=white guibg=black autocmd BufNewFile *.py,*.cc,*.sh,*.java exec &quot;:call SetTitle()&quot; func SetTitle() if expand(&quot;%:e&quot;) == &apos;sh&apos; call setline(1, &quot;#!/bin/bash&quot;) call setline(2, &quot;#Author:ithelei&quot;) call setline(3, &quot;#website:http://www.wayboo.com&quot;) call setline(4, &quot;#Time:&quot;.strftime(&quot;%F %T&quot;)) call setline(5, &quot;#Name:&quot;.expand(&quot;%&quot;)) call setline(6, &quot;#Version:V1.0&quot;) call setline(7, &quot;#Description:This is a test script.&quot;) endif endfunc ` 只要是以.sh为扩展名的文件，就会自动增加版权信息； 当代码量较大时比较有用的高级功能——代码折叠，在命令模式下，可以将光标定位到需要折叠的开始行，然后执行zf3j（其中3是指定要折叠多少行），便可以折叠当前行及下面三行的代码，若把光标放在对应折叠后的行上，按空格键即可展开折叠的行。 有时从外部复制部分shell代码到当前脚本后发现缩进是乱的，可以将vim编辑器调整为命令模式（按Esc键），然后将光标定位到要调整的行开头，接下来按“v”键，然后用键盘上下键选定要调整的多行代码，选中后按“=”键即可将代码调整为规整的格式。 注释： `&quot;关闭兼容模式 set nocompatible &quot;设置历史记录步数 set history=100 &quot;开启相关插件 filetype on filetype plugin on filetype indent on &quot;当文件在外部被修改时，自动更新该文件 set autoread &quot;激活鼠标的使用 set mouse=a &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; =&gt; 字体和颜色 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;开启语法 syntax enable &quot;设置字体 &quot;set guifont=dejaVu\\ Sans\\ MONO\\ 10 &quot; &quot;&quot;设置配色 &quot;colorscheme desert &quot;高亮显示当前行 set cursorline hi cursorline guibg=#00ff00 hi CursorColumn guibg=#00ff00 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; =&gt; 代码折叠功能 by oldboy &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;激活折叠功能 set foldenable &quot;设置按照语法方式折叠（可简写set fdm=XX） &quot;有6种折叠方法： &quot;manual 手工定义折叠 &quot;indent 更多的缩进表示更高级别的折叠 &quot;expr 用表达式来定义折叠 &quot;syntax 用语法高亮来定义折叠 &quot;diff 对没有更改的文本进行折叠 &quot;marker 对文中的标志进行折叠 set foldmethod=manual &quot;设置折叠区域的宽度 &quot;如果不为0，则在屏幕左侧显示一个折叠标识列 &quot;分别用“-”和“+”来表示打开和关闭的折叠。 set foldcolumn=0 &quot;设置折叠层数为3 setlocal foldlevel=3 &quot;设置为自动关闭折叠 set foldclose=all &quot;用空格键来代替zo和zc快捷键实现开关折叠 &quot;zo O-pen a fold (打开折叠) &quot;zc C-lose a fold (关闭折叠) &quot;zf F-old creation (创建折叠) nnoremap &lt;space&gt; @=((foldclosed(line(&apos;.&apos;)) &lt; 0) &apos;zc&apos; : &apos;zo&apos;)&lt;CR&gt; &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; =&gt; 文字处理 by oldboy &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;使用空格来替换Tab set expandtab &quot;设置所有的Tab和缩进为4个空格 set tabstop=4 &quot;设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为4 set shiftwidth=4 &quot;使得按退格键时可以一次删掉4个空格 set softtabstop=4 set smarttab &quot;缩进，自动缩进(继承前一行的缩进) &quot;set autoindent命令关闭自动缩进，是下面配置的缩写。 &quot;可使用autoindent命令的简写，即 “:set ai” 和 “:set noai”。 &quot;还可以使用“ :set ai sw=4”在一个命令中打开缩进并设置缩进级别。 set ai &quot;智能缩进 set si &quot;自动换行 set wrap &quot;设置软宽度 set sw=4 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; =&gt; Vim 界面 by oldboy &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;Turn on WiLd menu set wildmenu &quot;显示标尺 set ruler &quot;设置命令行的高度 set cmdheight=1 &quot;显示行数 &quot;set nu &quot;Do not redraw, when running macros.. lazyredraw set lz &quot;设置退格 set backspace=eol,start,indent &quot;Bbackspace and cursor keys wrap to set whichwrap+=&lt;,&gt;,h,l &quot;Set magic on（设置魔术） set magic &quot;关闭遇到错误时的声音提示 &quot;关闭错误信息响铃 set noerrorbells &quot;关闭使用可视响铃代替呼叫 set novisualbell &quot;显示匹配的括号([{和}]) set showmatch &quot;How many tenths of a second to blink set mat=2 &quot;搜索时高亮显示搜索到的内容 set hlsearch &quot;搜索时不区分大小写 &quot;还可以使用简写（“:set ic” 和 “:set noic”） set ignorecase &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; =&gt; 编码设置 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;设置编码 set encoding=utf-8 &quot;设置文件编码 set fileencodings=utf-8 &quot;设置终端编码 set termencoding=utf-8 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; =&gt; 其他设置 by oldboy 2010 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;开启新行时使用智能自动缩进 set smartindent set cin set showmatch &quot;隐藏工具栏 set guioptions-=T &quot;隐藏菜单栏 set guioptions-=m &quot;置空错误铃声的终端代码 set vb t_vb= &quot;显示状态栏 (默认值为 1, 表示无法显示状态栏) set laststatus=2 &quot;粘贴不换行问题的解决方法 set pastetoggle=&lt;F9&gt; &quot;设置背景色 set background=dark &quot;设置高亮相关 highlight Search ctermbg=black ctermfg=white guifg=white guibg=black `","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://www.ithelei.com/tags/Linux/"}]}]}